{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JA-5zb09MvcQ"
      },
      "source": [
        "# ECE C247 - Neural Networks & Deep Learning, EEG Project\n",
        "## Alexie Pogue, Amir Omidfar, Eric Peltola, Kenny Chen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "33ma69ROKKx9",
        "outputId": "9b9ea6f6-bf4e-4413-f1bf-54147e2fe12f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IUTceQ9hNnQ2",
        "colab": {}
      },
      "source": [
        "from models import *\n",
        "from solver import *\n",
        "from utils import *\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4UwlDe0UQ3KQ"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cHDBStjfQ45O",
        "colab": {}
      },
      "source": [
        "LR      = 0.0005\n",
        "BETAS   = (0.9, 0.999)\n",
        "EPS     = 1e-08\n",
        "DECAY   = 0.0005\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS  = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CQELDHqOPaEL"
      },
      "source": [
        "# Data Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u59xJ4i0Kini"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ijYr79w7PbX4",
        "outputId": "1ee335fa-f76c-4220-e16f-086e347d825c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "data_path = \"/content/drive/Shared drives/ECE C247 Project/data/\"\n",
        "\n",
        "# load data files\n",
        "X_train_valid, y_train_valid, X_test, y_test = load_data(data_path, subjects=[1,2,3,4,5,6,7,8,9], verbose=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GLwTyAw7Ki3J"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vh43GoyeKsWt",
        "colab": {}
      },
      "source": [
        "# filter inputs\n",
        "X_train_valid = filter_data(X_train_valid, fs=250, order=6, lowcut=7, highcut=30)\n",
        "X_test = filter_data(X_test, fs=250, order=6, lowcut=7, highcut=30)\n",
        "\n",
        "# smooth inputs\n",
        "X_train_valid = smooth_data(X_train_valid, ws=5)\n",
        "X_test = smooth_data(X_test, ws=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oElNaA-4KjbO"
      },
      "source": [
        "## PyTorch Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rq3HS1tXKuEa",
        "colab": {}
      },
      "source": [
        "# set up PyTorch dataloaders\n",
        "data_loaders = dataloader_setup(X_train_valid, y_train_valid, X_test, y_test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4Tr4gG-DQvbc"
      },
      "source": [
        "# Model Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H0w34hNie-H1"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ty1ScpYGR4wQ",
        "outputId": "e401dd23-1428-41cc-c8ab-925bbabd09fa",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = CNN().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=BETAS, eps=EPS, weight_decay=DECAY)\n",
        "train_and_evaluate(model, optimizer, data_loaders, num_epochs=EPOCHS)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Progress: \tEpoch 1 [0/1692 (0.00%)]\t\tLoss: 1.40412\n",
            "Training Progress: \tEpoch 1 [320/1692 (18.87%)]\t\tLoss: 1.49935\n",
            "Training Progress: \tEpoch 1 [640/1692 (37.74%)]\t\tLoss: 1.41915\n",
            "Training Progress: \tEpoch 1 [960/1692 (56.60%)]\t\tLoss: 1.34529\n",
            "Training Progress: \tEpoch 1 [1280/1692 (75.47%)]\t\tLoss: 1.33864\n",
            "Training Progress: \tEpoch 1 [1600/1692 (94.34%)]\t\tLoss: 1.36990\n",
            "\tTrain loss: 0.04362, Accuracy: 460/1692 (27.19%)\n",
            "\tValidation loss: 0.00330, Accuracy: 117/423 (27.66%)\n",
            "\tTest loss: 0.00314, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 2 [0/1692 (0.00%)]\t\tLoss: 1.38965\n",
            "Training Progress: \tEpoch 2 [320/1692 (18.87%)]\t\tLoss: 1.39425\n",
            "Training Progress: \tEpoch 2 [640/1692 (37.74%)]\t\tLoss: 1.35069\n",
            "Training Progress: \tEpoch 2 [960/1692 (56.60%)]\t\tLoss: 1.40820\n",
            "Training Progress: \tEpoch 2 [1280/1692 (75.47%)]\t\tLoss: 1.34062\n",
            "Training Progress: \tEpoch 2 [1600/1692 (94.34%)]\t\tLoss: 1.41581\n",
            "\tTrain loss: 0.04350, Accuracy: 462/1692 (27.30%)\n",
            "\tValidation loss: 0.00332, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00313, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 3 [0/1692 (0.00%)]\t\tLoss: 1.38061\n",
            "Training Progress: \tEpoch 3 [320/1692 (18.87%)]\t\tLoss: 1.46384\n",
            "Training Progress: \tEpoch 3 [640/1692 (37.74%)]\t\tLoss: 1.44600\n",
            "Training Progress: \tEpoch 3 [960/1692 (56.60%)]\t\tLoss: 1.37653\n",
            "Training Progress: \tEpoch 3 [1280/1692 (75.47%)]\t\tLoss: 1.34107\n",
            "Training Progress: \tEpoch 3 [1600/1692 (94.34%)]\t\tLoss: 1.42817\n",
            "\tTrain loss: 0.04319, Accuracy: 488/1692 (28.84%)\n",
            "\tValidation loss: 0.00330, Accuracy: 115/423 (27.19%)\n",
            "\tTest loss: 0.00312, Accuracy: 122/443 (27.54%)\n",
            "\n",
            "Training Progress: \tEpoch 4 [0/1692 (0.00%)]\t\tLoss: 1.37881\n",
            "Training Progress: \tEpoch 4 [320/1692 (18.87%)]\t\tLoss: 1.41426\n",
            "Training Progress: \tEpoch 4 [640/1692 (37.74%)]\t\tLoss: 1.44449\n",
            "Training Progress: \tEpoch 4 [960/1692 (56.60%)]\t\tLoss: 1.34695\n",
            "Training Progress: \tEpoch 4 [1280/1692 (75.47%)]\t\tLoss: 1.32525\n",
            "Training Progress: \tEpoch 4 [1600/1692 (94.34%)]\t\tLoss: 1.33047\n",
            "\tTrain loss: 0.04301, Accuracy: 481/1692 (28.43%)\n",
            "\tValidation loss: 0.00329, Accuracy: 125/423 (29.55%)\n",
            "\tTest loss: 0.00311, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 5 [0/1692 (0.00%)]\t\tLoss: 1.38846\n",
            "Training Progress: \tEpoch 5 [320/1692 (18.87%)]\t\tLoss: 1.45061\n",
            "Training Progress: \tEpoch 5 [640/1692 (37.74%)]\t\tLoss: 1.38646\n",
            "Training Progress: \tEpoch 5 [960/1692 (56.60%)]\t\tLoss: 1.39156\n",
            "Training Progress: \tEpoch 5 [1280/1692 (75.47%)]\t\tLoss: 1.32554\n",
            "Training Progress: \tEpoch 5 [1600/1692 (94.34%)]\t\tLoss: 1.32285\n",
            "\tTrain loss: 0.04302, Accuracy: 475/1692 (28.07%)\n",
            "\tValidation loss: 0.00329, Accuracy: 115/423 (27.19%)\n",
            "\tTest loss: 0.00312, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 6 [0/1692 (0.00%)]\t\tLoss: 1.38970\n",
            "Training Progress: \tEpoch 6 [320/1692 (18.87%)]\t\tLoss: 1.43258\n",
            "Training Progress: \tEpoch 6 [640/1692 (37.74%)]\t\tLoss: 1.37493\n",
            "Training Progress: \tEpoch 6 [960/1692 (56.60%)]\t\tLoss: 1.39242\n",
            "Training Progress: \tEpoch 6 [1280/1692 (75.47%)]\t\tLoss: 1.36025\n",
            "Training Progress: \tEpoch 6 [1600/1692 (94.34%)]\t\tLoss: 1.38129\n",
            "\tTrain loss: 0.04291, Accuracy: 502/1692 (29.67%)\n",
            "\tValidation loss: 0.00330, Accuracy: 114/423 (26.95%)\n",
            "\tTest loss: 0.00311, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 7 [0/1692 (0.00%)]\t\tLoss: 1.40508\n",
            "Training Progress: \tEpoch 7 [320/1692 (18.87%)]\t\tLoss: 1.36545\n",
            "Training Progress: \tEpoch 7 [640/1692 (37.74%)]\t\tLoss: 1.39831\n",
            "Training Progress: \tEpoch 7 [960/1692 (56.60%)]\t\tLoss: 1.38521\n",
            "Training Progress: \tEpoch 7 [1280/1692 (75.47%)]\t\tLoss: 1.37566\n",
            "Training Progress: \tEpoch 7 [1600/1692 (94.34%)]\t\tLoss: 1.38656\n",
            "\tTrain loss: 0.04271, Accuracy: 530/1692 (31.32%)\n",
            "\tValidation loss: 0.00328, Accuracy: 116/423 (27.42%)\n",
            "\tTest loss: 0.00310, Accuracy: 115/443 (25.96%)\n",
            "\n",
            "Training Progress: \tEpoch 8 [0/1692 (0.00%)]\t\tLoss: 1.36486\n",
            "Training Progress: \tEpoch 8 [320/1692 (18.87%)]\t\tLoss: 1.39369\n",
            "Training Progress: \tEpoch 8 [640/1692 (37.74%)]\t\tLoss: 1.40500\n",
            "Training Progress: \tEpoch 8 [960/1692 (56.60%)]\t\tLoss: 1.32310\n",
            "Training Progress: \tEpoch 8 [1280/1692 (75.47%)]\t\tLoss: 1.35650\n",
            "Training Progress: \tEpoch 8 [1600/1692 (94.34%)]\t\tLoss: 1.35723\n",
            "\tTrain loss: 0.04287, Accuracy: 510/1692 (30.14%)\n",
            "\tValidation loss: 0.00330, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00310, Accuracy: 124/443 (27.99%)\n",
            "\n",
            "Training Progress: \tEpoch 9 [0/1692 (0.00%)]\t\tLoss: 1.38649\n",
            "Training Progress: \tEpoch 9 [320/1692 (18.87%)]\t\tLoss: 1.40954\n",
            "Training Progress: \tEpoch 9 [640/1692 (37.74%)]\t\tLoss: 1.34275\n",
            "Training Progress: \tEpoch 9 [960/1692 (56.60%)]\t\tLoss: 1.36940\n",
            "Training Progress: \tEpoch 9 [1280/1692 (75.47%)]\t\tLoss: 1.39280\n",
            "Training Progress: \tEpoch 9 [1600/1692 (94.34%)]\t\tLoss: 1.39520\n",
            "\tTrain loss: 0.04269, Accuracy: 532/1692 (31.44%)\n",
            "\tValidation loss: 0.00329, Accuracy: 105/423 (24.82%)\n",
            "\tTest loss: 0.00311, Accuracy: 124/443 (27.99%)\n",
            "\n",
            "Training Progress: \tEpoch 10 [0/1692 (0.00%)]\t\tLoss: 1.36210\n",
            "Training Progress: \tEpoch 10 [320/1692 (18.87%)]\t\tLoss: 1.38484\n",
            "Training Progress: \tEpoch 10 [640/1692 (37.74%)]\t\tLoss: 1.42178\n",
            "Training Progress: \tEpoch 10 [960/1692 (56.60%)]\t\tLoss: 1.35943\n",
            "Training Progress: \tEpoch 10 [1280/1692 (75.47%)]\t\tLoss: 1.34518\n",
            "Training Progress: \tEpoch 10 [1600/1692 (94.34%)]\t\tLoss: 1.33410\n",
            "\tTrain loss: 0.04249, Accuracy: 515/1692 (30.44%)\n",
            "\tValidation loss: 0.00328, Accuracy: 119/423 (28.13%)\n",
            "\tTest loss: 0.00311, Accuracy: 127/443 (28.67%)\n",
            "\n",
            "Training Progress: \tEpoch 11 [0/1692 (0.00%)]\t\tLoss: 1.31903\n",
            "Training Progress: \tEpoch 11 [320/1692 (18.87%)]\t\tLoss: 1.43964\n",
            "Training Progress: \tEpoch 11 [640/1692 (37.74%)]\t\tLoss: 1.38783\n",
            "Training Progress: \tEpoch 11 [960/1692 (56.60%)]\t\tLoss: 1.37981\n",
            "Training Progress: \tEpoch 11 [1280/1692 (75.47%)]\t\tLoss: 1.32034\n",
            "Training Progress: \tEpoch 11 [1600/1692 (94.34%)]\t\tLoss: 1.34903\n",
            "\tTrain loss: 0.04244, Accuracy: 534/1692 (31.56%)\n",
            "\tValidation loss: 0.00327, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00310, Accuracy: 132/443 (29.80%)\n",
            "\n",
            "Training Progress: \tEpoch 12 [0/1692 (0.00%)]\t\tLoss: 1.37772\n",
            "Training Progress: \tEpoch 12 [320/1692 (18.87%)]\t\tLoss: 1.39796\n",
            "Training Progress: \tEpoch 12 [640/1692 (37.74%)]\t\tLoss: 1.38947\n",
            "Training Progress: \tEpoch 12 [960/1692 (56.60%)]\t\tLoss: 1.32869\n",
            "Training Progress: \tEpoch 12 [1280/1692 (75.47%)]\t\tLoss: 1.33653\n",
            "Training Progress: \tEpoch 12 [1600/1692 (94.34%)]\t\tLoss: 1.30738\n",
            "\tTrain loss: 0.04240, Accuracy: 555/1692 (32.80%)\n",
            "\tValidation loss: 0.00326, Accuracy: 112/423 (26.48%)\n",
            "\tTest loss: 0.00310, Accuracy: 130/443 (29.35%)\n",
            "\n",
            "Training Progress: \tEpoch 13 [0/1692 (0.00%)]\t\tLoss: 1.38420\n",
            "Training Progress: \tEpoch 13 [320/1692 (18.87%)]\t\tLoss: 1.39579\n",
            "Training Progress: \tEpoch 13 [640/1692 (37.74%)]\t\tLoss: 1.42977\n",
            "Training Progress: \tEpoch 13 [960/1692 (56.60%)]\t\tLoss: 1.36849\n",
            "Training Progress: \tEpoch 13 [1280/1692 (75.47%)]\t\tLoss: 1.27570\n",
            "Training Progress: \tEpoch 13 [1600/1692 (94.34%)]\t\tLoss: 1.34316\n",
            "\tTrain loss: 0.04250, Accuracy: 529/1692 (31.26%)\n",
            "\tValidation loss: 0.00327, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00310, Accuracy: 139/443 (31.38%)\n",
            "\n",
            "Training Progress: \tEpoch 14 [0/1692 (0.00%)]\t\tLoss: 1.39490\n",
            "Training Progress: \tEpoch 14 [320/1692 (18.87%)]\t\tLoss: 1.44868\n",
            "Training Progress: \tEpoch 14 [640/1692 (37.74%)]\t\tLoss: 1.37507\n",
            "Training Progress: \tEpoch 14 [960/1692 (56.60%)]\t\tLoss: 1.36955\n",
            "Training Progress: \tEpoch 14 [1280/1692 (75.47%)]\t\tLoss: 1.32653\n",
            "Training Progress: \tEpoch 14 [1600/1692 (94.34%)]\t\tLoss: 1.36727\n",
            "\tTrain loss: 0.04206, Accuracy: 563/1692 (33.27%)\n",
            "\tValidation loss: 0.00327, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00308, Accuracy: 131/443 (29.57%)\n",
            "\n",
            "Training Progress: \tEpoch 15 [0/1692 (0.00%)]\t\tLoss: 1.34787\n",
            "Training Progress: \tEpoch 15 [320/1692 (18.87%)]\t\tLoss: 1.36246\n",
            "Training Progress: \tEpoch 15 [640/1692 (37.74%)]\t\tLoss: 1.37123\n",
            "Training Progress: \tEpoch 15 [960/1692 (56.60%)]\t\tLoss: 1.33337\n",
            "Training Progress: \tEpoch 15 [1280/1692 (75.47%)]\t\tLoss: 1.36314\n",
            "Training Progress: \tEpoch 15 [1600/1692 (94.34%)]\t\tLoss: 1.29936\n",
            "\tTrain loss: 0.04205, Accuracy: 585/1692 (34.57%)\n",
            "\tValidation loss: 0.00326, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00310, Accuracy: 143/443 (32.28%)\n",
            "\n",
            "Training Progress: \tEpoch 16 [0/1692 (0.00%)]\t\tLoss: 1.33426\n",
            "Training Progress: \tEpoch 16 [320/1692 (18.87%)]\t\tLoss: 1.42239\n",
            "Training Progress: \tEpoch 16 [640/1692 (37.74%)]\t\tLoss: 1.33685\n",
            "Training Progress: \tEpoch 16 [960/1692 (56.60%)]\t\tLoss: 1.34941\n",
            "Training Progress: \tEpoch 16 [1280/1692 (75.47%)]\t\tLoss: 1.31547\n",
            "Training Progress: \tEpoch 16 [1600/1692 (94.34%)]\t\tLoss: 1.27998\n",
            "\tTrain loss: 0.04169, Accuracy: 600/1692 (35.46%)\n",
            "\tValidation loss: 0.00326, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00308, Accuracy: 139/443 (31.38%)\n",
            "\n",
            "Training Progress: \tEpoch 17 [0/1692 (0.00%)]\t\tLoss: 1.34671\n",
            "Training Progress: \tEpoch 17 [320/1692 (18.87%)]\t\tLoss: 1.40282\n",
            "Training Progress: \tEpoch 17 [640/1692 (37.74%)]\t\tLoss: 1.31736\n",
            "Training Progress: \tEpoch 17 [960/1692 (56.60%)]\t\tLoss: 1.31749\n",
            "Training Progress: \tEpoch 17 [1280/1692 (75.47%)]\t\tLoss: 1.31442\n",
            "Training Progress: \tEpoch 17 [1600/1692 (94.34%)]\t\tLoss: 1.32857\n",
            "\tTrain loss: 0.04147, Accuracy: 623/1692 (36.82%)\n",
            "\tValidation loss: 0.00326, Accuracy: 111/423 (26.24%)\n",
            "\tTest loss: 0.00308, Accuracy: 135/443 (30.47%)\n",
            "\n",
            "Training Progress: \tEpoch 18 [0/1692 (0.00%)]\t\tLoss: 1.33342\n",
            "Training Progress: \tEpoch 18 [320/1692 (18.87%)]\t\tLoss: 1.40069\n",
            "Training Progress: \tEpoch 18 [640/1692 (37.74%)]\t\tLoss: 1.38450\n",
            "Training Progress: \tEpoch 18 [960/1692 (56.60%)]\t\tLoss: 1.31112\n",
            "Training Progress: \tEpoch 18 [1280/1692 (75.47%)]\t\tLoss: 1.35440\n",
            "Training Progress: \tEpoch 18 [1600/1692 (94.34%)]\t\tLoss: 1.27888\n",
            "\tTrain loss: 0.04164, Accuracy: 592/1692 (34.99%)\n",
            "\tValidation loss: 0.00326, Accuracy: 106/423 (25.06%)\n",
            "\tTest loss: 0.00307, Accuracy: 148/443 (33.41%)\n",
            "\n",
            "Training Progress: \tEpoch 19 [0/1692 (0.00%)]\t\tLoss: 1.32307\n",
            "Training Progress: \tEpoch 19 [320/1692 (18.87%)]\t\tLoss: 1.36895\n",
            "Training Progress: \tEpoch 19 [640/1692 (37.74%)]\t\tLoss: 1.42157\n",
            "Training Progress: \tEpoch 19 [960/1692 (56.60%)]\t\tLoss: 1.34362\n",
            "Training Progress: \tEpoch 19 [1280/1692 (75.47%)]\t\tLoss: 1.34710\n",
            "Training Progress: \tEpoch 19 [1600/1692 (94.34%)]\t\tLoss: 1.30268\n",
            "\tTrain loss: 0.04146, Accuracy: 614/1692 (36.29%)\n",
            "\tValidation loss: 0.00326, Accuracy: 114/423 (26.95%)\n",
            "\tTest loss: 0.00307, Accuracy: 130/443 (29.35%)\n",
            "\n",
            "Training Progress: \tEpoch 20 [0/1692 (0.00%)]\t\tLoss: 1.37708\n",
            "Training Progress: \tEpoch 20 [320/1692 (18.87%)]\t\tLoss: 1.39338\n",
            "Training Progress: \tEpoch 20 [640/1692 (37.74%)]\t\tLoss: 1.31159\n",
            "Training Progress: \tEpoch 20 [960/1692 (56.60%)]\t\tLoss: 1.30563\n",
            "Training Progress: \tEpoch 20 [1280/1692 (75.47%)]\t\tLoss: 1.31010\n",
            "Training Progress: \tEpoch 20 [1600/1692 (94.34%)]\t\tLoss: 1.28887\n",
            "\tTrain loss: 0.04091, Accuracy: 667/1692 (39.42%)\n",
            "\tValidation loss: 0.00324, Accuracy: 118/423 (27.90%)\n",
            "\tTest loss: 0.00309, Accuracy: 146/443 (32.96%)\n",
            "\n",
            "Training Progress: \tEpoch 21 [0/1692 (0.00%)]\t\tLoss: 1.30152\n",
            "Training Progress: \tEpoch 21 [320/1692 (18.87%)]\t\tLoss: 1.38044\n",
            "Training Progress: \tEpoch 21 [640/1692 (37.74%)]\t\tLoss: 1.30507\n",
            "Training Progress: \tEpoch 21 [960/1692 (56.60%)]\t\tLoss: 1.33931\n",
            "Training Progress: \tEpoch 21 [1280/1692 (75.47%)]\t\tLoss: 1.32804\n",
            "Training Progress: \tEpoch 21 [1600/1692 (94.34%)]\t\tLoss: 1.34393\n",
            "\tTrain loss: 0.04093, Accuracy: 643/1692 (38.00%)\n",
            "\tValidation loss: 0.00324, Accuracy: 115/423 (27.19%)\n",
            "\tTest loss: 0.00309, Accuracy: 142/443 (32.05%)\n",
            "\n",
            "Training Progress: \tEpoch 22 [0/1692 (0.00%)]\t\tLoss: 1.31319\n",
            "Training Progress: \tEpoch 22 [320/1692 (18.87%)]\t\tLoss: 1.41628\n",
            "Training Progress: \tEpoch 22 [640/1692 (37.74%)]\t\tLoss: 1.29892\n",
            "Training Progress: \tEpoch 22 [960/1692 (56.60%)]\t\tLoss: 1.34329\n",
            "Training Progress: \tEpoch 22 [1280/1692 (75.47%)]\t\tLoss: 1.36468\n",
            "Training Progress: \tEpoch 22 [1600/1692 (94.34%)]\t\tLoss: 1.32469\n",
            "\tTrain loss: 0.04088, Accuracy: 671/1692 (39.66%)\n",
            "\tValidation loss: 0.00325, Accuracy: 118/423 (27.90%)\n",
            "\tTest loss: 0.00308, Accuracy: 148/443 (33.41%)\n",
            "\n",
            "Training Progress: \tEpoch 23 [0/1692 (0.00%)]\t\tLoss: 1.30756\n",
            "Training Progress: \tEpoch 23 [320/1692 (18.87%)]\t\tLoss: 1.40077\n",
            "Training Progress: \tEpoch 23 [640/1692 (37.74%)]\t\tLoss: 1.34698\n",
            "Training Progress: \tEpoch 23 [960/1692 (56.60%)]\t\tLoss: 1.33164\n",
            "Training Progress: \tEpoch 23 [1280/1692 (75.47%)]\t\tLoss: 1.24877\n",
            "Training Progress: \tEpoch 23 [1600/1692 (94.34%)]\t\tLoss: 1.21314\n",
            "\tTrain loss: 0.04011, Accuracy: 701/1692 (41.43%)\n",
            "\tValidation loss: 0.00323, Accuracy: 124/423 (29.31%)\n",
            "\tTest loss: 0.00306, Accuracy: 142/443 (32.05%)\n",
            "\n",
            "Training Progress: \tEpoch 24 [0/1692 (0.00%)]\t\tLoss: 1.33312\n",
            "Training Progress: \tEpoch 24 [320/1692 (18.87%)]\t\tLoss: 1.33827\n",
            "Training Progress: \tEpoch 24 [640/1692 (37.74%)]\t\tLoss: 1.25162\n",
            "Training Progress: \tEpoch 24 [960/1692 (56.60%)]\t\tLoss: 1.35825\n",
            "Training Progress: \tEpoch 24 [1280/1692 (75.47%)]\t\tLoss: 1.29519\n",
            "Training Progress: \tEpoch 24 [1600/1692 (94.34%)]\t\tLoss: 1.30828\n",
            "\tTrain loss: 0.03968, Accuracy: 710/1692 (41.96%)\n",
            "\tValidation loss: 0.00324, Accuracy: 119/423 (28.13%)\n",
            "\tTest loss: 0.00306, Accuracy: 154/443 (34.76%)\n",
            "\n",
            "Training Progress: \tEpoch 25 [0/1692 (0.00%)]\t\tLoss: 1.28643\n",
            "Training Progress: \tEpoch 25 [320/1692 (18.87%)]\t\tLoss: 1.23843\n",
            "Training Progress: \tEpoch 25 [640/1692 (37.74%)]\t\tLoss: 1.30588\n",
            "Training Progress: \tEpoch 25 [960/1692 (56.60%)]\t\tLoss: 1.39188\n",
            "Training Progress: \tEpoch 25 [1280/1692 (75.47%)]\t\tLoss: 1.26394\n",
            "Training Progress: \tEpoch 25 [1600/1692 (94.34%)]\t\tLoss: 1.28243\n",
            "\tTrain loss: 0.03916, Accuracy: 790/1692 (46.69%)\n",
            "\tValidation loss: 0.00325, Accuracy: 121/423 (28.61%)\n",
            "\tTest loss: 0.00307, Accuracy: 156/443 (35.21%)\n",
            "\n",
            "Training Progress: \tEpoch 26 [0/1692 (0.00%)]\t\tLoss: 1.28542\n",
            "Training Progress: \tEpoch 26 [320/1692 (18.87%)]\t\tLoss: 1.31511\n",
            "Training Progress: \tEpoch 26 [640/1692 (37.74%)]\t\tLoss: 1.28881\n",
            "Training Progress: \tEpoch 26 [960/1692 (56.60%)]\t\tLoss: 1.25198\n",
            "Training Progress: \tEpoch 26 [1280/1692 (75.47%)]\t\tLoss: 1.33689\n",
            "Training Progress: \tEpoch 26 [1600/1692 (94.34%)]\t\tLoss: 1.28992\n",
            "\tTrain loss: 0.03898, Accuracy: 735/1692 (43.44%)\n",
            "\tValidation loss: 0.00323, Accuracy: 119/423 (28.13%)\n",
            "\tTest loss: 0.00304, Accuracy: 168/443 (37.92%)\n",
            "\n",
            "Training Progress: \tEpoch 27 [0/1692 (0.00%)]\t\tLoss: 1.26194\n",
            "Training Progress: \tEpoch 27 [320/1692 (18.87%)]\t\tLoss: 1.36737\n",
            "Training Progress: \tEpoch 27 [640/1692 (37.74%)]\t\tLoss: 1.29155\n",
            "Training Progress: \tEpoch 27 [960/1692 (56.60%)]\t\tLoss: 1.31648\n",
            "Training Progress: \tEpoch 27 [1280/1692 (75.47%)]\t\tLoss: 1.29073\n",
            "Training Progress: \tEpoch 27 [1600/1692 (94.34%)]\t\tLoss: 1.30865\n",
            "\tTrain loss: 0.03891, Accuracy: 757/1692 (44.74%)\n",
            "\tValidation loss: 0.00324, Accuracy: 121/423 (28.61%)\n",
            "\tTest loss: 0.00308, Accuracy: 150/443 (33.86%)\n",
            "\n",
            "Training Progress: \tEpoch 28 [0/1692 (0.00%)]\t\tLoss: 1.25668\n",
            "Training Progress: \tEpoch 28 [320/1692 (18.87%)]\t\tLoss: 1.39597\n",
            "Training Progress: \tEpoch 28 [640/1692 (37.74%)]\t\tLoss: 1.21314\n",
            "Training Progress: \tEpoch 28 [960/1692 (56.60%)]\t\tLoss: 1.26929\n",
            "Training Progress: \tEpoch 28 [1280/1692 (75.47%)]\t\tLoss: 1.31314\n",
            "Training Progress: \tEpoch 28 [1600/1692 (94.34%)]\t\tLoss: 1.33308\n",
            "\tTrain loss: 0.03811, Accuracy: 818/1692 (48.35%)\n",
            "\tValidation loss: 0.00325, Accuracy: 125/423 (29.55%)\n",
            "\tTest loss: 0.00307, Accuracy: 139/443 (31.38%)\n",
            "\n",
            "Training Progress: \tEpoch 29 [0/1692 (0.00%)]\t\tLoss: 1.15954\n",
            "Training Progress: \tEpoch 29 [320/1692 (18.87%)]\t\tLoss: 1.33854\n",
            "Training Progress: \tEpoch 29 [640/1692 (37.74%)]\t\tLoss: 1.27057\n",
            "Training Progress: \tEpoch 29 [960/1692 (56.60%)]\t\tLoss: 1.30968\n",
            "Training Progress: \tEpoch 29 [1280/1692 (75.47%)]\t\tLoss: 1.24976\n",
            "Training Progress: \tEpoch 29 [1600/1692 (94.34%)]\t\tLoss: 1.26297\n",
            "\tTrain loss: 0.03823, Accuracy: 811/1692 (47.93%)\n",
            "\tValidation loss: 0.00325, Accuracy: 126/423 (29.79%)\n",
            "\tTest loss: 0.00308, Accuracy: 150/443 (33.86%)\n",
            "\n",
            "Training Progress: \tEpoch 30 [0/1692 (0.00%)]\t\tLoss: 1.20325\n",
            "Training Progress: \tEpoch 30 [320/1692 (18.87%)]\t\tLoss: 1.30610\n",
            "Training Progress: \tEpoch 30 [640/1692 (37.74%)]\t\tLoss: 1.30698\n",
            "Training Progress: \tEpoch 30 [960/1692 (56.60%)]\t\tLoss: 1.25593\n",
            "Training Progress: \tEpoch 30 [1280/1692 (75.47%)]\t\tLoss: 1.40834\n",
            "Training Progress: \tEpoch 30 [1600/1692 (94.34%)]\t\tLoss: 1.26754\n",
            "\tTrain loss: 0.03737, Accuracy: 871/1692 (51.48%)\n",
            "\tValidation loss: 0.00325, Accuracy: 122/423 (28.84%)\n",
            "\tTest loss: 0.00307, Accuracy: 144/443 (32.51%)\n",
            "\n",
            "Training Progress: \tEpoch 31 [0/1692 (0.00%)]\t\tLoss: 1.33746\n",
            "Training Progress: \tEpoch 31 [320/1692 (18.87%)]\t\tLoss: 1.33481\n",
            "Training Progress: \tEpoch 31 [640/1692 (37.74%)]\t\tLoss: 1.30501\n",
            "Training Progress: \tEpoch 31 [960/1692 (56.60%)]\t\tLoss: 1.30193\n",
            "Training Progress: \tEpoch 31 [1280/1692 (75.47%)]\t\tLoss: 1.23022\n",
            "Training Progress: \tEpoch 31 [1600/1692 (94.34%)]\t\tLoss: 1.27526\n",
            "\tTrain loss: 0.03692, Accuracy: 879/1692 (51.95%)\n",
            "\tValidation loss: 0.00321, Accuracy: 133/423 (31.44%)\n",
            "\tTest loss: 0.00306, Accuracy: 153/443 (34.54%)\n",
            "\n",
            "Training Progress: \tEpoch 32 [0/1692 (0.00%)]\t\tLoss: 1.16288\n",
            "Training Progress: \tEpoch 32 [320/1692 (18.87%)]\t\tLoss: 1.36841\n",
            "Training Progress: \tEpoch 32 [640/1692 (37.74%)]\t\tLoss: 1.08351\n",
            "Training Progress: \tEpoch 32 [960/1692 (56.60%)]\t\tLoss: 1.25368\n",
            "Training Progress: \tEpoch 32 [1280/1692 (75.47%)]\t\tLoss: 1.26237\n",
            "Training Progress: \tEpoch 32 [1600/1692 (94.34%)]\t\tLoss: 1.33807\n",
            "\tTrain loss: 0.03606, Accuracy: 892/1692 (52.72%)\n",
            "\tValidation loss: 0.00323, Accuracy: 127/423 (30.02%)\n",
            "\tTest loss: 0.00306, Accuracy: 153/443 (34.54%)\n",
            "\n",
            "Training Progress: \tEpoch 33 [0/1692 (0.00%)]\t\tLoss: 1.14240\n",
            "Training Progress: \tEpoch 33 [320/1692 (18.87%)]\t\tLoss: 1.17155\n",
            "Training Progress: \tEpoch 33 [640/1692 (37.74%)]\t\tLoss: 1.17244\n",
            "Training Progress: \tEpoch 33 [960/1692 (56.60%)]\t\tLoss: 1.30088\n",
            "Training Progress: \tEpoch 33 [1280/1692 (75.47%)]\t\tLoss: 1.21009\n",
            "Training Progress: \tEpoch 33 [1600/1692 (94.34%)]\t\tLoss: 1.14824\n",
            "\tTrain loss: 0.03619, Accuracy: 904/1692 (53.43%)\n",
            "\tValidation loss: 0.00322, Accuracy: 128/423 (30.26%)\n",
            "\tTest loss: 0.00309, Accuracy: 135/443 (30.47%)\n",
            "\n",
            "Training Progress: \tEpoch 34 [0/1692 (0.00%)]\t\tLoss: 1.16490\n",
            "Training Progress: \tEpoch 34 [320/1692 (18.87%)]\t\tLoss: 1.24412\n",
            "Training Progress: \tEpoch 34 [640/1692 (37.74%)]\t\tLoss: 1.17492\n",
            "Training Progress: \tEpoch 34 [960/1692 (56.60%)]\t\tLoss: 1.13767\n",
            "Training Progress: \tEpoch 34 [1280/1692 (75.47%)]\t\tLoss: 1.20559\n",
            "Training Progress: \tEpoch 34 [1600/1692 (94.34%)]\t\tLoss: 1.16766\n",
            "\tTrain loss: 0.03462, Accuracy: 950/1692 (56.15%)\n",
            "\tValidation loss: 0.00322, Accuracy: 139/423 (32.86%)\n",
            "\tTest loss: 0.00307, Accuracy: 137/443 (30.93%)\n",
            "\n",
            "Training Progress: \tEpoch 35 [0/1692 (0.00%)]\t\tLoss: 1.10093\n",
            "Training Progress: \tEpoch 35 [320/1692 (18.87%)]\t\tLoss: 1.15096\n",
            "Training Progress: \tEpoch 35 [640/1692 (37.74%)]\t\tLoss: 1.19986\n",
            "Training Progress: \tEpoch 35 [960/1692 (56.60%)]\t\tLoss: 1.22260\n",
            "Training Progress: \tEpoch 35 [1280/1692 (75.47%)]\t\tLoss: 1.15155\n",
            "Training Progress: \tEpoch 35 [1600/1692 (94.34%)]\t\tLoss: 1.23057\n",
            "\tTrain loss: 0.03484, Accuracy: 979/1692 (57.86%)\n",
            "\tValidation loss: 0.00323, Accuracy: 132/423 (31.21%)\n",
            "\tTest loss: 0.00311, Accuracy: 139/443 (31.38%)\n",
            "\n",
            "Training Progress: \tEpoch 36 [0/1692 (0.00%)]\t\tLoss: 1.19259\n",
            "Training Progress: \tEpoch 36 [320/1692 (18.87%)]\t\tLoss: 1.36289\n",
            "Training Progress: \tEpoch 36 [640/1692 (37.74%)]\t\tLoss: 1.13412\n",
            "Training Progress: \tEpoch 36 [960/1692 (56.60%)]\t\tLoss: 1.22671\n",
            "Training Progress: \tEpoch 36 [1280/1692 (75.47%)]\t\tLoss: 1.00767\n",
            "Training Progress: \tEpoch 36 [1600/1692 (94.34%)]\t\tLoss: 1.12064\n",
            "\tTrain loss: 0.03394, Accuracy: 1002/1692 (59.22%)\n",
            "\tValidation loss: 0.00324, Accuracy: 129/423 (30.50%)\n",
            "\tTest loss: 0.00308, Accuracy: 141/443 (31.83%)\n",
            "\n",
            "Training Progress: \tEpoch 37 [0/1692 (0.00%)]\t\tLoss: 1.07094\n",
            "Training Progress: \tEpoch 37 [320/1692 (18.87%)]\t\tLoss: 1.22935\n",
            "Training Progress: \tEpoch 37 [640/1692 (37.74%)]\t\tLoss: 1.06466\n",
            "Training Progress: \tEpoch 37 [960/1692 (56.60%)]\t\tLoss: 1.12256\n",
            "Training Progress: \tEpoch 37 [1280/1692 (75.47%)]\t\tLoss: 1.29834\n",
            "Training Progress: \tEpoch 37 [1600/1692 (94.34%)]\t\tLoss: 1.18680\n",
            "\tTrain loss: 0.03241, Accuracy: 1043/1692 (61.64%)\n",
            "\tValidation loss: 0.00331, Accuracy: 115/423 (27.19%)\n",
            "\tTest loss: 0.00312, Accuracy: 140/443 (31.60%)\n",
            "\n",
            "Training Progress: \tEpoch 38 [0/1692 (0.00%)]\t\tLoss: 1.10563\n",
            "Training Progress: \tEpoch 38 [320/1692 (18.87%)]\t\tLoss: 1.36631\n",
            "Training Progress: \tEpoch 38 [640/1692 (37.74%)]\t\tLoss: 1.08842\n",
            "Training Progress: \tEpoch 38 [960/1692 (56.60%)]\t\tLoss: 1.24867\n",
            "Training Progress: \tEpoch 38 [1280/1692 (75.47%)]\t\tLoss: 1.19128\n",
            "Training Progress: \tEpoch 38 [1600/1692 (94.34%)]\t\tLoss: 1.17620\n",
            "\tTrain loss: 0.03278, Accuracy: 1020/1692 (60.28%)\n",
            "\tValidation loss: 0.00328, Accuracy: 124/423 (29.31%)\n",
            "\tTest loss: 0.00308, Accuracy: 140/443 (31.60%)\n",
            "\n",
            "Training Progress: \tEpoch 39 [0/1692 (0.00%)]\t\tLoss: 1.17679\n",
            "Training Progress: \tEpoch 39 [320/1692 (18.87%)]\t\tLoss: 1.15712\n",
            "Training Progress: \tEpoch 39 [640/1692 (37.74%)]\t\tLoss: 1.03707\n",
            "Training Progress: \tEpoch 39 [960/1692 (56.60%)]\t\tLoss: 1.10142\n",
            "Training Progress: \tEpoch 39 [1280/1692 (75.47%)]\t\tLoss: 1.12844\n",
            "Training Progress: \tEpoch 39 [1600/1692 (94.34%)]\t\tLoss: 1.16193\n",
            "\tTrain loss: 0.03076, Accuracy: 1106/1692 (65.37%)\n",
            "\tValidation loss: 0.00332, Accuracy: 117/423 (27.66%)\n",
            "\tTest loss: 0.00316, Accuracy: 139/443 (31.38%)\n",
            "\n",
            "Training Progress: \tEpoch 40 [0/1692 (0.00%)]\t\tLoss: 1.21981\n",
            "Training Progress: \tEpoch 40 [320/1692 (18.87%)]\t\tLoss: 1.10029\n",
            "Training Progress: \tEpoch 40 [640/1692 (37.74%)]\t\tLoss: 1.24036\n",
            "Training Progress: \tEpoch 40 [960/1692 (56.60%)]\t\tLoss: 1.06855\n",
            "Training Progress: \tEpoch 40 [1280/1692 (75.47%)]\t\tLoss: 1.12150\n",
            "Training Progress: \tEpoch 40 [1600/1692 (94.34%)]\t\tLoss: 1.16635\n",
            "\tTrain loss: 0.03006, Accuracy: 1155/1692 (68.26%)\n",
            "\tValidation loss: 0.00330, Accuracy: 130/423 (30.73%)\n",
            "\tTest loss: 0.00315, Accuracy: 141/443 (31.83%)\n",
            "\n",
            "Training Progress: \tEpoch 41 [0/1692 (0.00%)]\t\tLoss: 1.08322\n",
            "Training Progress: \tEpoch 41 [320/1692 (18.87%)]\t\tLoss: 1.31112\n",
            "Training Progress: \tEpoch 41 [640/1692 (37.74%)]\t\tLoss: 1.06218\n",
            "Training Progress: \tEpoch 41 [960/1692 (56.60%)]\t\tLoss: 1.00620\n",
            "Training Progress: \tEpoch 41 [1280/1692 (75.47%)]\t\tLoss: 1.17491\n",
            "Training Progress: \tEpoch 41 [1600/1692 (94.34%)]\t\tLoss: 1.16764\n",
            "\tTrain loss: 0.02951, Accuracy: 1139/1692 (67.32%)\n",
            "\tValidation loss: 0.00328, Accuracy: 128/423 (30.26%)\n",
            "\tTest loss: 0.00320, Accuracy: 130/443 (29.35%)\n",
            "\n",
            "Training Progress: \tEpoch 42 [0/1692 (0.00%)]\t\tLoss: 1.18421\n",
            "Training Progress: \tEpoch 42 [320/1692 (18.87%)]\t\tLoss: 1.08887\n",
            "Training Progress: \tEpoch 42 [640/1692 (37.74%)]\t\tLoss: 1.10209\n",
            "Training Progress: \tEpoch 42 [960/1692 (56.60%)]\t\tLoss: 1.16576\n",
            "Training Progress: \tEpoch 42 [1280/1692 (75.47%)]\t\tLoss: 1.06864\n",
            "Training Progress: \tEpoch 42 [1600/1692 (94.34%)]\t\tLoss: 1.05147\n",
            "\tTrain loss: 0.02883, Accuracy: 1157/1692 (68.38%)\n",
            "\tValidation loss: 0.00331, Accuracy: 117/423 (27.66%)\n",
            "\tTest loss: 0.00325, Accuracy: 131/443 (29.57%)\n",
            "\n",
            "Training Progress: \tEpoch 43 [0/1692 (0.00%)]\t\tLoss: 1.11414\n",
            "Training Progress: \tEpoch 43 [320/1692 (18.87%)]\t\tLoss: 1.18412\n",
            "Training Progress: \tEpoch 43 [640/1692 (37.74%)]\t\tLoss: 0.96630\n",
            "Training Progress: \tEpoch 43 [960/1692 (56.60%)]\t\tLoss: 1.07453\n",
            "Training Progress: \tEpoch 43 [1280/1692 (75.47%)]\t\tLoss: 1.02710\n",
            "Training Progress: \tEpoch 43 [1600/1692 (94.34%)]\t\tLoss: 1.23063\n",
            "\tTrain loss: 0.02765, Accuracy: 1227/1692 (72.52%)\n",
            "\tValidation loss: 0.00326, Accuracy: 134/423 (31.68%)\n",
            "\tTest loss: 0.00321, Accuracy: 135/443 (30.47%)\n",
            "\n",
            "Training Progress: \tEpoch 44 [0/1692 (0.00%)]\t\tLoss: 0.94662\n",
            "Training Progress: \tEpoch 44 [320/1692 (18.87%)]\t\tLoss: 1.09922\n",
            "Training Progress: \tEpoch 44 [640/1692 (37.74%)]\t\tLoss: 1.01054\n",
            "Training Progress: \tEpoch 44 [960/1692 (56.60%)]\t\tLoss: 1.13646\n",
            "Training Progress: \tEpoch 44 [1280/1692 (75.47%)]\t\tLoss: 0.85192\n",
            "Training Progress: \tEpoch 44 [1600/1692 (94.34%)]\t\tLoss: 1.08992\n",
            "\tTrain loss: 0.02643, Accuracy: 1269/1692 (75.00%)\n",
            "\tValidation loss: 0.00329, Accuracy: 140/423 (33.10%)\n",
            "\tTest loss: 0.00329, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 45 [0/1692 (0.00%)]\t\tLoss: 1.10978\n",
            "Training Progress: \tEpoch 45 [320/1692 (18.87%)]\t\tLoss: 1.17078\n",
            "Training Progress: \tEpoch 45 [640/1692 (37.74%)]\t\tLoss: 0.95158\n",
            "Training Progress: \tEpoch 45 [960/1692 (56.60%)]\t\tLoss: 0.94072\n",
            "Training Progress: \tEpoch 45 [1280/1692 (75.47%)]\t\tLoss: 1.10105\n",
            "Training Progress: \tEpoch 45 [1600/1692 (94.34%)]\t\tLoss: 0.93186\n",
            "\tTrain loss: 0.02532, Accuracy: 1295/1692 (76.54%)\n",
            "\tValidation loss: 0.00328, Accuracy: 128/423 (30.26%)\n",
            "\tTest loss: 0.00325, Accuracy: 141/443 (31.83%)\n",
            "\n",
            "Training Progress: \tEpoch 46 [0/1692 (0.00%)]\t\tLoss: 1.03488\n",
            "Training Progress: \tEpoch 46 [320/1692 (18.87%)]\t\tLoss: 1.15835\n",
            "Training Progress: \tEpoch 46 [640/1692 (37.74%)]\t\tLoss: 0.94085\n",
            "Training Progress: \tEpoch 46 [960/1692 (56.60%)]\t\tLoss: 0.99039\n",
            "Training Progress: \tEpoch 46 [1280/1692 (75.47%)]\t\tLoss: 0.95141\n",
            "Training Progress: \tEpoch 46 [1600/1692 (94.34%)]\t\tLoss: 0.97180\n",
            "\tTrain loss: 0.02421, Accuracy: 1319/1692 (77.96%)\n",
            "\tValidation loss: 0.00330, Accuracy: 131/423 (30.97%)\n",
            "\tTest loss: 0.00330, Accuracy: 128/443 (28.89%)\n",
            "\n",
            "Training Progress: \tEpoch 47 [0/1692 (0.00%)]\t\tLoss: 1.01449\n",
            "Training Progress: \tEpoch 47 [320/1692 (18.87%)]\t\tLoss: 1.19305\n",
            "Training Progress: \tEpoch 47 [640/1692 (37.74%)]\t\tLoss: 1.02724\n",
            "Training Progress: \tEpoch 47 [960/1692 (56.60%)]\t\tLoss: 1.02370\n",
            "Training Progress: \tEpoch 47 [1280/1692 (75.47%)]\t\tLoss: 1.02631\n",
            "Training Progress: \tEpoch 47 [1600/1692 (94.34%)]\t\tLoss: 1.08760\n",
            "\tTrain loss: 0.02269, Accuracy: 1377/1692 (81.38%)\n",
            "\tValidation loss: 0.00327, Accuracy: 142/423 (33.57%)\n",
            "\tTest loss: 0.00326, Accuracy: 127/443 (28.67%)\n",
            "\n",
            "Training Progress: \tEpoch 48 [0/1692 (0.00%)]\t\tLoss: 1.00041\n",
            "Training Progress: \tEpoch 48 [320/1692 (18.87%)]\t\tLoss: 0.91751\n",
            "Training Progress: \tEpoch 48 [640/1692 (37.74%)]\t\tLoss: 0.82464\n",
            "Training Progress: \tEpoch 48 [960/1692 (56.60%)]\t\tLoss: 0.98060\n",
            "Training Progress: \tEpoch 48 [1280/1692 (75.47%)]\t\tLoss: 0.68525\n",
            "Training Progress: \tEpoch 48 [1600/1692 (94.34%)]\t\tLoss: 0.84411\n",
            "\tTrain loss: 0.02102, Accuracy: 1375/1692 (81.26%)\n",
            "\tValidation loss: 0.00335, Accuracy: 131/423 (30.97%)\n",
            "\tTest loss: 0.00337, Accuracy: 136/443 (30.70%)\n",
            "\n",
            "Training Progress: \tEpoch 49 [0/1692 (0.00%)]\t\tLoss: 0.85524\n",
            "Training Progress: \tEpoch 49 [320/1692 (18.87%)]\t\tLoss: 0.98568\n",
            "Training Progress: \tEpoch 49 [640/1692 (37.74%)]\t\tLoss: 0.81403\n",
            "Training Progress: \tEpoch 49 [960/1692 (56.60%)]\t\tLoss: 0.98029\n",
            "Training Progress: \tEpoch 49 [1280/1692 (75.47%)]\t\tLoss: 1.01523\n",
            "Training Progress: \tEpoch 49 [1600/1692 (94.34%)]\t\tLoss: 0.79263\n",
            "\tTrain loss: 0.02132, Accuracy: 1352/1692 (79.91%)\n",
            "\tValidation loss: 0.00344, Accuracy: 134/423 (31.68%)\n",
            "\tTest loss: 0.00346, Accuracy: 122/443 (27.54%)\n",
            "\n",
            "Training Progress: \tEpoch 50 [0/1692 (0.00%)]\t\tLoss: 0.77832\n",
            "Training Progress: \tEpoch 50 [320/1692 (18.87%)]\t\tLoss: 0.93335\n",
            "Training Progress: \tEpoch 50 [640/1692 (37.74%)]\t\tLoss: 0.72862\n",
            "Training Progress: \tEpoch 50 [960/1692 (56.60%)]\t\tLoss: 1.02219\n",
            "Training Progress: \tEpoch 50 [1280/1692 (75.47%)]\t\tLoss: 0.80232\n",
            "Training Progress: \tEpoch 50 [1600/1692 (94.34%)]\t\tLoss: 0.95620\n",
            "\tTrain loss: 0.01889, Accuracy: 1445/1692 (85.40%)\n",
            "\tValidation loss: 0.00338, Accuracy: 128/423 (30.26%)\n",
            "\tTest loss: 0.00339, Accuracy: 130/443 (29.35%)\n",
            "\n",
            "Training Progress: \tEpoch 51 [0/1692 (0.00%)]\t\tLoss: 0.89505\n",
            "Training Progress: \tEpoch 51 [320/1692 (18.87%)]\t\tLoss: 1.04054\n",
            "Training Progress: \tEpoch 51 [640/1692 (37.74%)]\t\tLoss: 0.87627\n",
            "Training Progress: \tEpoch 51 [960/1692 (56.60%)]\t\tLoss: 0.83227\n",
            "Training Progress: \tEpoch 51 [1280/1692 (75.47%)]\t\tLoss: 0.74294\n",
            "Training Progress: \tEpoch 51 [1600/1692 (94.34%)]\t\tLoss: 0.86182\n",
            "\tTrain loss: 0.01814, Accuracy: 1456/1692 (86.05%)\n",
            "\tValidation loss: 0.00350, Accuracy: 137/423 (32.39%)\n",
            "\tTest loss: 0.00341, Accuracy: 127/443 (28.67%)\n",
            "\n",
            "Training Progress: \tEpoch 52 [0/1692 (0.00%)]\t\tLoss: 0.73717\n",
            "Training Progress: \tEpoch 52 [320/1692 (18.87%)]\t\tLoss: 0.83671\n",
            "Training Progress: \tEpoch 52 [640/1692 (37.74%)]\t\tLoss: 0.72248\n",
            "Training Progress: \tEpoch 52 [960/1692 (56.60%)]\t\tLoss: 0.80080\n",
            "Training Progress: \tEpoch 52 [1280/1692 (75.47%)]\t\tLoss: 0.69367\n",
            "Training Progress: \tEpoch 52 [1600/1692 (94.34%)]\t\tLoss: 0.84148\n",
            "\tTrain loss: 0.01733, Accuracy: 1460/1692 (86.29%)\n",
            "\tValidation loss: 0.00354, Accuracy: 129/423 (30.50%)\n",
            "\tTest loss: 0.00342, Accuracy: 128/443 (28.89%)\n",
            "\n",
            "Training Progress: \tEpoch 53 [0/1692 (0.00%)]\t\tLoss: 0.92266\n",
            "Training Progress: \tEpoch 53 [320/1692 (18.87%)]\t\tLoss: 0.97260\n",
            "Training Progress: \tEpoch 53 [640/1692 (37.74%)]\t\tLoss: 0.61830\n",
            "Training Progress: \tEpoch 53 [960/1692 (56.60%)]\t\tLoss: 0.81448\n",
            "Training Progress: \tEpoch 53 [1280/1692 (75.47%)]\t\tLoss: 0.82049\n",
            "Training Progress: \tEpoch 53 [1600/1692 (94.34%)]\t\tLoss: 0.72059\n",
            "\tTrain loss: 0.01566, Accuracy: 1508/1692 (89.13%)\n",
            "\tValidation loss: 0.00354, Accuracy: 137/423 (32.39%)\n",
            "\tTest loss: 0.00355, Accuracy: 119/443 (26.86%)\n",
            "\n",
            "Training Progress: \tEpoch 54 [0/1692 (0.00%)]\t\tLoss: 0.70821\n",
            "Training Progress: \tEpoch 54 [320/1692 (18.87%)]\t\tLoss: 0.67334\n",
            "Training Progress: \tEpoch 54 [640/1692 (37.74%)]\t\tLoss: 1.05589\n",
            "Training Progress: \tEpoch 54 [960/1692 (56.60%)]\t\tLoss: 0.89450\n",
            "Training Progress: \tEpoch 54 [1280/1692 (75.47%)]\t\tLoss: 0.88572\n",
            "Training Progress: \tEpoch 54 [1600/1692 (94.34%)]\t\tLoss: 0.80751\n",
            "\tTrain loss: 0.01504, Accuracy: 1514/1692 (89.48%)\n",
            "\tValidation loss: 0.00365, Accuracy: 135/423 (31.91%)\n",
            "\tTest loss: 0.00363, Accuracy: 126/443 (28.44%)\n",
            "\n",
            "Training Progress: \tEpoch 55 [0/1692 (0.00%)]\t\tLoss: 0.91052\n",
            "Training Progress: \tEpoch 55 [320/1692 (18.87%)]\t\tLoss: 0.73319\n",
            "Training Progress: \tEpoch 55 [640/1692 (37.74%)]\t\tLoss: 0.91350\n",
            "Training Progress: \tEpoch 55 [960/1692 (56.60%)]\t\tLoss: 0.85390\n",
            "Training Progress: \tEpoch 55 [1280/1692 (75.47%)]\t\tLoss: 0.58563\n",
            "Training Progress: \tEpoch 55 [1600/1692 (94.34%)]\t\tLoss: 0.63392\n",
            "\tTrain loss: 0.01463, Accuracy: 1504/1692 (88.89%)\n",
            "\tValidation loss: 0.00366, Accuracy: 138/423 (32.62%)\n",
            "\tTest loss: 0.00373, Accuracy: 120/443 (27.09%)\n",
            "\n",
            "Training Progress: \tEpoch 56 [0/1692 (0.00%)]\t\tLoss: 0.76506\n",
            "Training Progress: \tEpoch 56 [320/1692 (18.87%)]\t\tLoss: 0.63408\n",
            "Training Progress: \tEpoch 56 [640/1692 (37.74%)]\t\tLoss: 0.85816\n",
            "Training Progress: \tEpoch 56 [960/1692 (56.60%)]\t\tLoss: 0.66130\n",
            "Training Progress: \tEpoch 56 [1280/1692 (75.47%)]\t\tLoss: 0.77794\n",
            "Training Progress: \tEpoch 56 [1600/1692 (94.34%)]\t\tLoss: 0.77876\n",
            "\tTrain loss: 0.01274, Accuracy: 1538/1692 (90.90%)\n",
            "\tValidation loss: 0.00369, Accuracy: 134/423 (31.68%)\n",
            "\tTest loss: 0.00374, Accuracy: 125/443 (28.22%)\n",
            "\n",
            "Training Progress: \tEpoch 57 [0/1692 (0.00%)]\t\tLoss: 0.69429\n",
            "Training Progress: \tEpoch 57 [320/1692 (18.87%)]\t\tLoss: 0.65369\n",
            "Training Progress: \tEpoch 57 [640/1692 (37.74%)]\t\tLoss: 0.55845\n",
            "Training Progress: \tEpoch 57 [960/1692 (56.60%)]\t\tLoss: 0.92185\n",
            "Training Progress: \tEpoch 57 [1280/1692 (75.47%)]\t\tLoss: 0.59830\n",
            "Training Progress: \tEpoch 57 [1600/1692 (94.34%)]\t\tLoss: 0.63125\n",
            "\tTrain loss: 0.01094, Accuracy: 1570/1692 (92.79%)\n",
            "\tValidation loss: 0.00378, Accuracy: 140/423 (33.10%)\n",
            "\tTest loss: 0.00377, Accuracy: 128/443 (28.89%)\n",
            "\n",
            "Training Progress: \tEpoch 58 [0/1692 (0.00%)]\t\tLoss: 0.72856\n",
            "Training Progress: \tEpoch 58 [320/1692 (18.87%)]\t\tLoss: 0.74222\n",
            "Training Progress: \tEpoch 58 [640/1692 (37.74%)]\t\tLoss: 0.90914\n",
            "Training Progress: \tEpoch 58 [960/1692 (56.60%)]\t\tLoss: 0.83755\n",
            "Training Progress: \tEpoch 58 [1280/1692 (75.47%)]\t\tLoss: 0.75407\n",
            "Training Progress: \tEpoch 58 [1600/1692 (94.34%)]\t\tLoss: 0.51133\n",
            "\tTrain loss: 0.01019, Accuracy: 1592/1692 (94.09%)\n",
            "\tValidation loss: 0.00389, Accuracy: 135/423 (31.91%)\n",
            "\tTest loss: 0.00378, Accuracy: 133/443 (30.02%)\n",
            "\n",
            "Training Progress: \tEpoch 59 [0/1692 (0.00%)]\t\tLoss: 0.78709\n",
            "Training Progress: \tEpoch 59 [320/1692 (18.87%)]\t\tLoss: 0.81314\n",
            "Training Progress: \tEpoch 59 [640/1692 (37.74%)]\t\tLoss: 0.81160\n",
            "Training Progress: \tEpoch 59 [960/1692 (56.60%)]\t\tLoss: 0.83313\n",
            "Training Progress: \tEpoch 59 [1280/1692 (75.47%)]\t\tLoss: 0.58977\n",
            "Training Progress: \tEpoch 59 [1600/1692 (94.34%)]\t\tLoss: 0.45195\n",
            "\tTrain loss: 0.00894, Accuracy: 1621/1692 (95.80%)\n",
            "\tValidation loss: 0.00378, Accuracy: 144/423 (34.04%)\n",
            "\tTest loss: 0.00386, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 60 [0/1692 (0.00%)]\t\tLoss: 0.51312\n",
            "Training Progress: \tEpoch 60 [320/1692 (18.87%)]\t\tLoss: 0.70445\n",
            "Training Progress: \tEpoch 60 [640/1692 (37.74%)]\t\tLoss: 0.68168\n",
            "Training Progress: \tEpoch 60 [960/1692 (56.60%)]\t\tLoss: 0.72013\n",
            "Training Progress: \tEpoch 60 [1280/1692 (75.47%)]\t\tLoss: 0.69488\n",
            "Training Progress: \tEpoch 60 [1600/1692 (94.34%)]\t\tLoss: 0.74444\n",
            "\tTrain loss: 0.00913, Accuracy: 1610/1692 (95.15%)\n",
            "\tValidation loss: 0.00392, Accuracy: 145/423 (34.28%)\n",
            "\tTest loss: 0.00385, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 61 [0/1692 (0.00%)]\t\tLoss: 0.60614\n",
            "Training Progress: \tEpoch 61 [320/1692 (18.87%)]\t\tLoss: 0.65679\n",
            "Training Progress: \tEpoch 61 [640/1692 (37.74%)]\t\tLoss: 0.48977\n",
            "Training Progress: \tEpoch 61 [960/1692 (56.60%)]\t\tLoss: 0.82219\n",
            "Training Progress: \tEpoch 61 [1280/1692 (75.47%)]\t\tLoss: 0.66038\n",
            "Training Progress: \tEpoch 61 [1600/1692 (94.34%)]\t\tLoss: 0.40158\n",
            "\tTrain loss: 0.00773, Accuracy: 1611/1692 (95.21%)\n",
            "\tValidation loss: 0.00402, Accuracy: 140/423 (33.10%)\n",
            "\tTest loss: 0.00399, Accuracy: 126/443 (28.44%)\n",
            "\n",
            "Training Progress: \tEpoch 62 [0/1692 (0.00%)]\t\tLoss: 0.60233\n",
            "Training Progress: \tEpoch 62 [320/1692 (18.87%)]\t\tLoss: 0.53667\n",
            "Training Progress: \tEpoch 62 [640/1692 (37.74%)]\t\tLoss: 0.55678\n",
            "Training Progress: \tEpoch 62 [960/1692 (56.60%)]\t\tLoss: 0.54603\n",
            "Training Progress: \tEpoch 62 [1280/1692 (75.47%)]\t\tLoss: 0.71465\n",
            "Training Progress: \tEpoch 62 [1600/1692 (94.34%)]\t\tLoss: 0.31562\n",
            "\tTrain loss: 0.00753, Accuracy: 1631/1692 (96.39%)\n",
            "\tValidation loss: 0.00393, Accuracy: 138/423 (32.62%)\n",
            "\tTest loss: 0.00396, Accuracy: 136/443 (30.70%)\n",
            "\n",
            "Training Progress: \tEpoch 63 [0/1692 (0.00%)]\t\tLoss: 0.66729\n",
            "Training Progress: \tEpoch 63 [320/1692 (18.87%)]\t\tLoss: 0.33229\n",
            "Training Progress: \tEpoch 63 [640/1692 (37.74%)]\t\tLoss: 0.45772\n",
            "Training Progress: \tEpoch 63 [960/1692 (56.60%)]\t\tLoss: 0.71214\n",
            "Training Progress: \tEpoch 63 [1280/1692 (75.47%)]\t\tLoss: 0.64823\n",
            "Training Progress: \tEpoch 63 [1600/1692 (94.34%)]\t\tLoss: 0.60403\n",
            "\tTrain loss: 0.00743, Accuracy: 1638/1692 (96.81%)\n",
            "\tValidation loss: 0.00389, Accuracy: 135/423 (31.91%)\n",
            "\tTest loss: 0.00402, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 64 [0/1692 (0.00%)]\t\tLoss: 0.55361\n",
            "Training Progress: \tEpoch 64 [320/1692 (18.87%)]\t\tLoss: 0.56743\n",
            "Training Progress: \tEpoch 64 [640/1692 (37.74%)]\t\tLoss: 0.58926\n",
            "Training Progress: \tEpoch 64 [960/1692 (56.60%)]\t\tLoss: 0.68952\n",
            "Training Progress: \tEpoch 64 [1280/1692 (75.47%)]\t\tLoss: 0.45717\n",
            "Training Progress: \tEpoch 64 [1600/1692 (94.34%)]\t\tLoss: 0.44125\n",
            "\tTrain loss: 0.00627, Accuracy: 1642/1692 (97.04%)\n",
            "\tValidation loss: 0.00419, Accuracy: 146/423 (34.52%)\n",
            "\tTest loss: 0.00413, Accuracy: 129/443 (29.12%)\n",
            "\n",
            "Training Progress: \tEpoch 65 [0/1692 (0.00%)]\t\tLoss: 0.82490\n",
            "Training Progress: \tEpoch 65 [320/1692 (18.87%)]\t\tLoss: 0.39433\n",
            "Training Progress: \tEpoch 65 [640/1692 (37.74%)]\t\tLoss: 0.46016\n",
            "Training Progress: \tEpoch 65 [960/1692 (56.60%)]\t\tLoss: 0.56026\n",
            "Training Progress: \tEpoch 65 [1280/1692 (75.47%)]\t\tLoss: 0.60933\n",
            "Training Progress: \tEpoch 65 [1600/1692 (94.34%)]\t\tLoss: 0.47872\n",
            "\tTrain loss: 0.00577, Accuracy: 1637/1692 (96.75%)\n",
            "\tValidation loss: 0.00423, Accuracy: 144/423 (34.04%)\n",
            "\tTest loss: 0.00424, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 66 [0/1692 (0.00%)]\t\tLoss: 0.59734\n",
            "Training Progress: \tEpoch 66 [320/1692 (18.87%)]\t\tLoss: 0.54362\n",
            "Training Progress: \tEpoch 66 [640/1692 (37.74%)]\t\tLoss: 0.57719\n",
            "Training Progress: \tEpoch 66 [960/1692 (56.60%)]\t\tLoss: 0.61497\n",
            "Training Progress: \tEpoch 66 [1280/1692 (75.47%)]\t\tLoss: 0.34282\n",
            "Training Progress: \tEpoch 66 [1600/1692 (94.34%)]\t\tLoss: 0.42842\n",
            "\tTrain loss: 0.00502, Accuracy: 1652/1692 (97.64%)\n",
            "\tValidation loss: 0.00427, Accuracy: 135/423 (31.91%)\n",
            "\tTest loss: 0.00422, Accuracy: 134/443 (30.25%)\n",
            "\n",
            "Training Progress: \tEpoch 67 [0/1692 (0.00%)]\t\tLoss: 0.68181\n",
            "Training Progress: \tEpoch 67 [320/1692 (18.87%)]\t\tLoss: 0.57684\n",
            "Training Progress: \tEpoch 67 [640/1692 (37.74%)]\t\tLoss: 0.52297\n",
            "Training Progress: \tEpoch 67 [960/1692 (56.60%)]\t\tLoss: 0.62808\n",
            "Training Progress: \tEpoch 67 [1280/1692 (75.47%)]\t\tLoss: 0.57685\n",
            "Training Progress: \tEpoch 67 [1600/1692 (94.34%)]\t\tLoss: 0.48721\n",
            "\tTrain loss: 0.00551, Accuracy: 1655/1692 (97.81%)\n",
            "\tValidation loss: 0.00428, Accuracy: 140/423 (33.10%)\n",
            "\tTest loss: 0.00431, Accuracy: 120/443 (27.09%)\n",
            "\n",
            "Training Progress: \tEpoch 68 [0/1692 (0.00%)]\t\tLoss: 0.54196\n",
            "Training Progress: \tEpoch 68 [320/1692 (18.87%)]\t\tLoss: 0.68107\n",
            "Training Progress: \tEpoch 68 [640/1692 (37.74%)]\t\tLoss: 0.47428\n",
            "Training Progress: \tEpoch 68 [960/1692 (56.60%)]\t\tLoss: 0.40075\n",
            "Training Progress: \tEpoch 68 [1280/1692 (75.47%)]\t\tLoss: 0.55378\n",
            "Training Progress: \tEpoch 68 [1600/1692 (94.34%)]\t\tLoss: 0.27749\n",
            "\tTrain loss: 0.00449, Accuracy: 1660/1692 (98.11%)\n",
            "\tValidation loss: 0.00437, Accuracy: 138/423 (32.62%)\n",
            "\tTest loss: 0.00435, Accuracy: 128/443 (28.89%)\n",
            "\n",
            "Training Progress: \tEpoch 69 [0/1692 (0.00%)]\t\tLoss: 0.44598\n",
            "Training Progress: \tEpoch 69 [320/1692 (18.87%)]\t\tLoss: 0.63352\n",
            "Training Progress: \tEpoch 69 [640/1692 (37.74%)]\t\tLoss: 0.57796\n",
            "Training Progress: \tEpoch 69 [960/1692 (56.60%)]\t\tLoss: 0.61507\n",
            "Training Progress: \tEpoch 69 [1280/1692 (75.47%)]\t\tLoss: 0.42910\n",
            "Training Progress: \tEpoch 69 [1600/1692 (94.34%)]\t\tLoss: 0.24285\n",
            "\tTrain loss: 0.00418, Accuracy: 1672/1692 (98.82%)\n",
            "\tValidation loss: 0.00440, Accuracy: 135/423 (31.91%)\n",
            "\tTest loss: 0.00435, Accuracy: 123/443 (27.77%)\n",
            "\n",
            "Training Progress: \tEpoch 70 [0/1692 (0.00%)]\t\tLoss: 0.50157\n",
            "Training Progress: \tEpoch 70 [320/1692 (18.87%)]\t\tLoss: 0.37460\n",
            "Training Progress: \tEpoch 70 [640/1692 (37.74%)]\t\tLoss: 0.48558\n",
            "Training Progress: \tEpoch 70 [960/1692 (56.60%)]\t\tLoss: 0.41736\n",
            "Training Progress: \tEpoch 70 [1280/1692 (75.47%)]\t\tLoss: 0.39223\n",
            "Training Progress: \tEpoch 70 [1600/1692 (94.34%)]\t\tLoss: 0.22437\n",
            "\tTrain loss: 0.00308, Accuracy: 1675/1692 (99.00%)\n",
            "\tValidation loss: 0.00451, Accuracy: 143/423 (33.81%)\n",
            "\tTest loss: 0.00447, Accuracy: 125/443 (28.22%)\n",
            "\n",
            "Training Progress: \tEpoch 71 [0/1692 (0.00%)]\t\tLoss: 0.33249\n",
            "Training Progress: \tEpoch 71 [320/1692 (18.87%)]\t\tLoss: 0.38376\n",
            "Training Progress: \tEpoch 71 [640/1692 (37.74%)]\t\tLoss: 0.28350\n",
            "Training Progress: \tEpoch 71 [960/1692 (56.60%)]\t\tLoss: 0.74548\n",
            "Training Progress: \tEpoch 71 [1280/1692 (75.47%)]\t\tLoss: 0.32510\n",
            "Training Progress: \tEpoch 71 [1600/1692 (94.34%)]\t\tLoss: 0.40898\n",
            "\tTrain loss: 0.00299, Accuracy: 1675/1692 (99.00%)\n",
            "\tValidation loss: 0.00449, Accuracy: 143/423 (33.81%)\n",
            "\tTest loss: 0.00468, Accuracy: 120/443 (27.09%)\n",
            "\n",
            "Training Progress: \tEpoch 72 [0/1692 (0.00%)]\t\tLoss: 0.28609\n",
            "Training Progress: \tEpoch 72 [320/1692 (18.87%)]\t\tLoss: 0.31752\n",
            "Training Progress: \tEpoch 72 [640/1692 (37.74%)]\t\tLoss: 0.28736\n",
            "Training Progress: \tEpoch 72 [960/1692 (56.60%)]\t\tLoss: 0.32550\n",
            "Training Progress: \tEpoch 72 [1280/1692 (75.47%)]\t\tLoss: 0.38530\n",
            "Training Progress: \tEpoch 72 [1600/1692 (94.34%)]\t\tLoss: 0.28778\n",
            "\tTrain loss: 0.00293, Accuracy: 1677/1692 (99.11%)\n",
            "\tValidation loss: 0.00450, Accuracy: 154/423 (36.41%)\n",
            "\tTest loss: 0.00455, Accuracy: 125/443 (28.22%)\n",
            "\n",
            "Training Progress: \tEpoch 73 [0/1692 (0.00%)]\t\tLoss: 0.36972\n",
            "Training Progress: \tEpoch 73 [320/1692 (18.87%)]\t\tLoss: 0.48327\n",
            "Training Progress: \tEpoch 73 [640/1692 (37.74%)]\t\tLoss: 0.43828\n",
            "Training Progress: \tEpoch 73 [960/1692 (56.60%)]\t\tLoss: 0.48405\n",
            "Training Progress: \tEpoch 73 [1280/1692 (75.47%)]\t\tLoss: 0.31325\n",
            "Training Progress: \tEpoch 73 [1600/1692 (94.34%)]\t\tLoss: 0.28420\n",
            "\tTrain loss: 0.00263, Accuracy: 1677/1692 (99.11%)\n",
            "\tValidation loss: 0.00453, Accuracy: 138/423 (32.62%)\n",
            "\tTest loss: 0.00470, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 74 [0/1692 (0.00%)]\t\tLoss: 0.32160\n",
            "Training Progress: \tEpoch 74 [320/1692 (18.87%)]\t\tLoss: 0.39315\n",
            "Training Progress: \tEpoch 74 [640/1692 (37.74%)]\t\tLoss: 0.29292\n",
            "Training Progress: \tEpoch 74 [960/1692 (56.60%)]\t\tLoss: 0.34377\n",
            "Training Progress: \tEpoch 74 [1280/1692 (75.47%)]\t\tLoss: 0.28279\n",
            "Training Progress: \tEpoch 74 [1600/1692 (94.34%)]\t\tLoss: 0.21021\n",
            "\tTrain loss: 0.00265, Accuracy: 1675/1692 (99.00%)\n",
            "\tValidation loss: 0.00458, Accuracy: 151/423 (35.70%)\n",
            "\tTest loss: 0.00480, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 75 [0/1692 (0.00%)]\t\tLoss: 0.36170\n",
            "Training Progress: \tEpoch 75 [320/1692 (18.87%)]\t\tLoss: 0.29138\n",
            "Training Progress: \tEpoch 75 [640/1692 (37.74%)]\t\tLoss: 0.43418\n",
            "Training Progress: \tEpoch 75 [960/1692 (56.60%)]\t\tLoss: 0.62626\n",
            "Training Progress: \tEpoch 75 [1280/1692 (75.47%)]\t\tLoss: 0.37340\n",
            "Training Progress: \tEpoch 75 [1600/1692 (94.34%)]\t\tLoss: 0.47305\n",
            "\tTrain loss: 0.00233, Accuracy: 1679/1692 (99.23%)\n",
            "\tValidation loss: 0.00448, Accuracy: 147/423 (34.75%)\n",
            "\tTest loss: 0.00481, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 76 [0/1692 (0.00%)]\t\tLoss: 0.22735\n",
            "Training Progress: \tEpoch 76 [320/1692 (18.87%)]\t\tLoss: 0.29169\n",
            "Training Progress: \tEpoch 76 [640/1692 (37.74%)]\t\tLoss: 0.35481\n",
            "Training Progress: \tEpoch 76 [960/1692 (56.60%)]\t\tLoss: 0.21857\n",
            "Training Progress: \tEpoch 76 [1280/1692 (75.47%)]\t\tLoss: 0.40388\n",
            "Training Progress: \tEpoch 76 [1600/1692 (94.34%)]\t\tLoss: 0.36315\n",
            "\tTrain loss: 0.00255, Accuracy: 1671/1692 (98.76%)\n",
            "\tValidation loss: 0.00458, Accuracy: 135/423 (31.91%)\n",
            "\tTest loss: 0.00481, Accuracy: 131/443 (29.57%)\n",
            "\n",
            "Training Progress: \tEpoch 77 [0/1692 (0.00%)]\t\tLoss: 0.32891\n",
            "Training Progress: \tEpoch 77 [320/1692 (18.87%)]\t\tLoss: 0.26386\n",
            "Training Progress: \tEpoch 77 [640/1692 (37.74%)]\t\tLoss: 0.26160\n",
            "Training Progress: \tEpoch 77 [960/1692 (56.60%)]\t\tLoss: 0.22745\n",
            "Training Progress: \tEpoch 77 [1280/1692 (75.47%)]\t\tLoss: 0.32672\n",
            "Training Progress: \tEpoch 77 [1600/1692 (94.34%)]\t\tLoss: 0.39775\n",
            "\tTrain loss: 0.00231, Accuracy: 1677/1692 (99.11%)\n",
            "\tValidation loss: 0.00460, Accuracy: 144/423 (34.04%)\n",
            "\tTest loss: 0.00460, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 78 [0/1692 (0.00%)]\t\tLoss: 0.36553\n",
            "Training Progress: \tEpoch 78 [320/1692 (18.87%)]\t\tLoss: 0.45325\n",
            "Training Progress: \tEpoch 78 [640/1692 (37.74%)]\t\tLoss: 0.24233\n",
            "Training Progress: \tEpoch 78 [960/1692 (56.60%)]\t\tLoss: 0.26966\n",
            "Training Progress: \tEpoch 78 [1280/1692 (75.47%)]\t\tLoss: 0.33560\n",
            "Training Progress: \tEpoch 78 [1600/1692 (94.34%)]\t\tLoss: 0.23428\n",
            "\tTrain loss: 0.00194, Accuracy: 1677/1692 (99.11%)\n",
            "\tValidation loss: 0.00460, Accuracy: 147/423 (34.75%)\n",
            "\tTest loss: 0.00490, Accuracy: 124/443 (27.99%)\n",
            "\n",
            "Training Progress: \tEpoch 79 [0/1692 (0.00%)]\t\tLoss: 0.37133\n",
            "Training Progress: \tEpoch 79 [320/1692 (18.87%)]\t\tLoss: 0.41839\n",
            "Training Progress: \tEpoch 79 [640/1692 (37.74%)]\t\tLoss: 0.40872\n",
            "Training Progress: \tEpoch 79 [960/1692 (56.60%)]\t\tLoss: 0.52624\n",
            "Training Progress: \tEpoch 79 [1280/1692 (75.47%)]\t\tLoss: 0.16171\n",
            "Training Progress: \tEpoch 79 [1600/1692 (94.34%)]\t\tLoss: 0.32269\n",
            "\tTrain loss: 0.00170, Accuracy: 1682/1692 (99.41%)\n",
            "\tValidation loss: 0.00474, Accuracy: 149/423 (35.22%)\n",
            "\tTest loss: 0.00502, Accuracy: 124/443 (27.99%)\n",
            "\n",
            "Training Progress: \tEpoch 80 [0/1692 (0.00%)]\t\tLoss: 0.26713\n",
            "Training Progress: \tEpoch 80 [320/1692 (18.87%)]\t\tLoss: 0.51393\n",
            "Training Progress: \tEpoch 80 [640/1692 (37.74%)]\t\tLoss: 0.44480\n",
            "Training Progress: \tEpoch 80 [960/1692 (56.60%)]\t\tLoss: 0.25504\n",
            "Training Progress: \tEpoch 80 [1280/1692 (75.47%)]\t\tLoss: 0.25600\n",
            "Training Progress: \tEpoch 80 [1600/1692 (94.34%)]\t\tLoss: 0.23539\n",
            "\tTrain loss: 0.00183, Accuracy: 1681/1692 (99.35%)\n",
            "\tValidation loss: 0.00458, Accuracy: 149/423 (35.22%)\n",
            "\tTest loss: 0.00476, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 81 [0/1692 (0.00%)]\t\tLoss: 0.32335\n",
            "Training Progress: \tEpoch 81 [320/1692 (18.87%)]\t\tLoss: 0.18136\n",
            "Training Progress: \tEpoch 81 [640/1692 (37.74%)]\t\tLoss: 0.42886\n",
            "Training Progress: \tEpoch 81 [960/1692 (56.60%)]\t\tLoss: 0.42162\n",
            "Training Progress: \tEpoch 81 [1280/1692 (75.47%)]\t\tLoss: 0.36529\n",
            "Training Progress: \tEpoch 81 [1600/1692 (94.34%)]\t\tLoss: 0.19337\n",
            "\tTrain loss: 0.00157, Accuracy: 1687/1692 (99.70%)\n",
            "\tValidation loss: 0.00469, Accuracy: 147/423 (34.75%)\n",
            "\tTest loss: 0.00482, Accuracy: 132/443 (29.80%)\n",
            "\n",
            "Training Progress: \tEpoch 82 [0/1692 (0.00%)]\t\tLoss: 0.36939\n",
            "Training Progress: \tEpoch 82 [320/1692 (18.87%)]\t\tLoss: 0.24646\n",
            "Training Progress: \tEpoch 82 [640/1692 (37.74%)]\t\tLoss: 0.17170\n",
            "Training Progress: \tEpoch 82 [960/1692 (56.60%)]\t\tLoss: 0.31527\n",
            "Training Progress: \tEpoch 82 [1280/1692 (75.47%)]\t\tLoss: 0.33835\n",
            "Training Progress: \tEpoch 82 [1600/1692 (94.34%)]\t\tLoss: 0.16431\n",
            "\tTrain loss: 0.00157, Accuracy: 1684/1692 (99.53%)\n",
            "\tValidation loss: 0.00479, Accuracy: 144/423 (34.04%)\n",
            "\tTest loss: 0.00494, Accuracy: 128/443 (28.89%)\n",
            "\n",
            "Training Progress: \tEpoch 83 [0/1692 (0.00%)]\t\tLoss: 0.51756\n",
            "Training Progress: \tEpoch 83 [320/1692 (18.87%)]\t\tLoss: 0.23677\n",
            "Training Progress: \tEpoch 83 [640/1692 (37.74%)]\t\tLoss: 0.59563\n",
            "Training Progress: \tEpoch 83 [960/1692 (56.60%)]\t\tLoss: 0.24893\n",
            "Training Progress: \tEpoch 83 [1280/1692 (75.47%)]\t\tLoss: 0.32985\n",
            "Training Progress: \tEpoch 83 [1600/1692 (94.34%)]\t\tLoss: 0.28229\n",
            "\tTrain loss: 0.00149, Accuracy: 1685/1692 (99.59%)\n",
            "\tValidation loss: 0.00481, Accuracy: 144/423 (34.04%)\n",
            "\tTest loss: 0.00493, Accuracy: 119/443 (26.86%)\n",
            "\n",
            "Training Progress: \tEpoch 84 [0/1692 (0.00%)]\t\tLoss: 0.20807\n",
            "Training Progress: \tEpoch 84 [320/1692 (18.87%)]\t\tLoss: 0.23273\n",
            "Training Progress: \tEpoch 84 [640/1692 (37.74%)]\t\tLoss: 0.17751\n",
            "Training Progress: \tEpoch 84 [960/1692 (56.60%)]\t\tLoss: 0.42391\n",
            "Training Progress: \tEpoch 84 [1280/1692 (75.47%)]\t\tLoss: 0.22119\n",
            "Training Progress: \tEpoch 84 [1600/1692 (94.34%)]\t\tLoss: 0.34342\n",
            "\tTrain loss: 0.00141, Accuracy: 1685/1692 (99.59%)\n",
            "\tValidation loss: 0.00476, Accuracy: 143/423 (33.81%)\n",
            "\tTest loss: 0.00487, Accuracy: 127/443 (28.67%)\n",
            "\n",
            "Training Progress: \tEpoch 85 [0/1692 (0.00%)]\t\tLoss: 0.20138\n",
            "Training Progress: \tEpoch 85 [320/1692 (18.87%)]\t\tLoss: 0.28544\n",
            "Training Progress: \tEpoch 85 [640/1692 (37.74%)]\t\tLoss: 0.26156\n",
            "Training Progress: \tEpoch 85 [960/1692 (56.60%)]\t\tLoss: 0.47317\n",
            "Training Progress: \tEpoch 85 [1280/1692 (75.47%)]\t\tLoss: 0.25624\n",
            "Training Progress: \tEpoch 85 [1600/1692 (94.34%)]\t\tLoss: 0.22170\n",
            "\tTrain loss: 0.00144, Accuracy: 1688/1692 (99.76%)\n",
            "\tValidation loss: 0.00482, Accuracy: 141/423 (33.33%)\n",
            "\tTest loss: 0.00496, Accuracy: 130/443 (29.35%)\n",
            "\n",
            "Training Progress: \tEpoch 86 [0/1692 (0.00%)]\t\tLoss: 0.31886\n",
            "Training Progress: \tEpoch 86 [320/1692 (18.87%)]\t\tLoss: 0.16944\n",
            "Training Progress: \tEpoch 86 [640/1692 (37.74%)]\t\tLoss: 0.39273\n",
            "Training Progress: \tEpoch 86 [960/1692 (56.60%)]\t\tLoss: 0.46771\n",
            "Training Progress: \tEpoch 86 [1280/1692 (75.47%)]\t\tLoss: 0.16463\n",
            "Training Progress: \tEpoch 86 [1600/1692 (94.34%)]\t\tLoss: 0.15150\n",
            "\tTrain loss: 0.00120, Accuracy: 1684/1692 (99.53%)\n",
            "\tValidation loss: 0.00489, Accuracy: 142/423 (33.57%)\n",
            "\tTest loss: 0.00510, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 87 [0/1692 (0.00%)]\t\tLoss: 0.32194\n",
            "Training Progress: \tEpoch 87 [320/1692 (18.87%)]\t\tLoss: 0.47974\n",
            "Training Progress: \tEpoch 87 [640/1692 (37.74%)]\t\tLoss: 0.32834\n",
            "Training Progress: \tEpoch 87 [960/1692 (56.60%)]\t\tLoss: 0.34656\n",
            "Training Progress: \tEpoch 87 [1280/1692 (75.47%)]\t\tLoss: 0.20875\n",
            "Training Progress: \tEpoch 87 [1600/1692 (94.34%)]\t\tLoss: 0.15243\n",
            "\tTrain loss: 0.00132, Accuracy: 1687/1692 (99.70%)\n",
            "\tValidation loss: 0.00469, Accuracy: 148/423 (34.99%)\n",
            "\tTest loss: 0.00498, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 88 [0/1692 (0.00%)]\t\tLoss: 0.47568\n",
            "Training Progress: \tEpoch 88 [320/1692 (18.87%)]\t\tLoss: 0.27800\n",
            "Training Progress: \tEpoch 88 [640/1692 (37.74%)]\t\tLoss: 0.19481\n",
            "Training Progress: \tEpoch 88 [960/1692 (56.60%)]\t\tLoss: 0.16228\n",
            "Training Progress: \tEpoch 88 [1280/1692 (75.47%)]\t\tLoss: 0.28015\n",
            "Training Progress: \tEpoch 88 [1600/1692 (94.34%)]\t\tLoss: 0.39096\n",
            "\tTrain loss: 0.00114, Accuracy: 1685/1692 (99.59%)\n",
            "\tValidation loss: 0.00502, Accuracy: 141/423 (33.33%)\n",
            "\tTest loss: 0.00521, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 89 [0/1692 (0.00%)]\t\tLoss: 0.25881\n",
            "Training Progress: \tEpoch 89 [320/1692 (18.87%)]\t\tLoss: 0.30214\n",
            "Training Progress: \tEpoch 89 [640/1692 (37.74%)]\t\tLoss: 0.15996\n",
            "Training Progress: \tEpoch 89 [960/1692 (56.60%)]\t\tLoss: 0.39762\n",
            "Training Progress: \tEpoch 89 [1280/1692 (75.47%)]\t\tLoss: 0.15246\n",
            "Training Progress: \tEpoch 89 [1600/1692 (94.34%)]\t\tLoss: 0.13233\n",
            "\tTrain loss: 0.00094, Accuracy: 1690/1692 (99.88%)\n",
            "\tValidation loss: 0.00475, Accuracy: 154/423 (36.41%)\n",
            "\tTest loss: 0.00509, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 90 [0/1692 (0.00%)]\t\tLoss: 0.21123\n",
            "Training Progress: \tEpoch 90 [320/1692 (18.87%)]\t\tLoss: 0.27586\n",
            "Training Progress: \tEpoch 90 [640/1692 (37.74%)]\t\tLoss: 0.21654\n",
            "Training Progress: \tEpoch 90 [960/1692 (56.60%)]\t\tLoss: 0.17206\n",
            "Training Progress: \tEpoch 90 [1280/1692 (75.47%)]\t\tLoss: 0.33368\n",
            "Training Progress: \tEpoch 90 [1600/1692 (94.34%)]\t\tLoss: 0.10635\n",
            "\tTrain loss: 0.00119, Accuracy: 1686/1692 (99.65%)\n",
            "\tValidation loss: 0.00486, Accuracy: 147/423 (34.75%)\n",
            "\tTest loss: 0.00508, Accuracy: 129/443 (29.12%)\n",
            "\n",
            "Training Progress: \tEpoch 91 [0/1692 (0.00%)]\t\tLoss: 0.36252\n",
            "Training Progress: \tEpoch 91 [320/1692 (18.87%)]\t\tLoss: 0.23456\n",
            "Training Progress: \tEpoch 91 [640/1692 (37.74%)]\t\tLoss: 0.34871\n",
            "Training Progress: \tEpoch 91 [960/1692 (56.60%)]\t\tLoss: 0.22771\n",
            "Training Progress: \tEpoch 91 [1280/1692 (75.47%)]\t\tLoss: 0.14771\n",
            "Training Progress: \tEpoch 91 [1600/1692 (94.34%)]\t\tLoss: 0.23615\n",
            "\tTrain loss: 0.00084, Accuracy: 1689/1692 (99.82%)\n",
            "\tValidation loss: 0.00491, Accuracy: 144/423 (34.04%)\n",
            "\tTest loss: 0.00514, Accuracy: 127/443 (28.67%)\n",
            "\n",
            "Training Progress: \tEpoch 92 [0/1692 (0.00%)]\t\tLoss: 0.15657\n",
            "Training Progress: \tEpoch 92 [320/1692 (18.87%)]\t\tLoss: 0.07521\n",
            "Training Progress: \tEpoch 92 [640/1692 (37.74%)]\t\tLoss: 0.17709\n",
            "Training Progress: \tEpoch 92 [960/1692 (56.60%)]\t\tLoss: 0.19011\n",
            "Training Progress: \tEpoch 92 [1280/1692 (75.47%)]\t\tLoss: 0.17631\n",
            "Training Progress: \tEpoch 92 [1600/1692 (94.34%)]\t\tLoss: 0.20547\n",
            "\tTrain loss: 0.00102, Accuracy: 1685/1692 (99.59%)\n",
            "\tValidation loss: 0.00497, Accuracy: 151/423 (35.70%)\n",
            "\tTest loss: 0.00533, Accuracy: 121/443 (27.31%)\n",
            "\n",
            "Training Progress: \tEpoch 93 [0/1692 (0.00%)]\t\tLoss: 0.35563\n",
            "Training Progress: \tEpoch 93 [320/1692 (18.87%)]\t\tLoss: 0.13095\n",
            "Training Progress: \tEpoch 93 [640/1692 (37.74%)]\t\tLoss: 0.30945\n",
            "Training Progress: \tEpoch 93 [960/1692 (56.60%)]\t\tLoss: 0.21837\n",
            "Training Progress: \tEpoch 93 [1280/1692 (75.47%)]\t\tLoss: 0.40992\n",
            "Training Progress: \tEpoch 93 [1600/1692 (94.34%)]\t\tLoss: 0.08154\n",
            "\tTrain loss: 0.00106, Accuracy: 1683/1692 (99.47%)\n",
            "\tValidation loss: 0.00505, Accuracy: 145/423 (34.28%)\n",
            "\tTest loss: 0.00543, Accuracy: 115/443 (25.96%)\n",
            "\n",
            "Training Progress: \tEpoch 94 [0/1692 (0.00%)]\t\tLoss: 0.17590\n",
            "Training Progress: \tEpoch 94 [320/1692 (18.87%)]\t\tLoss: 0.19450\n",
            "Training Progress: \tEpoch 94 [640/1692 (37.74%)]\t\tLoss: 0.10036\n",
            "Training Progress: \tEpoch 94 [960/1692 (56.60%)]\t\tLoss: 0.25421\n",
            "Training Progress: \tEpoch 94 [1280/1692 (75.47%)]\t\tLoss: 0.18876\n",
            "Training Progress: \tEpoch 94 [1600/1692 (94.34%)]\t\tLoss: 0.64514\n",
            "\tTrain loss: 0.00083, Accuracy: 1690/1692 (99.88%)\n",
            "\tValidation loss: 0.00512, Accuracy: 143/423 (33.81%)\n",
            "\tTest loss: 0.00518, Accuracy: 124/443 (27.99%)\n",
            "\n",
            "Training Progress: \tEpoch 95 [0/1692 (0.00%)]\t\tLoss: 0.32737\n",
            "Training Progress: \tEpoch 95 [320/1692 (18.87%)]\t\tLoss: 0.20462\n",
            "Training Progress: \tEpoch 95 [640/1692 (37.74%)]\t\tLoss: 0.31225\n",
            "Training Progress: \tEpoch 95 [960/1692 (56.60%)]\t\tLoss: 0.32379\n",
            "Training Progress: \tEpoch 95 [1280/1692 (75.47%)]\t\tLoss: 0.42136\n",
            "Training Progress: \tEpoch 95 [1600/1692 (94.34%)]\t\tLoss: 0.13622\n",
            "\tTrain loss: 0.00081, Accuracy: 1688/1692 (99.76%)\n",
            "\tValidation loss: 0.00502, Accuracy: 146/423 (34.52%)\n",
            "\tTest loss: 0.00509, Accuracy: 124/443 (27.99%)\n",
            "\n",
            "Training Progress: \tEpoch 96 [0/1692 (0.00%)]\t\tLoss: 0.10509\n",
            "Training Progress: \tEpoch 96 [320/1692 (18.87%)]\t\tLoss: 0.30954\n",
            "Training Progress: \tEpoch 96 [640/1692 (37.74%)]\t\tLoss: 0.16942\n",
            "Training Progress: \tEpoch 96 [960/1692 (56.60%)]\t\tLoss: 0.19097\n",
            "Training Progress: \tEpoch 96 [1280/1692 (75.47%)]\t\tLoss: 0.30059\n",
            "Training Progress: \tEpoch 96 [1600/1692 (94.34%)]\t\tLoss: 0.31252\n",
            "\tTrain loss: 0.00087, Accuracy: 1685/1692 (99.59%)\n",
            "\tValidation loss: 0.00511, Accuracy: 144/423 (34.04%)\n",
            "\tTest loss: 0.00531, Accuracy: 136/443 (30.70%)\n",
            "\n",
            "Training Progress: \tEpoch 97 [0/1692 (0.00%)]\t\tLoss: 0.14777\n",
            "Training Progress: \tEpoch 97 [320/1692 (18.87%)]\t\tLoss: 0.22374\n",
            "Training Progress: \tEpoch 97 [640/1692 (37.74%)]\t\tLoss: 0.30403\n",
            "Training Progress: \tEpoch 97 [960/1692 (56.60%)]\t\tLoss: 0.23969\n",
            "Training Progress: \tEpoch 97 [1280/1692 (75.47%)]\t\tLoss: 0.22328\n",
            "Training Progress: \tEpoch 97 [1600/1692 (94.34%)]\t\tLoss: 0.12088\n",
            "\tTrain loss: 0.00081, Accuracy: 1687/1692 (99.70%)\n",
            "\tValidation loss: 0.00511, Accuracy: 139/423 (32.86%)\n",
            "\tTest loss: 0.00525, Accuracy: 137/443 (30.93%)\n",
            "\n",
            "Training Progress: \tEpoch 98 [0/1692 (0.00%)]\t\tLoss: 0.25529\n",
            "Training Progress: \tEpoch 98 [320/1692 (18.87%)]\t\tLoss: 0.45364\n",
            "Training Progress: \tEpoch 98 [640/1692 (37.74%)]\t\tLoss: 0.11946\n",
            "Training Progress: \tEpoch 98 [960/1692 (56.60%)]\t\tLoss: 0.17651\n",
            "Training Progress: \tEpoch 98 [1280/1692 (75.47%)]\t\tLoss: 0.26787\n",
            "Training Progress: \tEpoch 98 [1600/1692 (94.34%)]\t\tLoss: 0.07769\n",
            "\tTrain loss: 0.00086, Accuracy: 1687/1692 (99.70%)\n",
            "\tValidation loss: 0.00511, Accuracy: 134/423 (31.68%)\n",
            "\tTest loss: 0.00518, Accuracy: 138/443 (31.15%)\n",
            "\n",
            "Training Progress: \tEpoch 99 [0/1692 (0.00%)]\t\tLoss: 0.17061\n",
            "Training Progress: \tEpoch 99 [320/1692 (18.87%)]\t\tLoss: 0.20517\n",
            "Training Progress: \tEpoch 99 [640/1692 (37.74%)]\t\tLoss: 0.06044\n",
            "Training Progress: \tEpoch 99 [960/1692 (56.60%)]\t\tLoss: 0.24068\n",
            "Training Progress: \tEpoch 99 [1280/1692 (75.47%)]\t\tLoss: 0.27438\n",
            "Training Progress: \tEpoch 99 [1600/1692 (94.34%)]\t\tLoss: 0.28786\n",
            "\tTrain loss: 0.00086, Accuracy: 1686/1692 (99.65%)\n",
            "\tValidation loss: 0.00526, Accuracy: 141/423 (33.33%)\n",
            "\tTest loss: 0.00530, Accuracy: 130/443 (29.35%)\n",
            "\n",
            "Training Progress: \tEpoch 100 [0/1692 (0.00%)]\t\tLoss: 0.47624\n",
            "Training Progress: \tEpoch 100 [320/1692 (18.87%)]\t\tLoss: 0.43219\n",
            "Training Progress: \tEpoch 100 [640/1692 (37.74%)]\t\tLoss: 0.14810\n",
            "Training Progress: \tEpoch 100 [960/1692 (56.60%)]\t\tLoss: 0.15838\n",
            "Training Progress: \tEpoch 100 [1280/1692 (75.47%)]\t\tLoss: 0.31730\n",
            "Training Progress: \tEpoch 100 [1600/1692 (94.34%)]\t\tLoss: 0.23828\n",
            "\tTrain loss: 0.00065, Accuracy: 1689/1692 (99.82%)\n",
            "\tValidation loss: 0.00507, Accuracy: 139/423 (32.86%)\n",
            "\tTest loss: 0.00534, Accuracy: 127/443 (28.67%)\n",
            "\n",
            "Best validation accuracy:\n",
            "0.3640661938534279\n",
            "Best test accuracy:\n",
            "0.3792325056433409\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAEICAYAAACd/8f0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGIZhGBGAOWzDMAzDiAD+H1gxfSJhOSjiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h_GG9B5Ce--K"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AKxCuSYb1i6",
        "outputId": "0ca32b74-9c61-489e-a5c1-ee2d1ecc56db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = LSTM().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=BETAS, eps=EPS, weight_decay=DECAY)\n",
        "train_and_evaluate(model, optimizer, data_loaders, num_epochs=EPOCHS)\n",
        "del model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Progress: \tEpoch 1 [0/1692 (0.00%)]\t\tLoss: 1.48269\n",
            "Training Progress: \tEpoch 1 [320/1692 (18.87%)]\t\tLoss: 1.42255\n",
            "Training Progress: \tEpoch 1 [640/1692 (37.74%)]\t\tLoss: 1.41290\n",
            "Training Progress: \tEpoch 1 [960/1692 (56.60%)]\t\tLoss: 1.37290\n",
            "Training Progress: \tEpoch 1 [1280/1692 (75.47%)]\t\tLoss: 1.40694\n",
            "Training Progress: \tEpoch 1 [1600/1692 (94.34%)]\t\tLoss: 1.49067\n",
            "\tTrain loss: 0.04342, Accuracy: 451/1692 (26.65%)\n",
            "\tValidation loss: 0.00332, Accuracy: 89/423 (21.04%)\n",
            "\tTest loss: 0.00315, Accuracy: 102/443 (23.02%)\n",
            "\n",
            "Training Progress: \tEpoch 2 [0/1692 (0.00%)]\t\tLoss: 1.46186\n",
            "Training Progress: \tEpoch 2 [320/1692 (18.87%)]\t\tLoss: 1.38992\n",
            "Training Progress: \tEpoch 2 [640/1692 (37.74%)]\t\tLoss: 1.39906\n",
            "Training Progress: \tEpoch 2 [960/1692 (56.60%)]\t\tLoss: 1.35079\n",
            "Training Progress: \tEpoch 2 [1280/1692 (75.47%)]\t\tLoss: 1.44760\n",
            "Training Progress: \tEpoch 2 [1600/1692 (94.34%)]\t\tLoss: 1.46715\n",
            "\tTrain loss: 0.04317, Accuracy: 479/1692 (28.31%)\n",
            "\tValidation loss: 0.00331, Accuracy: 90/423 (21.28%)\n",
            "\tTest loss: 0.00314, Accuracy: 98/443 (22.12%)\n",
            "\n",
            "Training Progress: \tEpoch 3 [0/1692 (0.00%)]\t\tLoss: 1.40115\n",
            "Training Progress: \tEpoch 3 [320/1692 (18.87%)]\t\tLoss: 1.34802\n",
            "Training Progress: \tEpoch 3 [640/1692 (37.74%)]\t\tLoss: 1.36822\n",
            "Training Progress: \tEpoch 3 [960/1692 (56.60%)]\t\tLoss: 1.38394\n",
            "Training Progress: \tEpoch 3 [1280/1692 (75.47%)]\t\tLoss: 1.44167\n",
            "Training Progress: \tEpoch 3 [1600/1692 (94.34%)]\t\tLoss: 1.46390\n",
            "\tTrain loss: 0.04299, Accuracy: 507/1692 (29.96%)\n",
            "\tValidation loss: 0.00328, Accuracy: 100/423 (23.64%)\n",
            "\tTest loss: 0.00315, Accuracy: 97/443 (21.90%)\n",
            "\n",
            "Training Progress: \tEpoch 4 [0/1692 (0.00%)]\t\tLoss: 1.42594\n",
            "Training Progress: \tEpoch 4 [320/1692 (18.87%)]\t\tLoss: 1.35969\n",
            "Training Progress: \tEpoch 4 [640/1692 (37.74%)]\t\tLoss: 1.39221\n",
            "Training Progress: \tEpoch 4 [960/1692 (56.60%)]\t\tLoss: 1.35336\n",
            "Training Progress: \tEpoch 4 [1280/1692 (75.47%)]\t\tLoss: 1.36263\n",
            "Training Progress: \tEpoch 4 [1600/1692 (94.34%)]\t\tLoss: 1.40996\n",
            "\tTrain loss: 0.04279, Accuracy: 539/1692 (31.86%)\n",
            "\tValidation loss: 0.00330, Accuracy: 94/423 (22.22%)\n",
            "\tTest loss: 0.00315, Accuracy: 104/443 (23.48%)\n",
            "\n",
            "Training Progress: \tEpoch 5 [0/1692 (0.00%)]\t\tLoss: 1.45974\n",
            "Training Progress: \tEpoch 5 [320/1692 (18.87%)]\t\tLoss: 1.43213\n",
            "Training Progress: \tEpoch 5 [640/1692 (37.74%)]\t\tLoss: 1.34171\n",
            "Training Progress: \tEpoch 5 [960/1692 (56.60%)]\t\tLoss: 1.39083\n",
            "Training Progress: \tEpoch 5 [1280/1692 (75.47%)]\t\tLoss: 1.39262\n",
            "Training Progress: \tEpoch 5 [1600/1692 (94.34%)]\t\tLoss: 1.40040\n",
            "\tTrain loss: 0.04270, Accuracy: 549/1692 (32.45%)\n",
            "\tValidation loss: 0.00331, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00314, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 6 [0/1692 (0.00%)]\t\tLoss: 1.43051\n",
            "Training Progress: \tEpoch 6 [320/1692 (18.87%)]\t\tLoss: 1.37474\n",
            "Training Progress: \tEpoch 6 [640/1692 (37.74%)]\t\tLoss: 1.32050\n",
            "Training Progress: \tEpoch 6 [960/1692 (56.60%)]\t\tLoss: 1.40446\n",
            "Training Progress: \tEpoch 6 [1280/1692 (75.47%)]\t\tLoss: 1.40346\n",
            "Training Progress: \tEpoch 6 [1600/1692 (94.34%)]\t\tLoss: 1.41677\n",
            "\tTrain loss: 0.04269, Accuracy: 567/1692 (33.51%)\n",
            "\tValidation loss: 0.00329, Accuracy: 103/423 (24.35%)\n",
            "\tTest loss: 0.00315, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 7 [0/1692 (0.00%)]\t\tLoss: 1.41025\n",
            "Training Progress: \tEpoch 7 [320/1692 (18.87%)]\t\tLoss: 1.34765\n",
            "Training Progress: \tEpoch 7 [640/1692 (37.74%)]\t\tLoss: 1.41419\n",
            "Training Progress: \tEpoch 7 [960/1692 (56.60%)]\t\tLoss: 1.42370\n",
            "Training Progress: \tEpoch 7 [1280/1692 (75.47%)]\t\tLoss: 1.39663\n",
            "Training Progress: \tEpoch 7 [1600/1692 (94.34%)]\t\tLoss: 1.36202\n",
            "\tTrain loss: 0.04255, Accuracy: 581/1692 (34.34%)\n",
            "\tValidation loss: 0.00330, Accuracy: 103/423 (24.35%)\n",
            "\tTest loss: 0.00315, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 8 [0/1692 (0.00%)]\t\tLoss: 1.41619\n",
            "Training Progress: \tEpoch 8 [320/1692 (18.87%)]\t\tLoss: 1.39864\n",
            "Training Progress: \tEpoch 8 [640/1692 (37.74%)]\t\tLoss: 1.35638\n",
            "Training Progress: \tEpoch 8 [960/1692 (56.60%)]\t\tLoss: 1.37329\n",
            "Training Progress: \tEpoch 8 [1280/1692 (75.47%)]\t\tLoss: 1.38026\n",
            "Training Progress: \tEpoch 8 [1600/1692 (94.34%)]\t\tLoss: 1.42547\n",
            "\tTrain loss: 0.04238, Accuracy: 591/1692 (34.93%)\n",
            "\tValidation loss: 0.00331, Accuracy: 89/423 (21.04%)\n",
            "\tTest loss: 0.00316, Accuracy: 123/443 (27.77%)\n",
            "\n",
            "Training Progress: \tEpoch 9 [0/1692 (0.00%)]\t\tLoss: 1.41065\n",
            "Training Progress: \tEpoch 9 [320/1692 (18.87%)]\t\tLoss: 1.40625\n",
            "Training Progress: \tEpoch 9 [640/1692 (37.74%)]\t\tLoss: 1.36691\n",
            "Training Progress: \tEpoch 9 [960/1692 (56.60%)]\t\tLoss: 1.37166\n",
            "Training Progress: \tEpoch 9 [1280/1692 (75.47%)]\t\tLoss: 1.36956\n",
            "Training Progress: \tEpoch 9 [1600/1692 (94.34%)]\t\tLoss: 1.33664\n",
            "\tTrain loss: 0.04225, Accuracy: 600/1692 (35.46%)\n",
            "\tValidation loss: 0.00331, Accuracy: 105/423 (24.82%)\n",
            "\tTest loss: 0.00316, Accuracy: 121/443 (27.31%)\n",
            "\n",
            "Training Progress: \tEpoch 10 [0/1692 (0.00%)]\t\tLoss: 1.38530\n",
            "Training Progress: \tEpoch 10 [320/1692 (18.87%)]\t\tLoss: 1.34675\n",
            "Training Progress: \tEpoch 10 [640/1692 (37.74%)]\t\tLoss: 1.30117\n",
            "Training Progress: \tEpoch 10 [960/1692 (56.60%)]\t\tLoss: 1.40536\n",
            "Training Progress: \tEpoch 10 [1280/1692 (75.47%)]\t\tLoss: 1.30444\n",
            "Training Progress: \tEpoch 10 [1600/1692 (94.34%)]\t\tLoss: 1.30529\n",
            "\tTrain loss: 0.04199, Accuracy: 628/1692 (37.12%)\n",
            "\tValidation loss: 0.00332, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00316, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 11 [0/1692 (0.00%)]\t\tLoss: 1.40768\n",
            "Training Progress: \tEpoch 11 [320/1692 (18.87%)]\t\tLoss: 1.37843\n",
            "Training Progress: \tEpoch 11 [640/1692 (37.74%)]\t\tLoss: 1.32481\n",
            "Training Progress: \tEpoch 11 [960/1692 (56.60%)]\t\tLoss: 1.31433\n",
            "Training Progress: \tEpoch 11 [1280/1692 (75.47%)]\t\tLoss: 1.38860\n",
            "Training Progress: \tEpoch 11 [1600/1692 (94.34%)]\t\tLoss: 1.40148\n",
            "\tTrain loss: 0.04193, Accuracy: 605/1692 (35.76%)\n",
            "\tValidation loss: 0.00331, Accuracy: 103/423 (24.35%)\n",
            "\tTest loss: 0.00317, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 12 [0/1692 (0.00%)]\t\tLoss: 1.40107\n",
            "Training Progress: \tEpoch 12 [320/1692 (18.87%)]\t\tLoss: 1.37025\n",
            "Training Progress: \tEpoch 12 [640/1692 (37.74%)]\t\tLoss: 1.40235\n",
            "Training Progress: \tEpoch 12 [960/1692 (56.60%)]\t\tLoss: 1.38456\n",
            "Training Progress: \tEpoch 12 [1280/1692 (75.47%)]\t\tLoss: 1.38238\n",
            "Training Progress: \tEpoch 12 [1600/1692 (94.34%)]\t\tLoss: 1.36546\n",
            "\tTrain loss: 0.04176, Accuracy: 638/1692 (37.71%)\n",
            "\tValidation loss: 0.00332, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00315, Accuracy: 131/443 (29.57%)\n",
            "\n",
            "Training Progress: \tEpoch 13 [0/1692 (0.00%)]\t\tLoss: 1.36813\n",
            "Training Progress: \tEpoch 13 [320/1692 (18.87%)]\t\tLoss: 1.31382\n",
            "Training Progress: \tEpoch 13 [640/1692 (37.74%)]\t\tLoss: 1.31004\n",
            "Training Progress: \tEpoch 13 [960/1692 (56.60%)]\t\tLoss: 1.35688\n",
            "Training Progress: \tEpoch 13 [1280/1692 (75.47%)]\t\tLoss: 1.42507\n",
            "Training Progress: \tEpoch 13 [1600/1692 (94.34%)]\t\tLoss: 1.39504\n",
            "\tTrain loss: 0.04142, Accuracy: 651/1692 (38.48%)\n",
            "\tValidation loss: 0.00333, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00317, Accuracy: 124/443 (27.99%)\n",
            "\n",
            "Training Progress: \tEpoch 14 [0/1692 (0.00%)]\t\tLoss: 1.40884\n",
            "Training Progress: \tEpoch 14 [320/1692 (18.87%)]\t\tLoss: 1.34174\n",
            "Training Progress: \tEpoch 14 [640/1692 (37.74%)]\t\tLoss: 1.33659\n",
            "Training Progress: \tEpoch 14 [960/1692 (56.60%)]\t\tLoss: 1.42238\n",
            "Training Progress: \tEpoch 14 [1280/1692 (75.47%)]\t\tLoss: 1.31635\n",
            "Training Progress: \tEpoch 14 [1600/1692 (94.34%)]\t\tLoss: 1.34633\n",
            "\tTrain loss: 0.04133, Accuracy: 676/1692 (39.95%)\n",
            "\tValidation loss: 0.00333, Accuracy: 112/423 (26.48%)\n",
            "\tTest loss: 0.00317, Accuracy: 121/443 (27.31%)\n",
            "\n",
            "Training Progress: \tEpoch 15 [0/1692 (0.00%)]\t\tLoss: 1.32257\n",
            "Training Progress: \tEpoch 15 [320/1692 (18.87%)]\t\tLoss: 1.27837\n",
            "Training Progress: \tEpoch 15 [640/1692 (37.74%)]\t\tLoss: 1.29630\n",
            "Training Progress: \tEpoch 15 [960/1692 (56.60%)]\t\tLoss: 1.29491\n",
            "Training Progress: \tEpoch 15 [1280/1692 (75.47%)]\t\tLoss: 1.35792\n",
            "Training Progress: \tEpoch 15 [1600/1692 (94.34%)]\t\tLoss: 1.34776\n",
            "\tTrain loss: 0.04093, Accuracy: 679/1692 (40.13%)\n",
            "\tValidation loss: 0.00336, Accuracy: 105/423 (24.82%)\n",
            "\tTest loss: 0.00321, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 16 [0/1692 (0.00%)]\t\tLoss: 1.34917\n",
            "Training Progress: \tEpoch 16 [320/1692 (18.87%)]\t\tLoss: 1.38576\n",
            "Training Progress: \tEpoch 16 [640/1692 (37.74%)]\t\tLoss: 1.28620\n",
            "Training Progress: \tEpoch 16 [960/1692 (56.60%)]\t\tLoss: 1.31832\n",
            "Training Progress: \tEpoch 16 [1280/1692 (75.47%)]\t\tLoss: 1.43229\n",
            "Training Progress: \tEpoch 16 [1600/1692 (94.34%)]\t\tLoss: 1.39961\n",
            "\tTrain loss: 0.04058, Accuracy: 711/1692 (42.02%)\n",
            "\tValidation loss: 0.00335, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00320, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 17 [0/1692 (0.00%)]\t\tLoss: 1.33601\n",
            "Training Progress: \tEpoch 17 [320/1692 (18.87%)]\t\tLoss: 1.36747\n",
            "Training Progress: \tEpoch 17 [640/1692 (37.74%)]\t\tLoss: 1.34194\n",
            "Training Progress: \tEpoch 17 [960/1692 (56.60%)]\t\tLoss: 1.38803\n",
            "Training Progress: \tEpoch 17 [1280/1692 (75.47%)]\t\tLoss: 1.43125\n",
            "Training Progress: \tEpoch 17 [1600/1692 (94.34%)]\t\tLoss: 1.33188\n",
            "\tTrain loss: 0.04040, Accuracy: 715/1692 (42.26%)\n",
            "\tValidation loss: 0.00335, Accuracy: 111/423 (26.24%)\n",
            "\tTest loss: 0.00321, Accuracy: 110/443 (24.83%)\n",
            "\n",
            "Training Progress: \tEpoch 18 [0/1692 (0.00%)]\t\tLoss: 1.36020\n",
            "Training Progress: \tEpoch 18 [320/1692 (18.87%)]\t\tLoss: 1.27056\n",
            "Training Progress: \tEpoch 18 [640/1692 (37.74%)]\t\tLoss: 1.34890\n",
            "Training Progress: \tEpoch 18 [960/1692 (56.60%)]\t\tLoss: 1.38006\n",
            "Training Progress: \tEpoch 18 [1280/1692 (75.47%)]\t\tLoss: 1.37395\n",
            "Training Progress: \tEpoch 18 [1600/1692 (94.34%)]\t\tLoss: 1.26908\n",
            "\tTrain loss: 0.04032, Accuracy: 690/1692 (40.78%)\n",
            "\tValidation loss: 0.00338, Accuracy: 96/423 (22.70%)\n",
            "\tTest loss: 0.00320, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 19 [0/1692 (0.00%)]\t\tLoss: 1.27677\n",
            "Training Progress: \tEpoch 19 [320/1692 (18.87%)]\t\tLoss: 1.29932\n",
            "Training Progress: \tEpoch 19 [640/1692 (37.74%)]\t\tLoss: 1.23015\n",
            "Training Progress: \tEpoch 19 [960/1692 (56.60%)]\t\tLoss: 1.34232\n",
            "Training Progress: \tEpoch 19 [1280/1692 (75.47%)]\t\tLoss: 1.46446\n",
            "Training Progress: \tEpoch 19 [1600/1692 (94.34%)]\t\tLoss: 1.25010\n",
            "\tTrain loss: 0.03986, Accuracy: 744/1692 (43.97%)\n",
            "\tValidation loss: 0.00338, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00321, Accuracy: 126/443 (28.44%)\n",
            "\n",
            "Training Progress: \tEpoch 20 [0/1692 (0.00%)]\t\tLoss: 1.24094\n",
            "Training Progress: \tEpoch 20 [320/1692 (18.87%)]\t\tLoss: 1.37642\n",
            "Training Progress: \tEpoch 20 [640/1692 (37.74%)]\t\tLoss: 1.21707\n",
            "Training Progress: \tEpoch 20 [960/1692 (56.60%)]\t\tLoss: 1.25310\n",
            "Training Progress: \tEpoch 20 [1280/1692 (75.47%)]\t\tLoss: 1.30610\n",
            "Training Progress: \tEpoch 20 [1600/1692 (94.34%)]\t\tLoss: 1.26559\n",
            "\tTrain loss: 0.03946, Accuracy: 729/1692 (43.09%)\n",
            "\tValidation loss: 0.00338, Accuracy: 114/423 (26.95%)\n",
            "\tTest loss: 0.00323, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 21 [0/1692 (0.00%)]\t\tLoss: 1.31306\n",
            "Training Progress: \tEpoch 21 [320/1692 (18.87%)]\t\tLoss: 1.36118\n",
            "Training Progress: \tEpoch 21 [640/1692 (37.74%)]\t\tLoss: 1.19993\n",
            "Training Progress: \tEpoch 21 [960/1692 (56.60%)]\t\tLoss: 1.30208\n",
            "Training Progress: \tEpoch 21 [1280/1692 (75.47%)]\t\tLoss: 1.39922\n",
            "Training Progress: \tEpoch 21 [1600/1692 (94.34%)]\t\tLoss: 1.26595\n",
            "\tTrain loss: 0.03905, Accuracy: 757/1692 (44.74%)\n",
            "\tValidation loss: 0.00340, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00323, Accuracy: 125/443 (28.22%)\n",
            "\n",
            "Training Progress: \tEpoch 22 [0/1692 (0.00%)]\t\tLoss: 1.37125\n",
            "Training Progress: \tEpoch 22 [320/1692 (18.87%)]\t\tLoss: 1.32239\n",
            "Training Progress: \tEpoch 22 [640/1692 (37.74%)]\t\tLoss: 1.21097\n",
            "Training Progress: \tEpoch 22 [960/1692 (56.60%)]\t\tLoss: 1.22124\n",
            "Training Progress: \tEpoch 22 [1280/1692 (75.47%)]\t\tLoss: 1.45074\n",
            "Training Progress: \tEpoch 22 [1600/1692 (94.34%)]\t\tLoss: 1.25065\n",
            "\tTrain loss: 0.03912, Accuracy: 737/1692 (43.56%)\n",
            "\tValidation loss: 0.00341, Accuracy: 119/423 (28.13%)\n",
            "\tTest loss: 0.00325, Accuracy: 128/443 (28.89%)\n",
            "\n",
            "Training Progress: \tEpoch 23 [0/1692 (0.00%)]\t\tLoss: 1.26507\n",
            "Training Progress: \tEpoch 23 [320/1692 (18.87%)]\t\tLoss: 1.26178\n",
            "Training Progress: \tEpoch 23 [640/1692 (37.74%)]\t\tLoss: 1.22874\n",
            "Training Progress: \tEpoch 23 [960/1692 (56.60%)]\t\tLoss: 1.25628\n",
            "Training Progress: \tEpoch 23 [1280/1692 (75.47%)]\t\tLoss: 1.41631\n",
            "Training Progress: \tEpoch 23 [1600/1692 (94.34%)]\t\tLoss: 1.33840\n",
            "\tTrain loss: 0.03842, Accuracy: 789/1692 (46.63%)\n",
            "\tValidation loss: 0.00342, Accuracy: 114/423 (26.95%)\n",
            "\tTest loss: 0.00328, Accuracy: 122/443 (27.54%)\n",
            "\n",
            "Training Progress: \tEpoch 24 [0/1692 (0.00%)]\t\tLoss: 1.24953\n",
            "Training Progress: \tEpoch 24 [320/1692 (18.87%)]\t\tLoss: 1.22585\n",
            "Training Progress: \tEpoch 24 [640/1692 (37.74%)]\t\tLoss: 1.27573\n",
            "Training Progress: \tEpoch 24 [960/1692 (56.60%)]\t\tLoss: 1.26100\n",
            "Training Progress: \tEpoch 24 [1280/1692 (75.47%)]\t\tLoss: 1.27228\n",
            "Training Progress: \tEpoch 24 [1600/1692 (94.34%)]\t\tLoss: 1.24979\n",
            "\tTrain loss: 0.03800, Accuracy: 803/1692 (47.46%)\n",
            "\tValidation loss: 0.00341, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00331, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 25 [0/1692 (0.00%)]\t\tLoss: 1.21638\n",
            "Training Progress: \tEpoch 25 [320/1692 (18.87%)]\t\tLoss: 1.25066\n",
            "Training Progress: \tEpoch 25 [640/1692 (37.74%)]\t\tLoss: 1.26315\n",
            "Training Progress: \tEpoch 25 [960/1692 (56.60%)]\t\tLoss: 1.32780\n",
            "Training Progress: \tEpoch 25 [1280/1692 (75.47%)]\t\tLoss: 1.37173\n",
            "Training Progress: \tEpoch 25 [1600/1692 (94.34%)]\t\tLoss: 1.25433\n",
            "\tTrain loss: 0.03770, Accuracy: 805/1692 (47.58%)\n",
            "\tValidation loss: 0.00342, Accuracy: 119/423 (28.13%)\n",
            "\tTest loss: 0.00328, Accuracy: 119/443 (26.86%)\n",
            "\n",
            "Training Progress: \tEpoch 26 [0/1692 (0.00%)]\t\tLoss: 1.19599\n",
            "Training Progress: \tEpoch 26 [320/1692 (18.87%)]\t\tLoss: 1.20761\n",
            "Training Progress: \tEpoch 26 [640/1692 (37.74%)]\t\tLoss: 1.32051\n",
            "Training Progress: \tEpoch 26 [960/1692 (56.60%)]\t\tLoss: 1.23209\n",
            "Training Progress: \tEpoch 26 [1280/1692 (75.47%)]\t\tLoss: 1.32226\n",
            "Training Progress: \tEpoch 26 [1600/1692 (94.34%)]\t\tLoss: 1.27476\n",
            "\tTrain loss: 0.03720, Accuracy: 816/1692 (48.23%)\n",
            "\tValidation loss: 0.00346, Accuracy: 118/423 (27.90%)\n",
            "\tTest loss: 0.00332, Accuracy: 119/443 (26.86%)\n",
            "\n",
            "Training Progress: \tEpoch 27 [0/1692 (0.00%)]\t\tLoss: 1.18407\n",
            "Training Progress: \tEpoch 27 [320/1692 (18.87%)]\t\tLoss: 1.20834\n",
            "Training Progress: \tEpoch 27 [640/1692 (37.74%)]\t\tLoss: 1.17590\n",
            "Training Progress: \tEpoch 27 [960/1692 (56.60%)]\t\tLoss: 1.19699\n",
            "Training Progress: \tEpoch 27 [1280/1692 (75.47%)]\t\tLoss: 1.22963\n",
            "Training Progress: \tEpoch 27 [1600/1692 (94.34%)]\t\tLoss: 1.14680\n",
            "\tTrain loss: 0.03668, Accuracy: 848/1692 (50.12%)\n",
            "\tValidation loss: 0.00349, Accuracy: 114/423 (26.95%)\n",
            "\tTest loss: 0.00336, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 28 [0/1692 (0.00%)]\t\tLoss: 1.21970\n",
            "Training Progress: \tEpoch 28 [320/1692 (18.87%)]\t\tLoss: 1.21498\n",
            "Training Progress: \tEpoch 28 [640/1692 (37.74%)]\t\tLoss: 1.16094\n",
            "Training Progress: \tEpoch 28 [960/1692 (56.60%)]\t\tLoss: 1.32172\n",
            "Training Progress: \tEpoch 28 [1280/1692 (75.47%)]\t\tLoss: 1.22064\n",
            "Training Progress: \tEpoch 28 [1600/1692 (94.34%)]\t\tLoss: 1.25127\n",
            "\tTrain loss: 0.03614, Accuracy: 854/1692 (50.47%)\n",
            "\tValidation loss: 0.00349, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00342, Accuracy: 104/443 (23.48%)\n",
            "\n",
            "Training Progress: \tEpoch 29 [0/1692 (0.00%)]\t\tLoss: 1.19000\n",
            "Training Progress: \tEpoch 29 [320/1692 (18.87%)]\t\tLoss: 1.17712\n",
            "Training Progress: \tEpoch 29 [640/1692 (37.74%)]\t\tLoss: 1.10807\n",
            "Training Progress: \tEpoch 29 [960/1692 (56.60%)]\t\tLoss: 1.17214\n",
            "Training Progress: \tEpoch 29 [1280/1692 (75.47%)]\t\tLoss: 1.35179\n",
            "Training Progress: \tEpoch 29 [1600/1692 (94.34%)]\t\tLoss: 1.09714\n",
            "\tTrain loss: 0.03595, Accuracy: 865/1692 (51.12%)\n",
            "\tValidation loss: 0.00352, Accuracy: 120/423 (28.37%)\n",
            "\tTest loss: 0.00345, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 30 [0/1692 (0.00%)]\t\tLoss: 1.11013\n",
            "Training Progress: \tEpoch 30 [320/1692 (18.87%)]\t\tLoss: 1.09831\n",
            "Training Progress: \tEpoch 30 [640/1692 (37.74%)]\t\tLoss: 1.23189\n",
            "Training Progress: \tEpoch 30 [960/1692 (56.60%)]\t\tLoss: 1.19932\n",
            "Training Progress: \tEpoch 30 [1280/1692 (75.47%)]\t\tLoss: 1.19537\n",
            "Training Progress: \tEpoch 30 [1600/1692 (94.34%)]\t\tLoss: 1.17629\n",
            "\tTrain loss: 0.03559, Accuracy: 882/1692 (52.13%)\n",
            "\tValidation loss: 0.00359, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00345, Accuracy: 110/443 (24.83%)\n",
            "\n",
            "Training Progress: \tEpoch 31 [0/1692 (0.00%)]\t\tLoss: 1.14940\n",
            "Training Progress: \tEpoch 31 [320/1692 (18.87%)]\t\tLoss: 1.27005\n",
            "Training Progress: \tEpoch 31 [640/1692 (37.74%)]\t\tLoss: 1.05272\n",
            "Training Progress: \tEpoch 31 [960/1692 (56.60%)]\t\tLoss: 1.16951\n",
            "Training Progress: \tEpoch 31 [1280/1692 (75.47%)]\t\tLoss: 1.11700\n",
            "Training Progress: \tEpoch 31 [1600/1692 (94.34%)]\t\tLoss: 1.19690\n",
            "\tTrain loss: 0.03525, Accuracy: 887/1692 (52.42%)\n",
            "\tValidation loss: 0.00356, Accuracy: 125/423 (29.55%)\n",
            "\tTest loss: 0.00345, Accuracy: 121/443 (27.31%)\n",
            "\n",
            "Training Progress: \tEpoch 32 [0/1692 (0.00%)]\t\tLoss: 1.06154\n",
            "Training Progress: \tEpoch 32 [320/1692 (18.87%)]\t\tLoss: 1.18309\n",
            "Training Progress: \tEpoch 32 [640/1692 (37.74%)]\t\tLoss: 1.11529\n",
            "Training Progress: \tEpoch 32 [960/1692 (56.60%)]\t\tLoss: 1.19279\n",
            "Training Progress: \tEpoch 32 [1280/1692 (75.47%)]\t\tLoss: 1.26871\n",
            "Training Progress: \tEpoch 32 [1600/1692 (94.34%)]\t\tLoss: 1.08366\n",
            "\tTrain loss: 0.03458, Accuracy: 929/1692 (54.91%)\n",
            "\tValidation loss: 0.00357, Accuracy: 114/423 (26.95%)\n",
            "\tTest loss: 0.00345, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 33 [0/1692 (0.00%)]\t\tLoss: 1.17317\n",
            "Training Progress: \tEpoch 33 [320/1692 (18.87%)]\t\tLoss: 1.12309\n",
            "Training Progress: \tEpoch 33 [640/1692 (37.74%)]\t\tLoss: 1.00603\n",
            "Training Progress: \tEpoch 33 [960/1692 (56.60%)]\t\tLoss: 1.04321\n",
            "Training Progress: \tEpoch 33 [1280/1692 (75.47%)]\t\tLoss: 1.11827\n",
            "Training Progress: \tEpoch 33 [1600/1692 (94.34%)]\t\tLoss: 1.23369\n",
            "\tTrain loss: 0.03420, Accuracy: 919/1692 (54.31%)\n",
            "\tValidation loss: 0.00363, Accuracy: 114/423 (26.95%)\n",
            "\tTest loss: 0.00348, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 34 [0/1692 (0.00%)]\t\tLoss: 1.16721\n",
            "Training Progress: \tEpoch 34 [320/1692 (18.87%)]\t\tLoss: 1.08299\n",
            "Training Progress: \tEpoch 34 [640/1692 (37.74%)]\t\tLoss: 1.02043\n",
            "Training Progress: \tEpoch 34 [960/1692 (56.60%)]\t\tLoss: 1.25893\n",
            "Training Progress: \tEpoch 34 [1280/1692 (75.47%)]\t\tLoss: 1.18734\n",
            "Training Progress: \tEpoch 34 [1600/1692 (94.34%)]\t\tLoss: 1.12453\n",
            "\tTrain loss: 0.03382, Accuracy: 937/1692 (55.38%)\n",
            "\tValidation loss: 0.00363, Accuracy: 109/423 (25.77%)\n",
            "\tTest loss: 0.00350, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 35 [0/1692 (0.00%)]\t\tLoss: 1.11362\n",
            "Training Progress: \tEpoch 35 [320/1692 (18.87%)]\t\tLoss: 1.17811\n",
            "Training Progress: \tEpoch 35 [640/1692 (37.74%)]\t\tLoss: 1.01491\n",
            "Training Progress: \tEpoch 35 [960/1692 (56.60%)]\t\tLoss: 1.25606\n",
            "Training Progress: \tEpoch 35 [1280/1692 (75.47%)]\t\tLoss: 1.01982\n",
            "Training Progress: \tEpoch 35 [1600/1692 (94.34%)]\t\tLoss: 1.02892\n",
            "\tTrain loss: 0.03291, Accuracy: 966/1692 (57.09%)\n",
            "\tValidation loss: 0.00364, Accuracy: 118/423 (27.90%)\n",
            "\tTest loss: 0.00348, Accuracy: 120/443 (27.09%)\n",
            "\n",
            "Training Progress: \tEpoch 36 [0/1692 (0.00%)]\t\tLoss: 1.07080\n",
            "Training Progress: \tEpoch 36 [320/1692 (18.87%)]\t\tLoss: 1.10326\n",
            "Training Progress: \tEpoch 36 [640/1692 (37.74%)]\t\tLoss: 1.07825\n",
            "Training Progress: \tEpoch 36 [960/1692 (56.60%)]\t\tLoss: 1.10124\n",
            "Training Progress: \tEpoch 36 [1280/1692 (75.47%)]\t\tLoss: 1.13141\n",
            "Training Progress: \tEpoch 36 [1600/1692 (94.34%)]\t\tLoss: 1.10552\n",
            "\tTrain loss: 0.03223, Accuracy: 985/1692 (58.22%)\n",
            "\tValidation loss: 0.00370, Accuracy: 119/423 (28.13%)\n",
            "\tTest loss: 0.00362, Accuracy: 97/443 (21.90%)\n",
            "\n",
            "Training Progress: \tEpoch 37 [0/1692 (0.00%)]\t\tLoss: 1.05980\n",
            "Training Progress: \tEpoch 37 [320/1692 (18.87%)]\t\tLoss: 1.01339\n",
            "Training Progress: \tEpoch 37 [640/1692 (37.74%)]\t\tLoss: 1.01498\n",
            "Training Progress: \tEpoch 37 [960/1692 (56.60%)]\t\tLoss: 1.00049\n",
            "Training Progress: \tEpoch 37 [1280/1692 (75.47%)]\t\tLoss: 1.09114\n",
            "Training Progress: \tEpoch 37 [1600/1692 (94.34%)]\t\tLoss: 1.07215\n",
            "\tTrain loss: 0.03164, Accuracy: 991/1692 (58.57%)\n",
            "\tValidation loss: 0.00370, Accuracy: 116/423 (27.42%)\n",
            "\tTest loss: 0.00361, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 38 [0/1692 (0.00%)]\t\tLoss: 1.02436\n",
            "Training Progress: \tEpoch 38 [320/1692 (18.87%)]\t\tLoss: 1.00699\n",
            "Training Progress: \tEpoch 38 [640/1692 (37.74%)]\t\tLoss: 1.05358\n",
            "Training Progress: \tEpoch 38 [960/1692 (56.60%)]\t\tLoss: 1.05802\n",
            "Training Progress: \tEpoch 38 [1280/1692 (75.47%)]\t\tLoss: 1.11058\n",
            "Training Progress: \tEpoch 38 [1600/1692 (94.34%)]\t\tLoss: 1.15961\n",
            "\tTrain loss: 0.03213, Accuracy: 987/1692 (58.33%)\n",
            "\tValidation loss: 0.00370, Accuracy: 116/423 (27.42%)\n",
            "\tTest loss: 0.00358, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 39 [0/1692 (0.00%)]\t\tLoss: 1.15226\n",
            "Training Progress: \tEpoch 39 [320/1692 (18.87%)]\t\tLoss: 0.98731\n",
            "Training Progress: \tEpoch 39 [640/1692 (37.74%)]\t\tLoss: 1.00990\n",
            "Training Progress: \tEpoch 39 [960/1692 (56.60%)]\t\tLoss: 1.05751\n",
            "Training Progress: \tEpoch 39 [1280/1692 (75.47%)]\t\tLoss: 1.13578\n",
            "Training Progress: \tEpoch 39 [1600/1692 (94.34%)]\t\tLoss: 1.05829\n",
            "\tTrain loss: 0.03158, Accuracy: 1013/1692 (59.87%)\n",
            "\tValidation loss: 0.00374, Accuracy: 114/423 (26.95%)\n",
            "\tTest loss: 0.00362, Accuracy: 123/443 (27.77%)\n",
            "\n",
            "Training Progress: \tEpoch 40 [0/1692 (0.00%)]\t\tLoss: 1.08623\n",
            "Training Progress: \tEpoch 40 [320/1692 (18.87%)]\t\tLoss: 1.09482\n",
            "Training Progress: \tEpoch 40 [640/1692 (37.74%)]\t\tLoss: 1.05648\n",
            "Training Progress: \tEpoch 40 [960/1692 (56.60%)]\t\tLoss: 1.10023\n",
            "Training Progress: \tEpoch 40 [1280/1692 (75.47%)]\t\tLoss: 0.98009\n",
            "Training Progress: \tEpoch 40 [1600/1692 (94.34%)]\t\tLoss: 1.11072\n",
            "\tTrain loss: 0.03071, Accuracy: 1058/1692 (62.53%)\n",
            "\tValidation loss: 0.00371, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00362, Accuracy: 106/443 (23.93%)\n",
            "\n",
            "Training Progress: \tEpoch 41 [0/1692 (0.00%)]\t\tLoss: 1.01110\n",
            "Training Progress: \tEpoch 41 [320/1692 (18.87%)]\t\tLoss: 0.97771\n",
            "Training Progress: \tEpoch 41 [640/1692 (37.74%)]\t\tLoss: 0.87560\n",
            "Training Progress: \tEpoch 41 [960/1692 (56.60%)]\t\tLoss: 1.15329\n",
            "Training Progress: \tEpoch 41 [1280/1692 (75.47%)]\t\tLoss: 1.01461\n",
            "Training Progress: \tEpoch 41 [1600/1692 (94.34%)]\t\tLoss: 0.99408\n",
            "\tTrain loss: 0.03002, Accuracy: 1043/1692 (61.64%)\n",
            "\tValidation loss: 0.00386, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00377, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 42 [0/1692 (0.00%)]\t\tLoss: 0.99444\n",
            "Training Progress: \tEpoch 42 [320/1692 (18.87%)]\t\tLoss: 1.09477\n",
            "Training Progress: \tEpoch 42 [640/1692 (37.74%)]\t\tLoss: 0.93710\n",
            "Training Progress: \tEpoch 42 [960/1692 (56.60%)]\t\tLoss: 0.97920\n",
            "Training Progress: \tEpoch 42 [1280/1692 (75.47%)]\t\tLoss: 0.88869\n",
            "Training Progress: \tEpoch 42 [1600/1692 (94.34%)]\t\tLoss: 0.92266\n",
            "\tTrain loss: 0.02970, Accuracy: 1064/1692 (62.88%)\n",
            "\tValidation loss: 0.00385, Accuracy: 124/423 (29.31%)\n",
            "\tTest loss: 0.00377, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 43 [0/1692 (0.00%)]\t\tLoss: 0.92848\n",
            "Training Progress: \tEpoch 43 [320/1692 (18.87%)]\t\tLoss: 1.10691\n",
            "Training Progress: \tEpoch 43 [640/1692 (37.74%)]\t\tLoss: 0.87322\n",
            "Training Progress: \tEpoch 43 [960/1692 (56.60%)]\t\tLoss: 1.13893\n",
            "Training Progress: \tEpoch 43 [1280/1692 (75.47%)]\t\tLoss: 1.00790\n",
            "Training Progress: \tEpoch 43 [1600/1692 (94.34%)]\t\tLoss: 0.88572\n",
            "\tTrain loss: 0.02921, Accuracy: 1051/1692 (62.12%)\n",
            "\tValidation loss: 0.00395, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00389, Accuracy: 107/443 (24.15%)\n",
            "\n",
            "Training Progress: \tEpoch 44 [0/1692 (0.00%)]\t\tLoss: 1.05618\n",
            "Training Progress: \tEpoch 44 [320/1692 (18.87%)]\t\tLoss: 0.92465\n",
            "Training Progress: \tEpoch 44 [640/1692 (37.74%)]\t\tLoss: 0.94710\n",
            "Training Progress: \tEpoch 44 [960/1692 (56.60%)]\t\tLoss: 1.06350\n",
            "Training Progress: \tEpoch 44 [1280/1692 (75.47%)]\t\tLoss: 0.87619\n",
            "Training Progress: \tEpoch 44 [1600/1692 (94.34%)]\t\tLoss: 0.93601\n",
            "\tTrain loss: 0.02929, Accuracy: 1063/1692 (62.83%)\n",
            "\tValidation loss: 0.00392, Accuracy: 112/423 (26.48%)\n",
            "\tTest loss: 0.00377, Accuracy: 126/443 (28.44%)\n",
            "\n",
            "Training Progress: \tEpoch 45 [0/1692 (0.00%)]\t\tLoss: 1.07516\n",
            "Training Progress: \tEpoch 45 [320/1692 (18.87%)]\t\tLoss: 1.12865\n",
            "Training Progress: \tEpoch 45 [640/1692 (37.74%)]\t\tLoss: 0.89457\n",
            "Training Progress: \tEpoch 45 [960/1692 (56.60%)]\t\tLoss: 0.86396\n",
            "Training Progress: \tEpoch 45 [1280/1692 (75.47%)]\t\tLoss: 0.90049\n",
            "Training Progress: \tEpoch 45 [1600/1692 (94.34%)]\t\tLoss: 0.82131\n",
            "\tTrain loss: 0.02867, Accuracy: 1099/1692 (64.95%)\n",
            "\tValidation loss: 0.00389, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00375, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 46 [0/1692 (0.00%)]\t\tLoss: 0.97408\n",
            "Training Progress: \tEpoch 46 [320/1692 (18.87%)]\t\tLoss: 1.14746\n",
            "Training Progress: \tEpoch 46 [640/1692 (37.74%)]\t\tLoss: 0.82673\n",
            "Training Progress: \tEpoch 46 [960/1692 (56.60%)]\t\tLoss: 0.99680\n",
            "Training Progress: \tEpoch 46 [1280/1692 (75.47%)]\t\tLoss: 0.97837\n",
            "Training Progress: \tEpoch 46 [1600/1692 (94.34%)]\t\tLoss: 0.96931\n",
            "\tTrain loss: 0.02784, Accuracy: 1098/1692 (64.89%)\n",
            "\tValidation loss: 0.00397, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00387, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 47 [0/1692 (0.00%)]\t\tLoss: 0.94364\n",
            "Training Progress: \tEpoch 47 [320/1692 (18.87%)]\t\tLoss: 1.07624\n",
            "Training Progress: \tEpoch 47 [640/1692 (37.74%)]\t\tLoss: 0.95412\n",
            "Training Progress: \tEpoch 47 [960/1692 (56.60%)]\t\tLoss: 1.08881\n",
            "Training Progress: \tEpoch 47 [1280/1692 (75.47%)]\t\tLoss: 1.00439\n",
            "Training Progress: \tEpoch 47 [1600/1692 (94.34%)]\t\tLoss: 0.94977\n",
            "\tTrain loss: 0.02785, Accuracy: 1109/1692 (65.54%)\n",
            "\tValidation loss: 0.00404, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00395, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 48 [0/1692 (0.00%)]\t\tLoss: 0.90918\n",
            "Training Progress: \tEpoch 48 [320/1692 (18.87%)]\t\tLoss: 0.87731\n",
            "Training Progress: \tEpoch 48 [640/1692 (37.74%)]\t\tLoss: 0.80780\n",
            "Training Progress: \tEpoch 48 [960/1692 (56.60%)]\t\tLoss: 0.90968\n",
            "Training Progress: \tEpoch 48 [1280/1692 (75.47%)]\t\tLoss: 0.83147\n",
            "Training Progress: \tEpoch 48 [1600/1692 (94.34%)]\t\tLoss: 0.99392\n",
            "\tTrain loss: 0.02645, Accuracy: 1138/1692 (67.26%)\n",
            "\tValidation loss: 0.00417, Accuracy: 115/423 (27.19%)\n",
            "\tTest loss: 0.00408, Accuracy: 115/443 (25.96%)\n",
            "\n",
            "Training Progress: \tEpoch 49 [0/1692 (0.00%)]\t\tLoss: 0.96709\n",
            "Training Progress: \tEpoch 49 [320/1692 (18.87%)]\t\tLoss: 1.00145\n",
            "Training Progress: \tEpoch 49 [640/1692 (37.74%)]\t\tLoss: 0.81315\n",
            "Training Progress: \tEpoch 49 [960/1692 (56.60%)]\t\tLoss: 1.01652\n",
            "Training Progress: \tEpoch 49 [1280/1692 (75.47%)]\t\tLoss: 0.95894\n",
            "Training Progress: \tEpoch 49 [1600/1692 (94.34%)]\t\tLoss: 0.94753\n",
            "\tTrain loss: 0.02622, Accuracy: 1134/1692 (67.02%)\n",
            "\tValidation loss: 0.00413, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00404, Accuracy: 110/443 (24.83%)\n",
            "\n",
            "Training Progress: \tEpoch 50 [0/1692 (0.00%)]\t\tLoss: 1.20738\n",
            "Training Progress: \tEpoch 50 [320/1692 (18.87%)]\t\tLoss: 0.80514\n",
            "Training Progress: \tEpoch 50 [640/1692 (37.74%)]\t\tLoss: 0.97278\n",
            "Training Progress: \tEpoch 50 [960/1692 (56.60%)]\t\tLoss: 0.80816\n",
            "Training Progress: \tEpoch 50 [1280/1692 (75.47%)]\t\tLoss: 0.80139\n",
            "Training Progress: \tEpoch 50 [1600/1692 (94.34%)]\t\tLoss: 0.84041\n",
            "\tTrain loss: 0.02554, Accuracy: 1174/1692 (69.39%)\n",
            "\tValidation loss: 0.00420, Accuracy: 105/423 (24.82%)\n",
            "\tTest loss: 0.00409, Accuracy: 106/443 (23.93%)\n",
            "\n",
            "Training Progress: \tEpoch 51 [0/1692 (0.00%)]\t\tLoss: 0.98460\n",
            "Training Progress: \tEpoch 51 [320/1692 (18.87%)]\t\tLoss: 0.87269\n",
            "Training Progress: \tEpoch 51 [640/1692 (37.74%)]\t\tLoss: 0.91582\n",
            "Training Progress: \tEpoch 51 [960/1692 (56.60%)]\t\tLoss: 0.99170\n",
            "Training Progress: \tEpoch 51 [1280/1692 (75.47%)]\t\tLoss: 0.87410\n",
            "Training Progress: \tEpoch 51 [1600/1692 (94.34%)]\t\tLoss: 0.92166\n",
            "\tTrain loss: 0.02513, Accuracy: 1176/1692 (69.50%)\n",
            "\tValidation loss: 0.00428, Accuracy: 105/423 (24.82%)\n",
            "\tTest loss: 0.00413, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 52 [0/1692 (0.00%)]\t\tLoss: 0.72507\n",
            "Training Progress: \tEpoch 52 [320/1692 (18.87%)]\t\tLoss: 0.89036\n",
            "Training Progress: \tEpoch 52 [640/1692 (37.74%)]\t\tLoss: 0.91934\n",
            "Training Progress: \tEpoch 52 [960/1692 (56.60%)]\t\tLoss: 0.88455\n",
            "Training Progress: \tEpoch 52 [1280/1692 (75.47%)]\t\tLoss: 0.80990\n",
            "Training Progress: \tEpoch 52 [1600/1692 (94.34%)]\t\tLoss: 0.76015\n",
            "\tTrain loss: 0.02503, Accuracy: 1168/1692 (69.03%)\n",
            "\tValidation loss: 0.00421, Accuracy: 117/423 (27.66%)\n",
            "\tTest loss: 0.00402, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 53 [0/1692 (0.00%)]\t\tLoss: 0.92350\n",
            "Training Progress: \tEpoch 53 [320/1692 (18.87%)]\t\tLoss: 0.88889\n",
            "Training Progress: \tEpoch 53 [640/1692 (37.74%)]\t\tLoss: 0.75510\n",
            "Training Progress: \tEpoch 53 [960/1692 (56.60%)]\t\tLoss: 0.91202\n",
            "Training Progress: \tEpoch 53 [1280/1692 (75.47%)]\t\tLoss: 0.89310\n",
            "Training Progress: \tEpoch 53 [1600/1692 (94.34%)]\t\tLoss: 0.74589\n",
            "\tTrain loss: 0.02436, Accuracy: 1205/1692 (71.22%)\n",
            "\tValidation loss: 0.00428, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00420, Accuracy: 110/443 (24.83%)\n",
            "\n",
            "Training Progress: \tEpoch 54 [0/1692 (0.00%)]\t\tLoss: 0.97180\n",
            "Training Progress: \tEpoch 54 [320/1692 (18.87%)]\t\tLoss: 0.86419\n",
            "Training Progress: \tEpoch 54 [640/1692 (37.74%)]\t\tLoss: 0.86999\n",
            "Training Progress: \tEpoch 54 [960/1692 (56.60%)]\t\tLoss: 0.90038\n",
            "Training Progress: \tEpoch 54 [1280/1692 (75.47%)]\t\tLoss: 0.90147\n",
            "Training Progress: \tEpoch 54 [1600/1692 (94.34%)]\t\tLoss: 0.99830\n",
            "\tTrain loss: 0.02467, Accuracy: 1185/1692 (70.04%)\n",
            "\tValidation loss: 0.00431, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00429, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 55 [0/1692 (0.00%)]\t\tLoss: 0.82818\n",
            "Training Progress: \tEpoch 55 [320/1692 (18.87%)]\t\tLoss: 0.78393\n",
            "Training Progress: \tEpoch 55 [640/1692 (37.74%)]\t\tLoss: 0.86317\n",
            "Training Progress: \tEpoch 55 [960/1692 (56.60%)]\t\tLoss: 0.78914\n",
            "Training Progress: \tEpoch 55 [1280/1692 (75.47%)]\t\tLoss: 0.71197\n",
            "Training Progress: \tEpoch 55 [1600/1692 (94.34%)]\t\tLoss: 0.78721\n",
            "\tTrain loss: 0.02404, Accuracy: 1209/1692 (71.45%)\n",
            "\tValidation loss: 0.00430, Accuracy: 111/423 (26.24%)\n",
            "\tTest loss: 0.00426, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 56 [0/1692 (0.00%)]\t\tLoss: 0.96279\n",
            "Training Progress: \tEpoch 56 [320/1692 (18.87%)]\t\tLoss: 0.86236\n",
            "Training Progress: \tEpoch 56 [640/1692 (37.74%)]\t\tLoss: 0.80005\n",
            "Training Progress: \tEpoch 56 [960/1692 (56.60%)]\t\tLoss: 0.77590\n",
            "Training Progress: \tEpoch 56 [1280/1692 (75.47%)]\t\tLoss: 0.87640\n",
            "Training Progress: \tEpoch 56 [1600/1692 (94.34%)]\t\tLoss: 0.82835\n",
            "\tTrain loss: 0.02302, Accuracy: 1212/1692 (71.63%)\n",
            "\tValidation loss: 0.00443, Accuracy: 115/423 (27.19%)\n",
            "\tTest loss: 0.00450, Accuracy: 105/443 (23.70%)\n",
            "\n",
            "Training Progress: \tEpoch 57 [0/1692 (0.00%)]\t\tLoss: 0.86349\n",
            "Training Progress: \tEpoch 57 [320/1692 (18.87%)]\t\tLoss: 0.95050\n",
            "Training Progress: \tEpoch 57 [640/1692 (37.74%)]\t\tLoss: 0.78888\n",
            "Training Progress: \tEpoch 57 [960/1692 (56.60%)]\t\tLoss: 0.84266\n",
            "Training Progress: \tEpoch 57 [1280/1692 (75.47%)]\t\tLoss: 0.78408\n",
            "Training Progress: \tEpoch 57 [1600/1692 (94.34%)]\t\tLoss: 0.75377\n",
            "\tTrain loss: 0.02193, Accuracy: 1255/1692 (74.17%)\n",
            "\tValidation loss: 0.00458, Accuracy: 106/423 (25.06%)\n",
            "\tTest loss: 0.00446, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 58 [0/1692 (0.00%)]\t\tLoss: 0.81049\n",
            "Training Progress: \tEpoch 58 [320/1692 (18.87%)]\t\tLoss: 0.68246\n",
            "Training Progress: \tEpoch 58 [640/1692 (37.74%)]\t\tLoss: 0.62172\n",
            "Training Progress: \tEpoch 58 [960/1692 (56.60%)]\t\tLoss: 0.85097\n",
            "Training Progress: \tEpoch 58 [1280/1692 (75.47%)]\t\tLoss: 0.70231\n",
            "Training Progress: \tEpoch 58 [1600/1692 (94.34%)]\t\tLoss: 0.54569\n",
            "\tTrain loss: 0.02212, Accuracy: 1248/1692 (73.76%)\n",
            "\tValidation loss: 0.00460, Accuracy: 106/423 (25.06%)\n",
            "\tTest loss: 0.00456, Accuracy: 121/443 (27.31%)\n",
            "\n",
            "Training Progress: \tEpoch 59 [0/1692 (0.00%)]\t\tLoss: 0.70127\n",
            "Training Progress: \tEpoch 59 [320/1692 (18.87%)]\t\tLoss: 0.75190\n",
            "Training Progress: \tEpoch 59 [640/1692 (37.74%)]\t\tLoss: 0.89758\n",
            "Training Progress: \tEpoch 59 [960/1692 (56.60%)]\t\tLoss: 0.70880\n",
            "Training Progress: \tEpoch 59 [1280/1692 (75.47%)]\t\tLoss: 0.74768\n",
            "Training Progress: \tEpoch 59 [1600/1692 (94.34%)]\t\tLoss: 0.83824\n",
            "\tTrain loss: 0.02110, Accuracy: 1251/1692 (73.94%)\n",
            "\tValidation loss: 0.00461, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00452, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 60 [0/1692 (0.00%)]\t\tLoss: 0.76422\n",
            "Training Progress: \tEpoch 60 [320/1692 (18.87%)]\t\tLoss: 0.76002\n",
            "Training Progress: \tEpoch 60 [640/1692 (37.74%)]\t\tLoss: 0.67583\n",
            "Training Progress: \tEpoch 60 [960/1692 (56.60%)]\t\tLoss: 0.78597\n",
            "Training Progress: \tEpoch 60 [1280/1692 (75.47%)]\t\tLoss: 0.68085\n",
            "Training Progress: \tEpoch 60 [1600/1692 (94.34%)]\t\tLoss: 0.67202\n",
            "\tTrain loss: 0.02150, Accuracy: 1270/1692 (75.06%)\n",
            "\tValidation loss: 0.00460, Accuracy: 99/423 (23.40%)\n",
            "\tTest loss: 0.00449, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 61 [0/1692 (0.00%)]\t\tLoss: 0.73101\n",
            "Training Progress: \tEpoch 61 [320/1692 (18.87%)]\t\tLoss: 0.67717\n",
            "Training Progress: \tEpoch 61 [640/1692 (37.74%)]\t\tLoss: 0.74580\n",
            "Training Progress: \tEpoch 61 [960/1692 (56.60%)]\t\tLoss: 0.74845\n",
            "Training Progress: \tEpoch 61 [1280/1692 (75.47%)]\t\tLoss: 0.68409\n",
            "Training Progress: \tEpoch 61 [1600/1692 (94.34%)]\t\tLoss: 0.81816\n",
            "\tTrain loss: 0.02112, Accuracy: 1242/1692 (73.40%)\n",
            "\tValidation loss: 0.00465, Accuracy: 114/423 (26.95%)\n",
            "\tTest loss: 0.00462, Accuracy: 120/443 (27.09%)\n",
            "\n",
            "Training Progress: \tEpoch 62 [0/1692 (0.00%)]\t\tLoss: 0.73120\n",
            "Training Progress: \tEpoch 62 [320/1692 (18.87%)]\t\tLoss: 0.70895\n",
            "Training Progress: \tEpoch 62 [640/1692 (37.74%)]\t\tLoss: 0.51704\n",
            "Training Progress: \tEpoch 62 [960/1692 (56.60%)]\t\tLoss: 0.81327\n",
            "Training Progress: \tEpoch 62 [1280/1692 (75.47%)]\t\tLoss: 0.76712\n",
            "Training Progress: \tEpoch 62 [1600/1692 (94.34%)]\t\tLoss: 0.58149\n",
            "\tTrain loss: 0.01981, Accuracy: 1301/1692 (76.89%)\n",
            "\tValidation loss: 0.00472, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00452, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 63 [0/1692 (0.00%)]\t\tLoss: 0.68230\n",
            "Training Progress: \tEpoch 63 [320/1692 (18.87%)]\t\tLoss: 0.66942\n",
            "Training Progress: \tEpoch 63 [640/1692 (37.74%)]\t\tLoss: 0.74403\n",
            "Training Progress: \tEpoch 63 [960/1692 (56.60%)]\t\tLoss: 0.75432\n",
            "Training Progress: \tEpoch 63 [1280/1692 (75.47%)]\t\tLoss: 0.71379\n",
            "Training Progress: \tEpoch 63 [1600/1692 (94.34%)]\t\tLoss: 0.83784\n",
            "\tTrain loss: 0.01937, Accuracy: 1311/1692 (77.48%)\n",
            "\tValidation loss: 0.00483, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00484, Accuracy: 103/443 (23.25%)\n",
            "\n",
            "Training Progress: \tEpoch 64 [0/1692 (0.00%)]\t\tLoss: 0.65903\n",
            "Training Progress: \tEpoch 64 [320/1692 (18.87%)]\t\tLoss: 0.68479\n",
            "Training Progress: \tEpoch 64 [640/1692 (37.74%)]\t\tLoss: 0.64224\n",
            "Training Progress: \tEpoch 64 [960/1692 (56.60%)]\t\tLoss: 0.88469\n",
            "Training Progress: \tEpoch 64 [1280/1692 (75.47%)]\t\tLoss: 0.62765\n",
            "Training Progress: \tEpoch 64 [1600/1692 (94.34%)]\t\tLoss: 0.71175\n",
            "\tTrain loss: 0.01993, Accuracy: 1310/1692 (77.42%)\n",
            "\tValidation loss: 0.00465, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00456, Accuracy: 110/443 (24.83%)\n",
            "\n",
            "Training Progress: \tEpoch 65 [0/1692 (0.00%)]\t\tLoss: 0.73567\n",
            "Training Progress: \tEpoch 65 [320/1692 (18.87%)]\t\tLoss: 0.75747\n",
            "Training Progress: \tEpoch 65 [640/1692 (37.74%)]\t\tLoss: 0.65035\n",
            "Training Progress: \tEpoch 65 [960/1692 (56.60%)]\t\tLoss: 0.69815\n",
            "Training Progress: \tEpoch 65 [1280/1692 (75.47%)]\t\tLoss: 0.66038\n",
            "Training Progress: \tEpoch 65 [1600/1692 (94.34%)]\t\tLoss: 0.67968\n",
            "\tTrain loss: 0.01807, Accuracy: 1329/1692 (78.55%)\n",
            "\tValidation loss: 0.00500, Accuracy: 109/423 (25.77%)\n",
            "\tTest loss: 0.00496, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 66 [0/1692 (0.00%)]\t\tLoss: 0.84827\n",
            "Training Progress: \tEpoch 66 [320/1692 (18.87%)]\t\tLoss: 0.75364\n",
            "Training Progress: \tEpoch 66 [640/1692 (37.74%)]\t\tLoss: 0.65554\n",
            "Training Progress: \tEpoch 66 [960/1692 (56.60%)]\t\tLoss: 0.83786\n",
            "Training Progress: \tEpoch 66 [1280/1692 (75.47%)]\t\tLoss: 0.72046\n",
            "Training Progress: \tEpoch 66 [1600/1692 (94.34%)]\t\tLoss: 0.62780\n",
            "\tTrain loss: 0.01830, Accuracy: 1308/1692 (77.30%)\n",
            "\tValidation loss: 0.00502, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00496, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 67 [0/1692 (0.00%)]\t\tLoss: 0.76425\n",
            "Training Progress: \tEpoch 67 [320/1692 (18.87%)]\t\tLoss: 0.63252\n",
            "Training Progress: \tEpoch 67 [640/1692 (37.74%)]\t\tLoss: 0.71345\n",
            "Training Progress: \tEpoch 67 [960/1692 (56.60%)]\t\tLoss: 0.67127\n",
            "Training Progress: \tEpoch 67 [1280/1692 (75.47%)]\t\tLoss: 0.58721\n",
            "Training Progress: \tEpoch 67 [1600/1692 (94.34%)]\t\tLoss: 0.53365\n",
            "\tTrain loss: 0.01828, Accuracy: 1330/1692 (78.61%)\n",
            "\tValidation loss: 0.00505, Accuracy: 109/423 (25.77%)\n",
            "\tTest loss: 0.00492, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 68 [0/1692 (0.00%)]\t\tLoss: 0.64528\n",
            "Training Progress: \tEpoch 68 [320/1692 (18.87%)]\t\tLoss: 0.58364\n",
            "Training Progress: \tEpoch 68 [640/1692 (37.74%)]\t\tLoss: 0.70230\n",
            "Training Progress: \tEpoch 68 [960/1692 (56.60%)]\t\tLoss: 0.82882\n",
            "Training Progress: \tEpoch 68 [1280/1692 (75.47%)]\t\tLoss: 0.62574\n",
            "Training Progress: \tEpoch 68 [1600/1692 (94.34%)]\t\tLoss: 0.59165\n",
            "\tTrain loss: 0.01820, Accuracy: 1336/1692 (78.96%)\n",
            "\tValidation loss: 0.00518, Accuracy: 97/423 (22.93%)\n",
            "\tTest loss: 0.00492, Accuracy: 121/443 (27.31%)\n",
            "\n",
            "Training Progress: \tEpoch 69 [0/1692 (0.00%)]\t\tLoss: 0.79938\n",
            "Training Progress: \tEpoch 69 [320/1692 (18.87%)]\t\tLoss: 0.81480\n",
            "Training Progress: \tEpoch 69 [640/1692 (37.74%)]\t\tLoss: 0.50868\n",
            "Training Progress: \tEpoch 69 [960/1692 (56.60%)]\t\tLoss: 0.81012\n",
            "Training Progress: \tEpoch 69 [1280/1692 (75.47%)]\t\tLoss: 0.46477\n",
            "Training Progress: \tEpoch 69 [1600/1692 (94.34%)]\t\tLoss: 0.55653\n",
            "\tTrain loss: 0.01745, Accuracy: 1352/1692 (79.91%)\n",
            "\tValidation loss: 0.00506, Accuracy: 105/423 (24.82%)\n",
            "\tTest loss: 0.00494, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 70 [0/1692 (0.00%)]\t\tLoss: 0.68577\n",
            "Training Progress: \tEpoch 70 [320/1692 (18.87%)]\t\tLoss: 0.57237\n",
            "Training Progress: \tEpoch 70 [640/1692 (37.74%)]\t\tLoss: 0.52150\n",
            "Training Progress: \tEpoch 70 [960/1692 (56.60%)]\t\tLoss: 0.90262\n",
            "Training Progress: \tEpoch 70 [1280/1692 (75.47%)]\t\tLoss: 0.46692\n",
            "Training Progress: \tEpoch 70 [1600/1692 (94.34%)]\t\tLoss: 0.49999\n",
            "\tTrain loss: 0.01676, Accuracy: 1387/1692 (81.97%)\n",
            "\tValidation loss: 0.00516, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00504, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 71 [0/1692 (0.00%)]\t\tLoss: 0.41567\n",
            "Training Progress: \tEpoch 71 [320/1692 (18.87%)]\t\tLoss: 0.53820\n",
            "Training Progress: \tEpoch 71 [640/1692 (37.74%)]\t\tLoss: 0.46567\n",
            "Training Progress: \tEpoch 71 [960/1692 (56.60%)]\t\tLoss: 0.80431\n",
            "Training Progress: \tEpoch 71 [1280/1692 (75.47%)]\t\tLoss: 0.48937\n",
            "Training Progress: \tEpoch 71 [1600/1692 (94.34%)]\t\tLoss: 0.67908\n",
            "\tTrain loss: 0.01648, Accuracy: 1384/1692 (81.80%)\n",
            "\tValidation loss: 0.00505, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00487, Accuracy: 120/443 (27.09%)\n",
            "\n",
            "Training Progress: \tEpoch 72 [0/1692 (0.00%)]\t\tLoss: 0.72996\n",
            "Training Progress: \tEpoch 72 [320/1692 (18.87%)]\t\tLoss: 0.57124\n",
            "Training Progress: \tEpoch 72 [640/1692 (37.74%)]\t\tLoss: 0.37325\n",
            "Training Progress: \tEpoch 72 [960/1692 (56.60%)]\t\tLoss: 0.68474\n",
            "Training Progress: \tEpoch 72 [1280/1692 (75.47%)]\t\tLoss: 0.56109\n",
            "Training Progress: \tEpoch 72 [1600/1692 (94.34%)]\t\tLoss: 0.73865\n",
            "\tTrain loss: 0.01621, Accuracy: 1379/1692 (81.50%)\n",
            "\tValidation loss: 0.00532, Accuracy: 98/423 (23.17%)\n",
            "\tTest loss: 0.00513, Accuracy: 124/443 (27.99%)\n",
            "\n",
            "Training Progress: \tEpoch 73 [0/1692 (0.00%)]\t\tLoss: 0.46273\n",
            "Training Progress: \tEpoch 73 [320/1692 (18.87%)]\t\tLoss: 0.63260\n",
            "Training Progress: \tEpoch 73 [640/1692 (37.74%)]\t\tLoss: 0.63012\n",
            "Training Progress: \tEpoch 73 [960/1692 (56.60%)]\t\tLoss: 0.62954\n",
            "Training Progress: \tEpoch 73 [1280/1692 (75.47%)]\t\tLoss: 0.37827\n",
            "Training Progress: \tEpoch 73 [1600/1692 (94.34%)]\t\tLoss: 0.67575\n",
            "\tTrain loss: 0.01497, Accuracy: 1392/1692 (82.27%)\n",
            "\tValidation loss: 0.00549, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00536, Accuracy: 122/443 (27.54%)\n",
            "\n",
            "Training Progress: \tEpoch 74 [0/1692 (0.00%)]\t\tLoss: 0.52013\n",
            "Training Progress: \tEpoch 74 [320/1692 (18.87%)]\t\tLoss: 0.75796\n",
            "Training Progress: \tEpoch 74 [640/1692 (37.74%)]\t\tLoss: 0.60796\n",
            "Training Progress: \tEpoch 74 [960/1692 (56.60%)]\t\tLoss: 0.65777\n",
            "Training Progress: \tEpoch 74 [1280/1692 (75.47%)]\t\tLoss: 0.72506\n",
            "Training Progress: \tEpoch 74 [1600/1692 (94.34%)]\t\tLoss: 0.65369\n",
            "\tTrain loss: 0.01605, Accuracy: 1375/1692 (81.26%)\n",
            "\tValidation loss: 0.00541, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00539, Accuracy: 106/443 (23.93%)\n",
            "\n",
            "Training Progress: \tEpoch 75 [0/1692 (0.00%)]\t\tLoss: 0.69577\n",
            "Training Progress: \tEpoch 75 [320/1692 (18.87%)]\t\tLoss: 0.62589\n",
            "Training Progress: \tEpoch 75 [640/1692 (37.74%)]\t\tLoss: 0.80688\n",
            "Training Progress: \tEpoch 75 [960/1692 (56.60%)]\t\tLoss: 0.78458\n",
            "Training Progress: \tEpoch 75 [1280/1692 (75.47%)]\t\tLoss: 0.59261\n",
            "Training Progress: \tEpoch 75 [1600/1692 (94.34%)]\t\tLoss: 0.51943\n",
            "\tTrain loss: 0.01580, Accuracy: 1389/1692 (82.09%)\n",
            "\tValidation loss: 0.00522, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00516, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 76 [0/1692 (0.00%)]\t\tLoss: 0.56561\n",
            "Training Progress: \tEpoch 76 [320/1692 (18.87%)]\t\tLoss: 0.46177\n",
            "Training Progress: \tEpoch 76 [640/1692 (37.74%)]\t\tLoss: 0.50696\n",
            "Training Progress: \tEpoch 76 [960/1692 (56.60%)]\t\tLoss: 0.62287\n",
            "Training Progress: \tEpoch 76 [1280/1692 (75.47%)]\t\tLoss: 0.42888\n",
            "Training Progress: \tEpoch 76 [1600/1692 (94.34%)]\t\tLoss: 0.49612\n",
            "\tTrain loss: 0.01483, Accuracy: 1406/1692 (83.10%)\n",
            "\tValidation loss: 0.00543, Accuracy: 112/423 (26.48%)\n",
            "\tTest loss: 0.00537, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 77 [0/1692 (0.00%)]\t\tLoss: 0.47220\n",
            "Training Progress: \tEpoch 77 [320/1692 (18.87%)]\t\tLoss: 0.55507\n",
            "Training Progress: \tEpoch 77 [640/1692 (37.74%)]\t\tLoss: 0.38375\n",
            "Training Progress: \tEpoch 77 [960/1692 (56.60%)]\t\tLoss: 0.78706\n",
            "Training Progress: \tEpoch 77 [1280/1692 (75.47%)]\t\tLoss: 0.55912\n",
            "Training Progress: \tEpoch 77 [1600/1692 (94.34%)]\t\tLoss: 0.40507\n",
            "\tTrain loss: 0.01460, Accuracy: 1428/1692 (84.40%)\n",
            "\tValidation loss: 0.00541, Accuracy: 106/423 (25.06%)\n",
            "\tTest loss: 0.00526, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 78 [0/1692 (0.00%)]\t\tLoss: 0.53248\n",
            "Training Progress: \tEpoch 78 [320/1692 (18.87%)]\t\tLoss: 0.64326\n",
            "Training Progress: \tEpoch 78 [640/1692 (37.74%)]\t\tLoss: 0.43669\n",
            "Training Progress: \tEpoch 78 [960/1692 (56.60%)]\t\tLoss: 0.66392\n",
            "Training Progress: \tEpoch 78 [1280/1692 (75.47%)]\t\tLoss: 0.66764\n",
            "Training Progress: \tEpoch 78 [1600/1692 (94.34%)]\t\tLoss: 0.38801\n",
            "\tTrain loss: 0.01473, Accuracy: 1419/1692 (83.87%)\n",
            "\tValidation loss: 0.00548, Accuracy: 91/423 (21.51%)\n",
            "\tTest loss: 0.00530, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 79 [0/1692 (0.00%)]\t\tLoss: 0.81623\n",
            "Training Progress: \tEpoch 79 [320/1692 (18.87%)]\t\tLoss: 0.44848\n",
            "Training Progress: \tEpoch 79 [640/1692 (37.74%)]\t\tLoss: 0.72960\n",
            "Training Progress: \tEpoch 79 [960/1692 (56.60%)]\t\tLoss: 0.57625\n",
            "Training Progress: \tEpoch 79 [1280/1692 (75.47%)]\t\tLoss: 0.61107\n",
            "Training Progress: \tEpoch 79 [1600/1692 (94.34%)]\t\tLoss: 0.34483\n",
            "\tTrain loss: 0.01309, Accuracy: 1436/1692 (84.87%)\n",
            "\tValidation loss: 0.00560, Accuracy: 109/423 (25.77%)\n",
            "\tTest loss: 0.00547, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 80 [0/1692 (0.00%)]\t\tLoss: 0.66209\n",
            "Training Progress: \tEpoch 80 [320/1692 (18.87%)]\t\tLoss: 0.57113\n",
            "Training Progress: \tEpoch 80 [640/1692 (37.74%)]\t\tLoss: 0.51290\n",
            "Training Progress: \tEpoch 80 [960/1692 (56.60%)]\t\tLoss: 0.48950\n",
            "Training Progress: \tEpoch 80 [1280/1692 (75.47%)]\t\tLoss: 0.62569\n",
            "Training Progress: \tEpoch 80 [1600/1692 (94.34%)]\t\tLoss: 0.67538\n",
            "\tTrain loss: 0.01328, Accuracy: 1443/1692 (85.28%)\n",
            "\tValidation loss: 0.00572, Accuracy: 96/423 (22.70%)\n",
            "\tTest loss: 0.00551, Accuracy: 107/443 (24.15%)\n",
            "\n",
            "Training Progress: \tEpoch 81 [0/1692 (0.00%)]\t\tLoss: 0.46112\n",
            "Training Progress: \tEpoch 81 [320/1692 (18.87%)]\t\tLoss: 0.49533\n",
            "Training Progress: \tEpoch 81 [640/1692 (37.74%)]\t\tLoss: 0.54044\n",
            "Training Progress: \tEpoch 81 [960/1692 (56.60%)]\t\tLoss: 0.58494\n",
            "Training Progress: \tEpoch 81 [1280/1692 (75.47%)]\t\tLoss: 0.43703\n",
            "Training Progress: \tEpoch 81 [1600/1692 (94.34%)]\t\tLoss: 0.24487\n",
            "\tTrain loss: 0.01390, Accuracy: 1407/1692 (83.16%)\n",
            "\tValidation loss: 0.00598, Accuracy: 93/423 (21.99%)\n",
            "\tTest loss: 0.00549, Accuracy: 120/443 (27.09%)\n",
            "\n",
            "Training Progress: \tEpoch 82 [0/1692 (0.00%)]\t\tLoss: 0.49054\n",
            "Training Progress: \tEpoch 82 [320/1692 (18.87%)]\t\tLoss: 0.69057\n",
            "Training Progress: \tEpoch 82 [640/1692 (37.74%)]\t\tLoss: 0.46303\n",
            "Training Progress: \tEpoch 82 [960/1692 (56.60%)]\t\tLoss: 0.77851\n",
            "Training Progress: \tEpoch 82 [1280/1692 (75.47%)]\t\tLoss: 0.61340\n",
            "Training Progress: \tEpoch 82 [1600/1692 (94.34%)]\t\tLoss: 0.48442\n",
            "\tTrain loss: 0.01346, Accuracy: 1449/1692 (85.64%)\n",
            "\tValidation loss: 0.00587, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00566, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 83 [0/1692 (0.00%)]\t\tLoss: 0.52446\n",
            "Training Progress: \tEpoch 83 [320/1692 (18.87%)]\t\tLoss: 0.36909\n",
            "Training Progress: \tEpoch 83 [640/1692 (37.74%)]\t\tLoss: 0.34410\n",
            "Training Progress: \tEpoch 83 [960/1692 (56.60%)]\t\tLoss: 0.67194\n",
            "Training Progress: \tEpoch 83 [1280/1692 (75.47%)]\t\tLoss: 0.49772\n",
            "Training Progress: \tEpoch 83 [1600/1692 (94.34%)]\t\tLoss: 0.34512\n",
            "\tTrain loss: 0.01269, Accuracy: 1443/1692 (85.28%)\n",
            "\tValidation loss: 0.00599, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00565, Accuracy: 121/443 (27.31%)\n",
            "\n",
            "Training Progress: \tEpoch 84 [0/1692 (0.00%)]\t\tLoss: 0.44258\n",
            "Training Progress: \tEpoch 84 [320/1692 (18.87%)]\t\tLoss: 0.53341\n",
            "Training Progress: \tEpoch 84 [640/1692 (37.74%)]\t\tLoss: 0.39126\n",
            "Training Progress: \tEpoch 84 [960/1692 (56.60%)]\t\tLoss: 0.48368\n",
            "Training Progress: \tEpoch 84 [1280/1692 (75.47%)]\t\tLoss: 0.49893\n",
            "Training Progress: \tEpoch 84 [1600/1692 (94.34%)]\t\tLoss: 0.45094\n",
            "\tTrain loss: 0.01218, Accuracy: 1478/1692 (87.35%)\n",
            "\tValidation loss: 0.00604, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00579, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 85 [0/1692 (0.00%)]\t\tLoss: 0.51563\n",
            "Training Progress: \tEpoch 85 [320/1692 (18.87%)]\t\tLoss: 0.49119\n",
            "Training Progress: \tEpoch 85 [640/1692 (37.74%)]\t\tLoss: 0.60016\n",
            "Training Progress: \tEpoch 85 [960/1692 (56.60%)]\t\tLoss: 0.55271\n",
            "Training Progress: \tEpoch 85 [1280/1692 (75.47%)]\t\tLoss: 0.49137\n",
            "Training Progress: \tEpoch 85 [1600/1692 (94.34%)]\t\tLoss: 0.33269\n",
            "\tTrain loss: 0.01290, Accuracy: 1429/1692 (84.46%)\n",
            "\tValidation loss: 0.00595, Accuracy: 98/423 (23.17%)\n",
            "\tTest loss: 0.00563, Accuracy: 128/443 (28.89%)\n",
            "\n",
            "Training Progress: \tEpoch 86 [0/1692 (0.00%)]\t\tLoss: 0.57263\n",
            "Training Progress: \tEpoch 86 [320/1692 (18.87%)]\t\tLoss: 0.45416\n",
            "Training Progress: \tEpoch 86 [640/1692 (37.74%)]\t\tLoss: 0.33103\n",
            "Training Progress: \tEpoch 86 [960/1692 (56.60%)]\t\tLoss: 0.68115\n",
            "Training Progress: \tEpoch 86 [1280/1692 (75.47%)]\t\tLoss: 0.38062\n",
            "Training Progress: \tEpoch 86 [1600/1692 (94.34%)]\t\tLoss: 0.50885\n",
            "\tTrain loss: 0.01220, Accuracy: 1471/1692 (86.94%)\n",
            "\tValidation loss: 0.00598, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00588, Accuracy: 115/443 (25.96%)\n",
            "\n",
            "Training Progress: \tEpoch 87 [0/1692 (0.00%)]\t\tLoss: 0.38178\n",
            "Training Progress: \tEpoch 87 [320/1692 (18.87%)]\t\tLoss: 0.47849\n",
            "Training Progress: \tEpoch 87 [640/1692 (37.74%)]\t\tLoss: 0.52994\n",
            "Training Progress: \tEpoch 87 [960/1692 (56.60%)]\t\tLoss: 0.55816\n",
            "Training Progress: \tEpoch 87 [1280/1692 (75.47%)]\t\tLoss: 0.47684\n",
            "Training Progress: \tEpoch 87 [1600/1692 (94.34%)]\t\tLoss: 0.39901\n",
            "\tTrain loss: 0.01224, Accuracy: 1454/1692 (85.93%)\n",
            "\tValidation loss: 0.00612, Accuracy: 97/423 (22.93%)\n",
            "\tTest loss: 0.00598, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 88 [0/1692 (0.00%)]\t\tLoss: 0.50462\n",
            "Training Progress: \tEpoch 88 [320/1692 (18.87%)]\t\tLoss: 0.76133\n",
            "Training Progress: \tEpoch 88 [640/1692 (37.74%)]\t\tLoss: 0.47001\n",
            "Training Progress: \tEpoch 88 [960/1692 (56.60%)]\t\tLoss: 0.79907\n",
            "Training Progress: \tEpoch 88 [1280/1692 (75.47%)]\t\tLoss: 0.53040\n",
            "Training Progress: \tEpoch 88 [1600/1692 (94.34%)]\t\tLoss: 0.57771\n",
            "\tTrain loss: 0.01180, Accuracy: 1470/1692 (86.88%)\n",
            "\tValidation loss: 0.00594, Accuracy: 97/423 (22.93%)\n",
            "\tTest loss: 0.00579, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 89 [0/1692 (0.00%)]\t\tLoss: 0.41760\n",
            "Training Progress: \tEpoch 89 [320/1692 (18.87%)]\t\tLoss: 0.56605\n",
            "Training Progress: \tEpoch 89 [640/1692 (37.74%)]\t\tLoss: 0.43897\n",
            "Training Progress: \tEpoch 89 [960/1692 (56.60%)]\t\tLoss: 0.58110\n",
            "Training Progress: \tEpoch 89 [1280/1692 (75.47%)]\t\tLoss: 0.46626\n",
            "Training Progress: \tEpoch 89 [1600/1692 (94.34%)]\t\tLoss: 0.71123\n",
            "\tTrain loss: 0.01265, Accuracy: 1447/1692 (85.52%)\n",
            "\tValidation loss: 0.00615, Accuracy: 100/423 (23.64%)\n",
            "\tTest loss: 0.00583, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 90 [0/1692 (0.00%)]\t\tLoss: 0.65100\n",
            "Training Progress: \tEpoch 90 [320/1692 (18.87%)]\t\tLoss: 0.45787\n",
            "Training Progress: \tEpoch 90 [640/1692 (37.74%)]\t\tLoss: 0.37078\n",
            "Training Progress: \tEpoch 90 [960/1692 (56.60%)]\t\tLoss: 0.39736\n",
            "Training Progress: \tEpoch 90 [1280/1692 (75.47%)]\t\tLoss: 0.48662\n",
            "Training Progress: \tEpoch 90 [1600/1692 (94.34%)]\t\tLoss: 0.41092\n",
            "\tTrain loss: 0.01072, Accuracy: 1480/1692 (87.47%)\n",
            "\tValidation loss: 0.00640, Accuracy: 102/423 (24.11%)\n",
            "\tTest loss: 0.00613, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 91 [0/1692 (0.00%)]\t\tLoss: 0.53891\n",
            "Training Progress: \tEpoch 91 [320/1692 (18.87%)]\t\tLoss: 0.43526\n",
            "Training Progress: \tEpoch 91 [640/1692 (37.74%)]\t\tLoss: 0.31332\n",
            "Training Progress: \tEpoch 91 [960/1692 (56.60%)]\t\tLoss: 0.65446\n",
            "Training Progress: \tEpoch 91 [1280/1692 (75.47%)]\t\tLoss: 0.59688\n",
            "Training Progress: \tEpoch 91 [1600/1692 (94.34%)]\t\tLoss: 0.58007\n",
            "\tTrain loss: 0.01147, Accuracy: 1473/1692 (87.06%)\n",
            "\tValidation loss: 0.00637, Accuracy: 98/423 (23.17%)\n",
            "\tTest loss: 0.00598, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 92 [0/1692 (0.00%)]\t\tLoss: 0.49242\n",
            "Training Progress: \tEpoch 92 [320/1692 (18.87%)]\t\tLoss: 0.36692\n",
            "Training Progress: \tEpoch 92 [640/1692 (37.74%)]\t\tLoss: 0.24802\n",
            "Training Progress: \tEpoch 92 [960/1692 (56.60%)]\t\tLoss: 0.45277\n",
            "Training Progress: \tEpoch 92 [1280/1692 (75.47%)]\t\tLoss: 0.49061\n",
            "Training Progress: \tEpoch 92 [1600/1692 (94.34%)]\t\tLoss: 0.36458\n",
            "\tTrain loss: 0.01109, Accuracy: 1489/1692 (88.00%)\n",
            "\tValidation loss: 0.00662, Accuracy: 100/423 (23.64%)\n",
            "\tTest loss: 0.00631, Accuracy: 107/443 (24.15%)\n",
            "\n",
            "Training Progress: \tEpoch 93 [0/1692 (0.00%)]\t\tLoss: 0.31478\n",
            "Training Progress: \tEpoch 93 [320/1692 (18.87%)]\t\tLoss: 0.36617\n",
            "Training Progress: \tEpoch 93 [640/1692 (37.74%)]\t\tLoss: 0.42546\n",
            "Training Progress: \tEpoch 93 [960/1692 (56.60%)]\t\tLoss: 0.48147\n",
            "Training Progress: \tEpoch 93 [1280/1692 (75.47%)]\t\tLoss: 0.46072\n",
            "Training Progress: \tEpoch 93 [1600/1692 (94.34%)]\t\tLoss: 0.25111\n",
            "\tTrain loss: 0.01019, Accuracy: 1514/1692 (89.48%)\n",
            "\tValidation loss: 0.00638, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00607, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 94 [0/1692 (0.00%)]\t\tLoss: 0.50755\n",
            "Training Progress: \tEpoch 94 [320/1692 (18.87%)]\t\tLoss: 0.51812\n",
            "Training Progress: \tEpoch 94 [640/1692 (37.74%)]\t\tLoss: 0.25622\n",
            "Training Progress: \tEpoch 94 [960/1692 (56.60%)]\t\tLoss: 0.45625\n",
            "Training Progress: \tEpoch 94 [1280/1692 (75.47%)]\t\tLoss: 0.23910\n",
            "Training Progress: \tEpoch 94 [1600/1692 (94.34%)]\t\tLoss: 0.49770\n",
            "\tTrain loss: 0.01090, Accuracy: 1493/1692 (88.24%)\n",
            "\tValidation loss: 0.00646, Accuracy: 95/423 (22.46%)\n",
            "\tTest loss: 0.00611, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 95 [0/1692 (0.00%)]\t\tLoss: 0.55639\n",
            "Training Progress: \tEpoch 95 [320/1692 (18.87%)]\t\tLoss: 0.50711\n",
            "Training Progress: \tEpoch 95 [640/1692 (37.74%)]\t\tLoss: 0.21875\n",
            "Training Progress: \tEpoch 95 [960/1692 (56.60%)]\t\tLoss: 0.50354\n",
            "Training Progress: \tEpoch 95 [1280/1692 (75.47%)]\t\tLoss: 0.48503\n",
            "Training Progress: \tEpoch 95 [1600/1692 (94.34%)]\t\tLoss: 0.27146\n",
            "\tTrain loss: 0.01090, Accuracy: 1474/1692 (87.12%)\n",
            "\tValidation loss: 0.00680, Accuracy: 94/423 (22.22%)\n",
            "\tTest loss: 0.00649, Accuracy: 105/443 (23.70%)\n",
            "\n",
            "Training Progress: \tEpoch 96 [0/1692 (0.00%)]\t\tLoss: 0.43705\n",
            "Training Progress: \tEpoch 96 [320/1692 (18.87%)]\t\tLoss: 0.28995\n",
            "Training Progress: \tEpoch 96 [640/1692 (37.74%)]\t\tLoss: 0.49541\n",
            "Training Progress: \tEpoch 96 [960/1692 (56.60%)]\t\tLoss: 0.66836\n",
            "Training Progress: \tEpoch 96 [1280/1692 (75.47%)]\t\tLoss: 0.39438\n",
            "Training Progress: \tEpoch 96 [1600/1692 (94.34%)]\t\tLoss: 0.25615\n",
            "\tTrain loss: 0.00980, Accuracy: 1525/1692 (90.13%)\n",
            "\tValidation loss: 0.00645, Accuracy: 114/423 (26.95%)\n",
            "\tTest loss: 0.00616, Accuracy: 100/443 (22.57%)\n",
            "\n",
            "Training Progress: \tEpoch 97 [0/1692 (0.00%)]\t\tLoss: 0.35276\n",
            "Training Progress: \tEpoch 97 [320/1692 (18.87%)]\t\tLoss: 0.63500\n",
            "Training Progress: \tEpoch 97 [640/1692 (37.74%)]\t\tLoss: 0.55999\n",
            "Training Progress: \tEpoch 97 [960/1692 (56.60%)]\t\tLoss: 0.62895\n",
            "Training Progress: \tEpoch 97 [1280/1692 (75.47%)]\t\tLoss: 0.24058\n",
            "Training Progress: \tEpoch 97 [1600/1692 (94.34%)]\t\tLoss: 0.30621\n",
            "\tTrain loss: 0.01041, Accuracy: 1499/1692 (88.59%)\n",
            "\tValidation loss: 0.00654, Accuracy: 103/423 (24.35%)\n",
            "\tTest loss: 0.00616, Accuracy: 121/443 (27.31%)\n",
            "\n",
            "Training Progress: \tEpoch 98 [0/1692 (0.00%)]\t\tLoss: 0.56483\n",
            "Training Progress: \tEpoch 98 [320/1692 (18.87%)]\t\tLoss: 0.51422\n",
            "Training Progress: \tEpoch 98 [640/1692 (37.74%)]\t\tLoss: 0.26681\n",
            "Training Progress: \tEpoch 98 [960/1692 (56.60%)]\t\tLoss: 0.54970\n",
            "Training Progress: \tEpoch 98 [1280/1692 (75.47%)]\t\tLoss: 0.34307\n",
            "Training Progress: \tEpoch 98 [1600/1692 (94.34%)]\t\tLoss: 0.28237\n",
            "\tTrain loss: 0.01032, Accuracy: 1502/1692 (88.77%)\n",
            "\tValidation loss: 0.00645, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00637, Accuracy: 115/443 (25.96%)\n",
            "\n",
            "Training Progress: \tEpoch 99 [0/1692 (0.00%)]\t\tLoss: 0.54382\n",
            "Training Progress: \tEpoch 99 [320/1692 (18.87%)]\t\tLoss: 0.26666\n",
            "Training Progress: \tEpoch 99 [640/1692 (37.74%)]\t\tLoss: 0.32837\n",
            "Training Progress: \tEpoch 99 [960/1692 (56.60%)]\t\tLoss: 0.31982\n",
            "Training Progress: \tEpoch 99 [1280/1692 (75.47%)]\t\tLoss: 0.25686\n",
            "Training Progress: \tEpoch 99 [1600/1692 (94.34%)]\t\tLoss: 0.29219\n",
            "\tTrain loss: 0.00934, Accuracy: 1519/1692 (89.78%)\n",
            "\tValidation loss: 0.00668, Accuracy: 97/423 (22.93%)\n",
            "\tTest loss: 0.00645, Accuracy: 119/443 (26.86%)\n",
            "\n",
            "Training Progress: \tEpoch 100 [0/1692 (0.00%)]\t\tLoss: 0.26766\n",
            "Training Progress: \tEpoch 100 [320/1692 (18.87%)]\t\tLoss: 0.49273\n",
            "Training Progress: \tEpoch 100 [640/1692 (37.74%)]\t\tLoss: 0.21904\n",
            "Training Progress: \tEpoch 100 [960/1692 (56.60%)]\t\tLoss: 0.46120\n",
            "Training Progress: \tEpoch 100 [1280/1692 (75.47%)]\t\tLoss: 0.49847\n",
            "Training Progress: \tEpoch 100 [1600/1692 (94.34%)]\t\tLoss: 0.47074\n",
            "\tTrain loss: 0.00996, Accuracy: 1506/1692 (89.01%)\n",
            "\tValidation loss: 0.00630, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00628, Accuracy: 125/443 (28.22%)\n",
            "\n",
            "Best validation accuracy:\n",
            "0.29550827423167847\n",
            "Best test accuracy:\n",
            "0.29571106094808125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAEICAYAAACkmHavAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jyP29OkKe_t0"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cCBfGtuyckWL",
        "outputId": "06431671-5a2b-409d-9476-c1e06ad6bc65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = GRU().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=BETAS, eps=EPS, weight_decay=DECAY)\n",
        "train_and_evaluate(model, optimizer, data_loaders, num_epochs=EPOCHS)\n",
        "del model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Progress: \tEpoch 1 [0/1692 (0.00%)]\t\tLoss: 1.46978\n",
            "Training Progress: \tEpoch 1 [320/1692 (18.87%)]\t\tLoss: 1.46479\n",
            "Training Progress: \tEpoch 1 [640/1692 (37.74%)]\t\tLoss: 1.38789\n",
            "Training Progress: \tEpoch 1 [960/1692 (56.60%)]\t\tLoss: 1.43300\n",
            "Training Progress: \tEpoch 1 [1280/1692 (75.47%)]\t\tLoss: 1.41300\n",
            "Training Progress: \tEpoch 1 [1600/1692 (94.34%)]\t\tLoss: 1.36273\n",
            "\tTrain loss: 0.04353, Accuracy: 466/1692 (27.54%)\n",
            "\tValidation loss: 0.00331, Accuracy: 109/423 (25.77%)\n",
            "\tTest loss: 0.00316, Accuracy: 110/443 (24.83%)\n",
            "\n",
            "Training Progress: \tEpoch 2 [0/1692 (0.00%)]\t\tLoss: 1.46231\n",
            "Training Progress: \tEpoch 2 [320/1692 (18.87%)]\t\tLoss: 1.47586\n",
            "Training Progress: \tEpoch 2 [640/1692 (37.74%)]\t\tLoss: 1.36281\n",
            "Training Progress: \tEpoch 2 [960/1692 (56.60%)]\t\tLoss: 1.41151\n",
            "Training Progress: \tEpoch 2 [1280/1692 (75.47%)]\t\tLoss: 1.50655\n",
            "Training Progress: \tEpoch 2 [1600/1692 (94.34%)]\t\tLoss: 1.40276\n",
            "\tTrain loss: 0.04318, Accuracy: 447/1692 (26.42%)\n",
            "\tValidation loss: 0.00331, Accuracy: 99/423 (23.40%)\n",
            "\tTest loss: 0.00314, Accuracy: 121/443 (27.31%)\n",
            "\n",
            "Training Progress: \tEpoch 3 [0/1692 (0.00%)]\t\tLoss: 1.45511\n",
            "Training Progress: \tEpoch 3 [320/1692 (18.87%)]\t\tLoss: 1.50455\n",
            "Training Progress: \tEpoch 3 [640/1692 (37.74%)]\t\tLoss: 1.38102\n",
            "Training Progress: \tEpoch 3 [960/1692 (56.60%)]\t\tLoss: 1.40621\n",
            "Training Progress: \tEpoch 3 [1280/1692 (75.47%)]\t\tLoss: 1.44141\n",
            "Training Progress: \tEpoch 3 [1600/1692 (94.34%)]\t\tLoss: 1.40704\n",
            "\tTrain loss: 0.04299, Accuracy: 520/1692 (30.73%)\n",
            "\tValidation loss: 0.00329, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00316, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 4 [0/1692 (0.00%)]\t\tLoss: 1.39224\n",
            "Training Progress: \tEpoch 4 [320/1692 (18.87%)]\t\tLoss: 1.43794\n",
            "Training Progress: \tEpoch 4 [640/1692 (37.74%)]\t\tLoss: 1.35228\n",
            "Training Progress: \tEpoch 4 [960/1692 (56.60%)]\t\tLoss: 1.38913\n",
            "Training Progress: \tEpoch 4 [1280/1692 (75.47%)]\t\tLoss: 1.41928\n",
            "Training Progress: \tEpoch 4 [1600/1692 (94.34%)]\t\tLoss: 1.38446\n",
            "\tTrain loss: 0.04281, Accuracy: 525/1692 (31.03%)\n",
            "\tValidation loss: 0.00329, Accuracy: 112/423 (26.48%)\n",
            "\tTest loss: 0.00316, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 5 [0/1692 (0.00%)]\t\tLoss: 1.39322\n",
            "Training Progress: \tEpoch 5 [320/1692 (18.87%)]\t\tLoss: 1.37952\n",
            "Training Progress: \tEpoch 5 [640/1692 (37.74%)]\t\tLoss: 1.34491\n",
            "Training Progress: \tEpoch 5 [960/1692 (56.60%)]\t\tLoss: 1.39213\n",
            "Training Progress: \tEpoch 5 [1280/1692 (75.47%)]\t\tLoss: 1.38953\n",
            "Training Progress: \tEpoch 5 [1600/1692 (94.34%)]\t\tLoss: 1.35707\n",
            "\tTrain loss: 0.04265, Accuracy: 536/1692 (31.68%)\n",
            "\tValidation loss: 0.00330, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00316, Accuracy: 124/443 (27.99%)\n",
            "\n",
            "Training Progress: \tEpoch 6 [0/1692 (0.00%)]\t\tLoss: 1.38705\n",
            "Training Progress: \tEpoch 6 [320/1692 (18.87%)]\t\tLoss: 1.41053\n",
            "Training Progress: \tEpoch 6 [640/1692 (37.74%)]\t\tLoss: 1.40779\n",
            "Training Progress: \tEpoch 6 [960/1692 (56.60%)]\t\tLoss: 1.38033\n",
            "Training Progress: \tEpoch 6 [1280/1692 (75.47%)]\t\tLoss: 1.42147\n",
            "Training Progress: \tEpoch 6 [1600/1692 (94.34%)]\t\tLoss: 1.38634\n",
            "\tTrain loss: 0.04256, Accuracy: 565/1692 (33.39%)\n",
            "\tValidation loss: 0.00329, Accuracy: 116/423 (27.42%)\n",
            "\tTest loss: 0.00316, Accuracy: 115/443 (25.96%)\n",
            "\n",
            "Training Progress: \tEpoch 7 [0/1692 (0.00%)]\t\tLoss: 1.42215\n",
            "Training Progress: \tEpoch 7 [320/1692 (18.87%)]\t\tLoss: 1.39887\n",
            "Training Progress: \tEpoch 7 [640/1692 (37.74%)]\t\tLoss: 1.38094\n",
            "Training Progress: \tEpoch 7 [960/1692 (56.60%)]\t\tLoss: 1.38320\n",
            "Training Progress: \tEpoch 7 [1280/1692 (75.47%)]\t\tLoss: 1.41688\n",
            "Training Progress: \tEpoch 7 [1600/1692 (94.34%)]\t\tLoss: 1.37157\n",
            "\tTrain loss: 0.04265, Accuracy: 553/1692 (32.68%)\n",
            "\tValidation loss: 0.00329, Accuracy: 111/423 (26.24%)\n",
            "\tTest loss: 0.00316, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 8 [0/1692 (0.00%)]\t\tLoss: 1.34557\n",
            "Training Progress: \tEpoch 8 [320/1692 (18.87%)]\t\tLoss: 1.34046\n",
            "Training Progress: \tEpoch 8 [640/1692 (37.74%)]\t\tLoss: 1.38859\n",
            "Training Progress: \tEpoch 8 [960/1692 (56.60%)]\t\tLoss: 1.37091\n",
            "Training Progress: \tEpoch 8 [1280/1692 (75.47%)]\t\tLoss: 1.43262\n",
            "Training Progress: \tEpoch 8 [1600/1692 (94.34%)]\t\tLoss: 1.38396\n",
            "\tTrain loss: 0.04247, Accuracy: 571/1692 (33.75%)\n",
            "\tValidation loss: 0.00330, Accuracy: 102/423 (24.11%)\n",
            "\tTest loss: 0.00316, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 9 [0/1692 (0.00%)]\t\tLoss: 1.40253\n",
            "Training Progress: \tEpoch 9 [320/1692 (18.87%)]\t\tLoss: 1.40184\n",
            "Training Progress: \tEpoch 9 [640/1692 (37.74%)]\t\tLoss: 1.43531\n",
            "Training Progress: \tEpoch 9 [960/1692 (56.60%)]\t\tLoss: 1.40018\n",
            "Training Progress: \tEpoch 9 [1280/1692 (75.47%)]\t\tLoss: 1.40147\n",
            "Training Progress: \tEpoch 9 [1600/1692 (94.34%)]\t\tLoss: 1.42867\n",
            "\tTrain loss: 0.04245, Accuracy: 561/1692 (33.16%)\n",
            "\tValidation loss: 0.00329, Accuracy: 109/423 (25.77%)\n",
            "\tTest loss: 0.00315, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 10 [0/1692 (0.00%)]\t\tLoss: 1.37836\n",
            "Training Progress: \tEpoch 10 [320/1692 (18.87%)]\t\tLoss: 1.38970\n",
            "Training Progress: \tEpoch 10 [640/1692 (37.74%)]\t\tLoss: 1.37039\n",
            "Training Progress: \tEpoch 10 [960/1692 (56.60%)]\t\tLoss: 1.41665\n",
            "Training Progress: \tEpoch 10 [1280/1692 (75.47%)]\t\tLoss: 1.38401\n",
            "Training Progress: \tEpoch 10 [1600/1692 (94.34%)]\t\tLoss: 1.35030\n",
            "\tTrain loss: 0.04242, Accuracy: 572/1692 (33.81%)\n",
            "\tValidation loss: 0.00332, Accuracy: 103/423 (24.35%)\n",
            "\tTest loss: 0.00314, Accuracy: 127/443 (28.67%)\n",
            "\n",
            "Training Progress: \tEpoch 11 [0/1692 (0.00%)]\t\tLoss: 1.38453\n",
            "Training Progress: \tEpoch 11 [320/1692 (18.87%)]\t\tLoss: 1.33168\n",
            "Training Progress: \tEpoch 11 [640/1692 (37.74%)]\t\tLoss: 1.39223\n",
            "Training Progress: \tEpoch 11 [960/1692 (56.60%)]\t\tLoss: 1.39668\n",
            "Training Progress: \tEpoch 11 [1280/1692 (75.47%)]\t\tLoss: 1.42014\n",
            "Training Progress: \tEpoch 11 [1600/1692 (94.34%)]\t\tLoss: 1.36756\n",
            "\tTrain loss: 0.04223, Accuracy: 600/1692 (35.46%)\n",
            "\tValidation loss: 0.00332, Accuracy: 99/423 (23.40%)\n",
            "\tTest loss: 0.00315, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 12 [0/1692 (0.00%)]\t\tLoss: 1.36396\n",
            "Training Progress: \tEpoch 12 [320/1692 (18.87%)]\t\tLoss: 1.38533\n",
            "Training Progress: \tEpoch 12 [640/1692 (37.74%)]\t\tLoss: 1.39000\n",
            "Training Progress: \tEpoch 12 [960/1692 (56.60%)]\t\tLoss: 1.32780\n",
            "Training Progress: \tEpoch 12 [1280/1692 (75.47%)]\t\tLoss: 1.37067\n",
            "Training Progress: \tEpoch 12 [1600/1692 (94.34%)]\t\tLoss: 1.40104\n",
            "\tTrain loss: 0.04208, Accuracy: 606/1692 (35.82%)\n",
            "\tValidation loss: 0.00330, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00317, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 13 [0/1692 (0.00%)]\t\tLoss: 1.36753\n",
            "Training Progress: \tEpoch 13 [320/1692 (18.87%)]\t\tLoss: 1.40805\n",
            "Training Progress: \tEpoch 13 [640/1692 (37.74%)]\t\tLoss: 1.36493\n",
            "Training Progress: \tEpoch 13 [960/1692 (56.60%)]\t\tLoss: 1.35643\n",
            "Training Progress: \tEpoch 13 [1280/1692 (75.47%)]\t\tLoss: 1.36626\n",
            "Training Progress: \tEpoch 13 [1600/1692 (94.34%)]\t\tLoss: 1.37335\n",
            "\tTrain loss: 0.04201, Accuracy: 591/1692 (34.93%)\n",
            "\tValidation loss: 0.00331, Accuracy: 112/423 (26.48%)\n",
            "\tTest loss: 0.00316, Accuracy: 123/443 (27.77%)\n",
            "\n",
            "Training Progress: \tEpoch 14 [0/1692 (0.00%)]\t\tLoss: 1.36642\n",
            "Training Progress: \tEpoch 14 [320/1692 (18.87%)]\t\tLoss: 1.36879\n",
            "Training Progress: \tEpoch 14 [640/1692 (37.74%)]\t\tLoss: 1.37848\n",
            "Training Progress: \tEpoch 14 [960/1692 (56.60%)]\t\tLoss: 1.35228\n",
            "Training Progress: \tEpoch 14 [1280/1692 (75.47%)]\t\tLoss: 1.32584\n",
            "Training Progress: \tEpoch 14 [1600/1692 (94.34%)]\t\tLoss: 1.36312\n",
            "\tTrain loss: 0.04190, Accuracy: 618/1692 (36.52%)\n",
            "\tValidation loss: 0.00331, Accuracy: 112/423 (26.48%)\n",
            "\tTest loss: 0.00317, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 15 [0/1692 (0.00%)]\t\tLoss: 1.34105\n",
            "Training Progress: \tEpoch 15 [320/1692 (18.87%)]\t\tLoss: 1.36238\n",
            "Training Progress: \tEpoch 15 [640/1692 (37.74%)]\t\tLoss: 1.37482\n",
            "Training Progress: \tEpoch 15 [960/1692 (56.60%)]\t\tLoss: 1.42070\n",
            "Training Progress: \tEpoch 15 [1280/1692 (75.47%)]\t\tLoss: 1.37460\n",
            "Training Progress: \tEpoch 15 [1600/1692 (94.34%)]\t\tLoss: 1.36871\n",
            "\tTrain loss: 0.04173, Accuracy: 624/1692 (36.88%)\n",
            "\tValidation loss: 0.00332, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00317, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 16 [0/1692 (0.00%)]\t\tLoss: 1.35428\n",
            "Training Progress: \tEpoch 16 [320/1692 (18.87%)]\t\tLoss: 1.34814\n",
            "Training Progress: \tEpoch 16 [640/1692 (37.74%)]\t\tLoss: 1.34784\n",
            "Training Progress: \tEpoch 16 [960/1692 (56.60%)]\t\tLoss: 1.33607\n",
            "Training Progress: \tEpoch 16 [1280/1692 (75.47%)]\t\tLoss: 1.37441\n",
            "Training Progress: \tEpoch 16 [1600/1692 (94.34%)]\t\tLoss: 1.32171\n",
            "\tTrain loss: 0.04136, Accuracy: 648/1692 (38.30%)\n",
            "\tValidation loss: 0.00333, Accuracy: 111/423 (26.24%)\n",
            "\tTest loss: 0.00318, Accuracy: 104/443 (23.48%)\n",
            "\n",
            "Training Progress: \tEpoch 17 [0/1692 (0.00%)]\t\tLoss: 1.36659\n",
            "Training Progress: \tEpoch 17 [320/1692 (18.87%)]\t\tLoss: 1.39846\n",
            "Training Progress: \tEpoch 17 [640/1692 (37.74%)]\t\tLoss: 1.39374\n",
            "Training Progress: \tEpoch 17 [960/1692 (56.60%)]\t\tLoss: 1.41239\n",
            "Training Progress: \tEpoch 17 [1280/1692 (75.47%)]\t\tLoss: 1.31622\n",
            "Training Progress: \tEpoch 17 [1600/1692 (94.34%)]\t\tLoss: 1.35827\n",
            "\tTrain loss: 0.04137, Accuracy: 652/1692 (38.53%)\n",
            "\tValidation loss: 0.00333, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00321, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 18 [0/1692 (0.00%)]\t\tLoss: 1.35179\n",
            "Training Progress: \tEpoch 18 [320/1692 (18.87%)]\t\tLoss: 1.37247\n",
            "Training Progress: \tEpoch 18 [640/1692 (37.74%)]\t\tLoss: 1.27733\n",
            "Training Progress: \tEpoch 18 [960/1692 (56.60%)]\t\tLoss: 1.35051\n",
            "Training Progress: \tEpoch 18 [1280/1692 (75.47%)]\t\tLoss: 1.31000\n",
            "Training Progress: \tEpoch 18 [1600/1692 (94.34%)]\t\tLoss: 1.33004\n",
            "\tTrain loss: 0.04121, Accuracy: 674/1692 (39.83%)\n",
            "\tValidation loss: 0.00336, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00322, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 19 [0/1692 (0.00%)]\t\tLoss: 1.37782\n",
            "Training Progress: \tEpoch 19 [320/1692 (18.87%)]\t\tLoss: 1.37229\n",
            "Training Progress: \tEpoch 19 [640/1692 (37.74%)]\t\tLoss: 1.26668\n",
            "Training Progress: \tEpoch 19 [960/1692 (56.60%)]\t\tLoss: 1.36620\n",
            "Training Progress: \tEpoch 19 [1280/1692 (75.47%)]\t\tLoss: 1.34376\n",
            "Training Progress: \tEpoch 19 [1600/1692 (94.34%)]\t\tLoss: 1.39949\n",
            "\tTrain loss: 0.04098, Accuracy: 663/1692 (39.18%)\n",
            "\tValidation loss: 0.00333, Accuracy: 109/423 (25.77%)\n",
            "\tTest loss: 0.00322, Accuracy: 106/443 (23.93%)\n",
            "\n",
            "Training Progress: \tEpoch 20 [0/1692 (0.00%)]\t\tLoss: 1.33131\n",
            "Training Progress: \tEpoch 20 [320/1692 (18.87%)]\t\tLoss: 1.37312\n",
            "Training Progress: \tEpoch 20 [640/1692 (37.74%)]\t\tLoss: 1.40001\n",
            "Training Progress: \tEpoch 20 [960/1692 (56.60%)]\t\tLoss: 1.38973\n",
            "Training Progress: \tEpoch 20 [1280/1692 (75.47%)]\t\tLoss: 1.38731\n",
            "Training Progress: \tEpoch 20 [1600/1692 (94.34%)]\t\tLoss: 1.35610\n",
            "\tTrain loss: 0.04056, Accuracy: 677/1692 (40.01%)\n",
            "\tValidation loss: 0.00334, Accuracy: 120/423 (28.37%)\n",
            "\tTest loss: 0.00322, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 21 [0/1692 (0.00%)]\t\tLoss: 1.34770\n",
            "Training Progress: \tEpoch 21 [320/1692 (18.87%)]\t\tLoss: 1.35236\n",
            "Training Progress: \tEpoch 21 [640/1692 (37.74%)]\t\tLoss: 1.28339\n",
            "Training Progress: \tEpoch 21 [960/1692 (56.60%)]\t\tLoss: 1.37858\n",
            "Training Progress: \tEpoch 21 [1280/1692 (75.47%)]\t\tLoss: 1.35116\n",
            "Training Progress: \tEpoch 21 [1600/1692 (94.34%)]\t\tLoss: 1.31959\n",
            "\tTrain loss: 0.04051, Accuracy: 721/1692 (42.61%)\n",
            "\tValidation loss: 0.00336, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00322, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 22 [0/1692 (0.00%)]\t\tLoss: 1.35983\n",
            "Training Progress: \tEpoch 22 [320/1692 (18.87%)]\t\tLoss: 1.30676\n",
            "Training Progress: \tEpoch 22 [640/1692 (37.74%)]\t\tLoss: 1.27650\n",
            "Training Progress: \tEpoch 22 [960/1692 (56.60%)]\t\tLoss: 1.33749\n",
            "Training Progress: \tEpoch 22 [1280/1692 (75.47%)]\t\tLoss: 1.39728\n",
            "Training Progress: \tEpoch 22 [1600/1692 (94.34%)]\t\tLoss: 1.30348\n",
            "\tTrain loss: 0.04015, Accuracy: 714/1692 (42.20%)\n",
            "\tValidation loss: 0.00337, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00324, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 23 [0/1692 (0.00%)]\t\tLoss: 1.27986\n",
            "Training Progress: \tEpoch 23 [320/1692 (18.87%)]\t\tLoss: 1.30091\n",
            "Training Progress: \tEpoch 23 [640/1692 (37.74%)]\t\tLoss: 1.26928\n",
            "Training Progress: \tEpoch 23 [960/1692 (56.60%)]\t\tLoss: 1.35549\n",
            "Training Progress: \tEpoch 23 [1280/1692 (75.47%)]\t\tLoss: 1.36708\n",
            "Training Progress: \tEpoch 23 [1600/1692 (94.34%)]\t\tLoss: 1.28789\n",
            "\tTrain loss: 0.03998, Accuracy: 722/1692 (42.67%)\n",
            "\tValidation loss: 0.00338, Accuracy: 102/423 (24.11%)\n",
            "\tTest loss: 0.00325, Accuracy: 102/443 (23.02%)\n",
            "\n",
            "Training Progress: \tEpoch 24 [0/1692 (0.00%)]\t\tLoss: 1.32450\n",
            "Training Progress: \tEpoch 24 [320/1692 (18.87%)]\t\tLoss: 1.27842\n",
            "Training Progress: \tEpoch 24 [640/1692 (37.74%)]\t\tLoss: 1.31112\n",
            "Training Progress: \tEpoch 24 [960/1692 (56.60%)]\t\tLoss: 1.37187\n",
            "Training Progress: \tEpoch 24 [1280/1692 (75.47%)]\t\tLoss: 1.33564\n",
            "Training Progress: \tEpoch 24 [1600/1692 (94.34%)]\t\tLoss: 1.29476\n",
            "\tTrain loss: 0.03964, Accuracy: 757/1692 (44.74%)\n",
            "\tValidation loss: 0.00336, Accuracy: 109/423 (25.77%)\n",
            "\tTest loss: 0.00326, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 25 [0/1692 (0.00%)]\t\tLoss: 1.26674\n",
            "Training Progress: \tEpoch 25 [320/1692 (18.87%)]\t\tLoss: 1.30103\n",
            "Training Progress: \tEpoch 25 [640/1692 (37.74%)]\t\tLoss: 1.28405\n",
            "Training Progress: \tEpoch 25 [960/1692 (56.60%)]\t\tLoss: 1.28096\n",
            "Training Progress: \tEpoch 25 [1280/1692 (75.47%)]\t\tLoss: 1.28516\n",
            "Training Progress: \tEpoch 25 [1600/1692 (94.34%)]\t\tLoss: 1.33859\n",
            "\tTrain loss: 0.03948, Accuracy: 718/1692 (42.43%)\n",
            "\tValidation loss: 0.00341, Accuracy: 106/423 (25.06%)\n",
            "\tTest loss: 0.00327, Accuracy: 107/443 (24.15%)\n",
            "\n",
            "Training Progress: \tEpoch 26 [0/1692 (0.00%)]\t\tLoss: 1.38771\n",
            "Training Progress: \tEpoch 26 [320/1692 (18.87%)]\t\tLoss: 1.34327\n",
            "Training Progress: \tEpoch 26 [640/1692 (37.74%)]\t\tLoss: 1.23283\n",
            "Training Progress: \tEpoch 26 [960/1692 (56.60%)]\t\tLoss: 1.36807\n",
            "Training Progress: \tEpoch 26 [1280/1692 (75.47%)]\t\tLoss: 1.25302\n",
            "Training Progress: \tEpoch 26 [1600/1692 (94.34%)]\t\tLoss: 1.30349\n",
            "\tTrain loss: 0.03920, Accuracy: 750/1692 (44.33%)\n",
            "\tValidation loss: 0.00336, Accuracy: 115/423 (27.19%)\n",
            "\tTest loss: 0.00327, Accuracy: 110/443 (24.83%)\n",
            "\n",
            "Training Progress: \tEpoch 27 [0/1692 (0.00%)]\t\tLoss: 1.27465\n",
            "Training Progress: \tEpoch 27 [320/1692 (18.87%)]\t\tLoss: 1.38795\n",
            "Training Progress: \tEpoch 27 [640/1692 (37.74%)]\t\tLoss: 1.30482\n",
            "Training Progress: \tEpoch 27 [960/1692 (56.60%)]\t\tLoss: 1.38343\n",
            "Training Progress: \tEpoch 27 [1280/1692 (75.47%)]\t\tLoss: 1.30177\n",
            "Training Progress: \tEpoch 27 [1600/1692 (94.34%)]\t\tLoss: 1.39894\n",
            "\tTrain loss: 0.03899, Accuracy: 746/1692 (44.09%)\n",
            "\tValidation loss: 0.00341, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00331, Accuracy: 105/443 (23.70%)\n",
            "\n",
            "Training Progress: \tEpoch 28 [0/1692 (0.00%)]\t\tLoss: 1.22357\n",
            "Training Progress: \tEpoch 28 [320/1692 (18.87%)]\t\tLoss: 1.32508\n",
            "Training Progress: \tEpoch 28 [640/1692 (37.74%)]\t\tLoss: 1.27029\n",
            "Training Progress: \tEpoch 28 [960/1692 (56.60%)]\t\tLoss: 1.40527\n",
            "Training Progress: \tEpoch 28 [1280/1692 (75.47%)]\t\tLoss: 1.28829\n",
            "Training Progress: \tEpoch 28 [1600/1692 (94.34%)]\t\tLoss: 1.37112\n",
            "\tTrain loss: 0.03887, Accuracy: 774/1692 (45.74%)\n",
            "\tValidation loss: 0.00341, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00328, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 29 [0/1692 (0.00%)]\t\tLoss: 1.20314\n",
            "Training Progress: \tEpoch 29 [320/1692 (18.87%)]\t\tLoss: 1.37679\n",
            "Training Progress: \tEpoch 29 [640/1692 (37.74%)]\t\tLoss: 1.26818\n",
            "Training Progress: \tEpoch 29 [960/1692 (56.60%)]\t\tLoss: 1.26130\n",
            "Training Progress: \tEpoch 29 [1280/1692 (75.47%)]\t\tLoss: 1.30199\n",
            "Training Progress: \tEpoch 29 [1600/1692 (94.34%)]\t\tLoss: 1.29190\n",
            "\tTrain loss: 0.03846, Accuracy: 779/1692 (46.04%)\n",
            "\tValidation loss: 0.00341, Accuracy: 106/423 (25.06%)\n",
            "\tTest loss: 0.00328, Accuracy: 118/443 (26.64%)\n",
            "\n",
            "Training Progress: \tEpoch 30 [0/1692 (0.00%)]\t\tLoss: 1.25240\n",
            "Training Progress: \tEpoch 30 [320/1692 (18.87%)]\t\tLoss: 1.38815\n",
            "Training Progress: \tEpoch 30 [640/1692 (37.74%)]\t\tLoss: 1.19575\n",
            "Training Progress: \tEpoch 30 [960/1692 (56.60%)]\t\tLoss: 1.36798\n",
            "Training Progress: \tEpoch 30 [1280/1692 (75.47%)]\t\tLoss: 1.27894\n",
            "Training Progress: \tEpoch 30 [1600/1692 (94.34%)]\t\tLoss: 1.25901\n",
            "\tTrain loss: 0.03797, Accuracy: 797/1692 (47.10%)\n",
            "\tValidation loss: 0.00342, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00329, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 31 [0/1692 (0.00%)]\t\tLoss: 1.31142\n",
            "Training Progress: \tEpoch 31 [320/1692 (18.87%)]\t\tLoss: 1.27720\n",
            "Training Progress: \tEpoch 31 [640/1692 (37.74%)]\t\tLoss: 1.23265\n",
            "Training Progress: \tEpoch 31 [960/1692 (56.60%)]\t\tLoss: 1.27265\n",
            "Training Progress: \tEpoch 31 [1280/1692 (75.47%)]\t\tLoss: 1.21778\n",
            "Training Progress: \tEpoch 31 [1600/1692 (94.34%)]\t\tLoss: 1.34884\n",
            "\tTrain loss: 0.03788, Accuracy: 784/1692 (46.34%)\n",
            "\tValidation loss: 0.00344, Accuracy: 116/423 (27.42%)\n",
            "\tTest loss: 0.00332, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 32 [0/1692 (0.00%)]\t\tLoss: 1.19234\n",
            "Training Progress: \tEpoch 32 [320/1692 (18.87%)]\t\tLoss: 1.25790\n",
            "Training Progress: \tEpoch 32 [640/1692 (37.74%)]\t\tLoss: 1.19757\n",
            "Training Progress: \tEpoch 32 [960/1692 (56.60%)]\t\tLoss: 1.25186\n",
            "Training Progress: \tEpoch 32 [1280/1692 (75.47%)]\t\tLoss: 1.41506\n",
            "Training Progress: \tEpoch 32 [1600/1692 (94.34%)]\t\tLoss: 1.17247\n",
            "\tTrain loss: 0.03730, Accuracy: 828/1692 (48.94%)\n",
            "\tValidation loss: 0.00342, Accuracy: 109/423 (25.77%)\n",
            "\tTest loss: 0.00331, Accuracy: 110/443 (24.83%)\n",
            "\n",
            "Training Progress: \tEpoch 33 [0/1692 (0.00%)]\t\tLoss: 1.26684\n",
            "Training Progress: \tEpoch 33 [320/1692 (18.87%)]\t\tLoss: 1.32961\n",
            "Training Progress: \tEpoch 33 [640/1692 (37.74%)]\t\tLoss: 1.24882\n",
            "Training Progress: \tEpoch 33 [960/1692 (56.60%)]\t\tLoss: 1.23455\n",
            "Training Progress: \tEpoch 33 [1280/1692 (75.47%)]\t\tLoss: 1.22362\n",
            "Training Progress: \tEpoch 33 [1600/1692 (94.34%)]\t\tLoss: 1.25107\n",
            "\tTrain loss: 0.03693, Accuracy: 837/1692 (49.47%)\n",
            "\tValidation loss: 0.00348, Accuracy: 112/423 (26.48%)\n",
            "\tTest loss: 0.00336, Accuracy: 107/443 (24.15%)\n",
            "\n",
            "Training Progress: \tEpoch 34 [0/1692 (0.00%)]\t\tLoss: 1.14069\n",
            "Training Progress: \tEpoch 34 [320/1692 (18.87%)]\t\tLoss: 1.36494\n",
            "Training Progress: \tEpoch 34 [640/1692 (37.74%)]\t\tLoss: 1.24846\n",
            "Training Progress: \tEpoch 34 [960/1692 (56.60%)]\t\tLoss: 1.23999\n",
            "Training Progress: \tEpoch 34 [1280/1692 (75.47%)]\t\tLoss: 1.37475\n",
            "Training Progress: \tEpoch 34 [1600/1692 (94.34%)]\t\tLoss: 1.36287\n",
            "\tTrain loss: 0.03707, Accuracy: 833/1692 (49.23%)\n",
            "\tValidation loss: 0.00344, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00335, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 35 [0/1692 (0.00%)]\t\tLoss: 1.26495\n",
            "Training Progress: \tEpoch 35 [320/1692 (18.87%)]\t\tLoss: 1.30993\n",
            "Training Progress: \tEpoch 35 [640/1692 (37.74%)]\t\tLoss: 1.14073\n",
            "Training Progress: \tEpoch 35 [960/1692 (56.60%)]\t\tLoss: 1.25700\n",
            "Training Progress: \tEpoch 35 [1280/1692 (75.47%)]\t\tLoss: 1.17894\n",
            "Training Progress: \tEpoch 35 [1600/1692 (94.34%)]\t\tLoss: 1.24152\n",
            "\tTrain loss: 0.03665, Accuracy: 842/1692 (49.76%)\n",
            "\tValidation loss: 0.00343, Accuracy: 118/423 (27.90%)\n",
            "\tTest loss: 0.00335, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 36 [0/1692 (0.00%)]\t\tLoss: 1.20120\n",
            "Training Progress: \tEpoch 36 [320/1692 (18.87%)]\t\tLoss: 1.17612\n",
            "Training Progress: \tEpoch 36 [640/1692 (37.74%)]\t\tLoss: 1.16821\n",
            "Training Progress: \tEpoch 36 [960/1692 (56.60%)]\t\tLoss: 1.15257\n",
            "Training Progress: \tEpoch 36 [1280/1692 (75.47%)]\t\tLoss: 1.24161\n",
            "Training Progress: \tEpoch 36 [1600/1692 (94.34%)]\t\tLoss: 1.26821\n",
            "\tTrain loss: 0.03623, Accuracy: 858/1692 (50.71%)\n",
            "\tValidation loss: 0.00351, Accuracy: 102/423 (24.11%)\n",
            "\tTest loss: 0.00340, Accuracy: 101/443 (22.80%)\n",
            "\n",
            "Training Progress: \tEpoch 37 [0/1692 (0.00%)]\t\tLoss: 1.21355\n",
            "Training Progress: \tEpoch 37 [320/1692 (18.87%)]\t\tLoss: 1.27297\n",
            "Training Progress: \tEpoch 37 [640/1692 (37.74%)]\t\tLoss: 1.20575\n",
            "Training Progress: \tEpoch 37 [960/1692 (56.60%)]\t\tLoss: 1.21773\n",
            "Training Progress: \tEpoch 37 [1280/1692 (75.47%)]\t\tLoss: 1.17026\n",
            "Training Progress: \tEpoch 37 [1600/1692 (94.34%)]\t\tLoss: 1.22323\n",
            "\tTrain loss: 0.03586, Accuracy: 859/1692 (50.77%)\n",
            "\tValidation loss: 0.00350, Accuracy: 100/423 (23.64%)\n",
            "\tTest loss: 0.00345, Accuracy: 107/443 (24.15%)\n",
            "\n",
            "Training Progress: \tEpoch 38 [0/1692 (0.00%)]\t\tLoss: 1.26391\n",
            "Training Progress: \tEpoch 38 [320/1692 (18.87%)]\t\tLoss: 1.30077\n",
            "Training Progress: \tEpoch 38 [640/1692 (37.74%)]\t\tLoss: 1.26042\n",
            "Training Progress: \tEpoch 38 [960/1692 (56.60%)]\t\tLoss: 1.21317\n",
            "Training Progress: \tEpoch 38 [1280/1692 (75.47%)]\t\tLoss: 1.16879\n",
            "Training Progress: \tEpoch 38 [1600/1692 (94.34%)]\t\tLoss: 1.22418\n",
            "\tTrain loss: 0.03553, Accuracy: 906/1692 (53.55%)\n",
            "\tValidation loss: 0.00356, Accuracy: 100/423 (23.64%)\n",
            "\tTest loss: 0.00346, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 39 [0/1692 (0.00%)]\t\tLoss: 1.28131\n",
            "Training Progress: \tEpoch 39 [320/1692 (18.87%)]\t\tLoss: 1.30060\n",
            "Training Progress: \tEpoch 39 [640/1692 (37.74%)]\t\tLoss: 1.24884\n",
            "Training Progress: \tEpoch 39 [960/1692 (56.60%)]\t\tLoss: 1.27917\n",
            "Training Progress: \tEpoch 39 [1280/1692 (75.47%)]\t\tLoss: 1.30601\n",
            "Training Progress: \tEpoch 39 [1600/1692 (94.34%)]\t\tLoss: 1.21033\n",
            "\tTrain loss: 0.03547, Accuracy: 847/1692 (50.06%)\n",
            "\tValidation loss: 0.00353, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00347, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 40 [0/1692 (0.00%)]\t\tLoss: 1.18288\n",
            "Training Progress: \tEpoch 40 [320/1692 (18.87%)]\t\tLoss: 1.37910\n",
            "Training Progress: \tEpoch 40 [640/1692 (37.74%)]\t\tLoss: 1.14179\n",
            "Training Progress: \tEpoch 40 [960/1692 (56.60%)]\t\tLoss: 1.17017\n",
            "Training Progress: \tEpoch 40 [1280/1692 (75.47%)]\t\tLoss: 1.25196\n",
            "Training Progress: \tEpoch 40 [1600/1692 (94.34%)]\t\tLoss: 1.39929\n",
            "\tTrain loss: 0.03519, Accuracy: 875/1692 (51.71%)\n",
            "\tValidation loss: 0.00355, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00348, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 41 [0/1692 (0.00%)]\t\tLoss: 1.12589\n",
            "Training Progress: \tEpoch 41 [320/1692 (18.87%)]\t\tLoss: 1.17706\n",
            "Training Progress: \tEpoch 41 [640/1692 (37.74%)]\t\tLoss: 1.18489\n",
            "Training Progress: \tEpoch 41 [960/1692 (56.60%)]\t\tLoss: 1.20607\n",
            "Training Progress: \tEpoch 41 [1280/1692 (75.47%)]\t\tLoss: 1.32889\n",
            "Training Progress: \tEpoch 41 [1600/1692 (94.34%)]\t\tLoss: 1.21658\n",
            "\tTrain loss: 0.03460, Accuracy: 907/1692 (53.61%)\n",
            "\tValidation loss: 0.00351, Accuracy: 111/423 (26.24%)\n",
            "\tTest loss: 0.00349, Accuracy: 100/443 (22.57%)\n",
            "\n",
            "Training Progress: \tEpoch 42 [0/1692 (0.00%)]\t\tLoss: 1.09168\n",
            "Training Progress: \tEpoch 42 [320/1692 (18.87%)]\t\tLoss: 1.21642\n",
            "Training Progress: \tEpoch 42 [640/1692 (37.74%)]\t\tLoss: 1.12523\n",
            "Training Progress: \tEpoch 42 [960/1692 (56.60%)]\t\tLoss: 1.26082\n",
            "Training Progress: \tEpoch 42 [1280/1692 (75.47%)]\t\tLoss: 1.08730\n",
            "Training Progress: \tEpoch 42 [1600/1692 (94.34%)]\t\tLoss: 1.20507\n",
            "\tTrain loss: 0.03452, Accuracy: 901/1692 (53.25%)\n",
            "\tValidation loss: 0.00361, Accuracy: 112/423 (26.48%)\n",
            "\tTest loss: 0.00350, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 43 [0/1692 (0.00%)]\t\tLoss: 1.13617\n",
            "Training Progress: \tEpoch 43 [320/1692 (18.87%)]\t\tLoss: 1.21025\n",
            "Training Progress: \tEpoch 43 [640/1692 (37.74%)]\t\tLoss: 1.15738\n",
            "Training Progress: \tEpoch 43 [960/1692 (56.60%)]\t\tLoss: 1.11232\n",
            "Training Progress: \tEpoch 43 [1280/1692 (75.47%)]\t\tLoss: 1.13601\n",
            "Training Progress: \tEpoch 43 [1600/1692 (94.34%)]\t\tLoss: 1.27184\n",
            "\tTrain loss: 0.03391, Accuracy: 924/1692 (54.61%)\n",
            "\tValidation loss: 0.00360, Accuracy: 110/423 (26.00%)\n",
            "\tTest loss: 0.00349, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 44 [0/1692 (0.00%)]\t\tLoss: 1.16271\n",
            "Training Progress: \tEpoch 44 [320/1692 (18.87%)]\t\tLoss: 1.18488\n",
            "Training Progress: \tEpoch 44 [640/1692 (37.74%)]\t\tLoss: 1.02391\n",
            "Training Progress: \tEpoch 44 [960/1692 (56.60%)]\t\tLoss: 1.12094\n",
            "Training Progress: \tEpoch 44 [1280/1692 (75.47%)]\t\tLoss: 1.09815\n",
            "Training Progress: \tEpoch 44 [1600/1692 (94.34%)]\t\tLoss: 1.18896\n",
            "\tTrain loss: 0.03342, Accuracy: 940/1692 (55.56%)\n",
            "\tValidation loss: 0.00362, Accuracy: 113/423 (26.71%)\n",
            "\tTest loss: 0.00357, Accuracy: 107/443 (24.15%)\n",
            "\n",
            "Training Progress: \tEpoch 45 [0/1692 (0.00%)]\t\tLoss: 1.18269\n",
            "Training Progress: \tEpoch 45 [320/1692 (18.87%)]\t\tLoss: 1.23230\n",
            "Training Progress: \tEpoch 45 [640/1692 (37.74%)]\t\tLoss: 1.05909\n",
            "Training Progress: \tEpoch 45 [960/1692 (56.60%)]\t\tLoss: 1.24227\n",
            "Training Progress: \tEpoch 45 [1280/1692 (75.47%)]\t\tLoss: 1.14508\n",
            "Training Progress: \tEpoch 45 [1600/1692 (94.34%)]\t\tLoss: 1.23082\n",
            "\tTrain loss: 0.03312, Accuracy: 941/1692 (55.61%)\n",
            "\tValidation loss: 0.00373, Accuracy: 99/423 (23.40%)\n",
            "\tTest loss: 0.00356, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 46 [0/1692 (0.00%)]\t\tLoss: 1.05173\n",
            "Training Progress: \tEpoch 46 [320/1692 (18.87%)]\t\tLoss: 1.24771\n",
            "Training Progress: \tEpoch 46 [640/1692 (37.74%)]\t\tLoss: 1.01388\n",
            "Training Progress: \tEpoch 46 [960/1692 (56.60%)]\t\tLoss: 1.09257\n",
            "Training Progress: \tEpoch 46 [1280/1692 (75.47%)]\t\tLoss: 1.10641\n",
            "Training Progress: \tEpoch 46 [1600/1692 (94.34%)]\t\tLoss: 1.19890\n",
            "\tTrain loss: 0.03279, Accuracy: 961/1692 (56.80%)\n",
            "\tValidation loss: 0.00364, Accuracy: 107/423 (25.30%)\n",
            "\tTest loss: 0.00352, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 47 [0/1692 (0.00%)]\t\tLoss: 1.10852\n",
            "Training Progress: \tEpoch 47 [320/1692 (18.87%)]\t\tLoss: 1.29392\n",
            "Training Progress: \tEpoch 47 [640/1692 (37.74%)]\t\tLoss: 1.00398\n",
            "Training Progress: \tEpoch 47 [960/1692 (56.60%)]\t\tLoss: 1.07130\n",
            "Training Progress: \tEpoch 47 [1280/1692 (75.47%)]\t\tLoss: 1.12868\n",
            "Training Progress: \tEpoch 47 [1600/1692 (94.34%)]\t\tLoss: 1.18622\n",
            "\tTrain loss: 0.03258, Accuracy: 980/1692 (57.92%)\n",
            "\tValidation loss: 0.00371, Accuracy: 98/423 (23.17%)\n",
            "\tTest loss: 0.00356, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 48 [0/1692 (0.00%)]\t\tLoss: 1.10543\n",
            "Training Progress: \tEpoch 48 [320/1692 (18.87%)]\t\tLoss: 1.28707\n",
            "Training Progress: \tEpoch 48 [640/1692 (37.74%)]\t\tLoss: 0.93974\n",
            "Training Progress: \tEpoch 48 [960/1692 (56.60%)]\t\tLoss: 1.11262\n",
            "Training Progress: \tEpoch 48 [1280/1692 (75.47%)]\t\tLoss: 1.06011\n",
            "Training Progress: \tEpoch 48 [1600/1692 (94.34%)]\t\tLoss: 1.13717\n",
            "\tTrain loss: 0.03217, Accuracy: 991/1692 (58.57%)\n",
            "\tValidation loss: 0.00371, Accuracy: 100/423 (23.64%)\n",
            "\tTest loss: 0.00366, Accuracy: 106/443 (23.93%)\n",
            "\n",
            "Training Progress: \tEpoch 49 [0/1692 (0.00%)]\t\tLoss: 1.08385\n",
            "Training Progress: \tEpoch 49 [320/1692 (18.87%)]\t\tLoss: 1.16530\n",
            "Training Progress: \tEpoch 49 [640/1692 (37.74%)]\t\tLoss: 0.96832\n",
            "Training Progress: \tEpoch 49 [960/1692 (56.60%)]\t\tLoss: 1.03157\n",
            "Training Progress: \tEpoch 49 [1280/1692 (75.47%)]\t\tLoss: 1.13339\n",
            "Training Progress: \tEpoch 49 [1600/1692 (94.34%)]\t\tLoss: 1.20500\n",
            "\tTrain loss: 0.03150, Accuracy: 993/1692 (58.69%)\n",
            "\tValidation loss: 0.00377, Accuracy: 98/423 (23.17%)\n",
            "\tTest loss: 0.00367, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 50 [0/1692 (0.00%)]\t\tLoss: 1.03664\n",
            "Training Progress: \tEpoch 50 [320/1692 (18.87%)]\t\tLoss: 1.19078\n",
            "Training Progress: \tEpoch 50 [640/1692 (37.74%)]\t\tLoss: 1.09130\n",
            "Training Progress: \tEpoch 50 [960/1692 (56.60%)]\t\tLoss: 1.13801\n",
            "Training Progress: \tEpoch 50 [1280/1692 (75.47%)]\t\tLoss: 1.00076\n",
            "Training Progress: \tEpoch 50 [1600/1692 (94.34%)]\t\tLoss: 1.10628\n",
            "\tTrain loss: 0.03104, Accuracy: 1020/1692 (60.28%)\n",
            "\tValidation loss: 0.00376, Accuracy: 109/423 (25.77%)\n",
            "\tTest loss: 0.00364, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 51 [0/1692 (0.00%)]\t\tLoss: 0.96928\n",
            "Training Progress: \tEpoch 51 [320/1692 (18.87%)]\t\tLoss: 1.26297\n",
            "Training Progress: \tEpoch 51 [640/1692 (37.74%)]\t\tLoss: 0.94939\n",
            "Training Progress: \tEpoch 51 [960/1692 (56.60%)]\t\tLoss: 1.08846\n",
            "Training Progress: \tEpoch 51 [1280/1692 (75.47%)]\t\tLoss: 1.02314\n",
            "Training Progress: \tEpoch 51 [1600/1692 (94.34%)]\t\tLoss: 1.11385\n",
            "\tTrain loss: 0.03092, Accuracy: 989/1692 (58.45%)\n",
            "\tValidation loss: 0.00379, Accuracy: 95/423 (22.46%)\n",
            "\tTest loss: 0.00368, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 52 [0/1692 (0.00%)]\t\tLoss: 1.06363\n",
            "Training Progress: \tEpoch 52 [320/1692 (18.87%)]\t\tLoss: 1.20061\n",
            "Training Progress: \tEpoch 52 [640/1692 (37.74%)]\t\tLoss: 1.01294\n",
            "Training Progress: \tEpoch 52 [960/1692 (56.60%)]\t\tLoss: 1.06774\n",
            "Training Progress: \tEpoch 52 [1280/1692 (75.47%)]\t\tLoss: 1.08964\n",
            "Training Progress: \tEpoch 52 [1600/1692 (94.34%)]\t\tLoss: 1.18898\n",
            "\tTrain loss: 0.03077, Accuracy: 1009/1692 (59.63%)\n",
            "\tValidation loss: 0.00382, Accuracy: 106/423 (25.06%)\n",
            "\tTest loss: 0.00374, Accuracy: 110/443 (24.83%)\n",
            "\n",
            "Training Progress: \tEpoch 53 [0/1692 (0.00%)]\t\tLoss: 0.94474\n",
            "Training Progress: \tEpoch 53 [320/1692 (18.87%)]\t\tLoss: 1.26684\n",
            "Training Progress: \tEpoch 53 [640/1692 (37.74%)]\t\tLoss: 0.95065\n",
            "Training Progress: \tEpoch 53 [960/1692 (56.60%)]\t\tLoss: 1.12023\n",
            "Training Progress: \tEpoch 53 [1280/1692 (75.47%)]\t\tLoss: 1.06625\n",
            "Training Progress: \tEpoch 53 [1600/1692 (94.34%)]\t\tLoss: 1.18807\n",
            "\tTrain loss: 0.03002, Accuracy: 1046/1692 (61.82%)\n",
            "\tValidation loss: 0.00384, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00378, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 54 [0/1692 (0.00%)]\t\tLoss: 1.06739\n",
            "Training Progress: \tEpoch 54 [320/1692 (18.87%)]\t\tLoss: 1.14010\n",
            "Training Progress: \tEpoch 54 [640/1692 (37.74%)]\t\tLoss: 1.13304\n",
            "Training Progress: \tEpoch 54 [960/1692 (56.60%)]\t\tLoss: 1.09464\n",
            "Training Progress: \tEpoch 54 [1280/1692 (75.47%)]\t\tLoss: 0.99021\n",
            "Training Progress: \tEpoch 54 [1600/1692 (94.34%)]\t\tLoss: 1.07281\n",
            "\tTrain loss: 0.02958, Accuracy: 1060/1692 (62.65%)\n",
            "\tValidation loss: 0.00392, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00379, Accuracy: 115/443 (25.96%)\n",
            "\n",
            "Training Progress: \tEpoch 55 [0/1692 (0.00%)]\t\tLoss: 0.92434\n",
            "Training Progress: \tEpoch 55 [320/1692 (18.87%)]\t\tLoss: 1.09395\n",
            "Training Progress: \tEpoch 55 [640/1692 (37.74%)]\t\tLoss: 0.94407\n",
            "Training Progress: \tEpoch 55 [960/1692 (56.60%)]\t\tLoss: 1.03269\n",
            "Training Progress: \tEpoch 55 [1280/1692 (75.47%)]\t\tLoss: 1.02589\n",
            "Training Progress: \tEpoch 55 [1600/1692 (94.34%)]\t\tLoss: 1.31887\n",
            "\tTrain loss: 0.02968, Accuracy: 1062/1692 (62.77%)\n",
            "\tValidation loss: 0.00389, Accuracy: 91/423 (21.51%)\n",
            "\tTest loss: 0.00374, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 56 [0/1692 (0.00%)]\t\tLoss: 0.95575\n",
            "Training Progress: \tEpoch 56 [320/1692 (18.87%)]\t\tLoss: 1.08424\n",
            "Training Progress: \tEpoch 56 [640/1692 (37.74%)]\t\tLoss: 1.04839\n",
            "Training Progress: \tEpoch 56 [960/1692 (56.60%)]\t\tLoss: 1.00027\n",
            "Training Progress: \tEpoch 56 [1280/1692 (75.47%)]\t\tLoss: 1.04301\n",
            "Training Progress: \tEpoch 56 [1600/1692 (94.34%)]\t\tLoss: 1.25721\n",
            "\tTrain loss: 0.02901, Accuracy: 1059/1692 (62.59%)\n",
            "\tValidation loss: 0.00406, Accuracy: 102/423 (24.11%)\n",
            "\tTest loss: 0.00398, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 57 [0/1692 (0.00%)]\t\tLoss: 0.98999\n",
            "Training Progress: \tEpoch 57 [320/1692 (18.87%)]\t\tLoss: 1.08387\n",
            "Training Progress: \tEpoch 57 [640/1692 (37.74%)]\t\tLoss: 1.00749\n",
            "Training Progress: \tEpoch 57 [960/1692 (56.60%)]\t\tLoss: 1.08236\n",
            "Training Progress: \tEpoch 57 [1280/1692 (75.47%)]\t\tLoss: 0.86305\n",
            "Training Progress: \tEpoch 57 [1600/1692 (94.34%)]\t\tLoss: 1.10844\n",
            "\tTrain loss: 0.02826, Accuracy: 1077/1692 (63.65%)\n",
            "\tValidation loss: 0.00401, Accuracy: 98/423 (23.17%)\n",
            "\tTest loss: 0.00389, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 58 [0/1692 (0.00%)]\t\tLoss: 0.84706\n",
            "Training Progress: \tEpoch 58 [320/1692 (18.87%)]\t\tLoss: 1.20437\n",
            "Training Progress: \tEpoch 58 [640/1692 (37.74%)]\t\tLoss: 0.94387\n",
            "Training Progress: \tEpoch 58 [960/1692 (56.60%)]\t\tLoss: 0.96881\n",
            "Training Progress: \tEpoch 58 [1280/1692 (75.47%)]\t\tLoss: 1.06162\n",
            "Training Progress: \tEpoch 58 [1600/1692 (94.34%)]\t\tLoss: 1.02403\n",
            "\tTrain loss: 0.02809, Accuracy: 1074/1692 (63.48%)\n",
            "\tValidation loss: 0.00411, Accuracy: 105/423 (24.82%)\n",
            "\tTest loss: 0.00403, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 59 [0/1692 (0.00%)]\t\tLoss: 0.95890\n",
            "Training Progress: \tEpoch 59 [320/1692 (18.87%)]\t\tLoss: 0.93400\n",
            "Training Progress: \tEpoch 59 [640/1692 (37.74%)]\t\tLoss: 0.98315\n",
            "Training Progress: \tEpoch 59 [960/1692 (56.60%)]\t\tLoss: 1.04913\n",
            "Training Progress: \tEpoch 59 [1280/1692 (75.47%)]\t\tLoss: 1.05188\n",
            "Training Progress: \tEpoch 59 [1600/1692 (94.34%)]\t\tLoss: 1.09428\n",
            "\tTrain loss: 0.02850, Accuracy: 1083/1692 (64.01%)\n",
            "\tValidation loss: 0.00396, Accuracy: 106/423 (25.06%)\n",
            "\tTest loss: 0.00392, Accuracy: 104/443 (23.48%)\n",
            "\n",
            "Training Progress: \tEpoch 60 [0/1692 (0.00%)]\t\tLoss: 0.95597\n",
            "Training Progress: \tEpoch 60 [320/1692 (18.87%)]\t\tLoss: 1.22928\n",
            "Training Progress: \tEpoch 60 [640/1692 (37.74%)]\t\tLoss: 1.01901\n",
            "Training Progress: \tEpoch 60 [960/1692 (56.60%)]\t\tLoss: 0.93988\n",
            "Training Progress: \tEpoch 60 [1280/1692 (75.47%)]\t\tLoss: 0.92408\n",
            "Training Progress: \tEpoch 60 [1600/1692 (94.34%)]\t\tLoss: 1.06617\n",
            "\tTrain loss: 0.02742, Accuracy: 1117/1692 (66.02%)\n",
            "\tValidation loss: 0.00407, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00401, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 61 [0/1692 (0.00%)]\t\tLoss: 0.82127\n",
            "Training Progress: \tEpoch 61 [320/1692 (18.87%)]\t\tLoss: 1.01537\n",
            "Training Progress: \tEpoch 61 [640/1692 (37.74%)]\t\tLoss: 0.92536\n",
            "Training Progress: \tEpoch 61 [960/1692 (56.60%)]\t\tLoss: 0.97049\n",
            "Training Progress: \tEpoch 61 [1280/1692 (75.47%)]\t\tLoss: 0.89610\n",
            "Training Progress: \tEpoch 61 [1600/1692 (94.34%)]\t\tLoss: 1.04663\n",
            "\tTrain loss: 0.02719, Accuracy: 1111/1692 (65.66%)\n",
            "\tValidation loss: 0.00411, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00404, Accuracy: 107/443 (24.15%)\n",
            "\n",
            "Training Progress: \tEpoch 62 [0/1692 (0.00%)]\t\tLoss: 0.78945\n",
            "Training Progress: \tEpoch 62 [320/1692 (18.87%)]\t\tLoss: 1.20198\n",
            "Training Progress: \tEpoch 62 [640/1692 (37.74%)]\t\tLoss: 0.95165\n",
            "Training Progress: \tEpoch 62 [960/1692 (56.60%)]\t\tLoss: 0.88564\n",
            "Training Progress: \tEpoch 62 [1280/1692 (75.47%)]\t\tLoss: 0.87177\n",
            "Training Progress: \tEpoch 62 [1600/1692 (94.34%)]\t\tLoss: 0.93456\n",
            "\tTrain loss: 0.02650, Accuracy: 1116/1692 (65.96%)\n",
            "\tValidation loss: 0.00410, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00401, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 63 [0/1692 (0.00%)]\t\tLoss: 0.96871\n",
            "Training Progress: \tEpoch 63 [320/1692 (18.87%)]\t\tLoss: 0.85691\n",
            "Training Progress: \tEpoch 63 [640/1692 (37.74%)]\t\tLoss: 0.88178\n",
            "Training Progress: \tEpoch 63 [960/1692 (56.60%)]\t\tLoss: 0.92304\n",
            "Training Progress: \tEpoch 63 [1280/1692 (75.47%)]\t\tLoss: 0.94267\n",
            "Training Progress: \tEpoch 63 [1600/1692 (94.34%)]\t\tLoss: 1.19254\n",
            "\tTrain loss: 0.02634, Accuracy: 1129/1692 (66.73%)\n",
            "\tValidation loss: 0.00418, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00404, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 64 [0/1692 (0.00%)]\t\tLoss: 0.80102\n",
            "Training Progress: \tEpoch 64 [320/1692 (18.87%)]\t\tLoss: 1.05048\n",
            "Training Progress: \tEpoch 64 [640/1692 (37.74%)]\t\tLoss: 0.90517\n",
            "Training Progress: \tEpoch 64 [960/1692 (56.60%)]\t\tLoss: 0.87663\n",
            "Training Progress: \tEpoch 64 [1280/1692 (75.47%)]\t\tLoss: 1.05136\n",
            "Training Progress: \tEpoch 64 [1600/1692 (94.34%)]\t\tLoss: 1.05563\n",
            "\tTrain loss: 0.02577, Accuracy: 1158/1692 (68.44%)\n",
            "\tValidation loss: 0.00419, Accuracy: 102/423 (24.11%)\n",
            "\tTest loss: 0.00415, Accuracy: 106/443 (23.93%)\n",
            "\n",
            "Training Progress: \tEpoch 65 [0/1692 (0.00%)]\t\tLoss: 0.86239\n",
            "Training Progress: \tEpoch 65 [320/1692 (18.87%)]\t\tLoss: 1.11603\n",
            "Training Progress: \tEpoch 65 [640/1692 (37.74%)]\t\tLoss: 0.98182\n",
            "Training Progress: \tEpoch 65 [960/1692 (56.60%)]\t\tLoss: 0.79623\n",
            "Training Progress: \tEpoch 65 [1280/1692 (75.47%)]\t\tLoss: 0.98948\n",
            "Training Progress: \tEpoch 65 [1600/1692 (94.34%)]\t\tLoss: 1.08819\n",
            "\tTrain loss: 0.02552, Accuracy: 1171/1692 (69.21%)\n",
            "\tValidation loss: 0.00415, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00410, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 66 [0/1692 (0.00%)]\t\tLoss: 0.83431\n",
            "Training Progress: \tEpoch 66 [320/1692 (18.87%)]\t\tLoss: 1.10522\n",
            "Training Progress: \tEpoch 66 [640/1692 (37.74%)]\t\tLoss: 0.98003\n",
            "Training Progress: \tEpoch 66 [960/1692 (56.60%)]\t\tLoss: 0.82584\n",
            "Training Progress: \tEpoch 66 [1280/1692 (75.47%)]\t\tLoss: 0.84831\n",
            "Training Progress: \tEpoch 66 [1600/1692 (94.34%)]\t\tLoss: 0.93496\n",
            "\tTrain loss: 0.02552, Accuracy: 1137/1692 (67.20%)\n",
            "\tValidation loss: 0.00429, Accuracy: 103/423 (24.35%)\n",
            "\tTest loss: 0.00414, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 67 [0/1692 (0.00%)]\t\tLoss: 1.03308\n",
            "Training Progress: \tEpoch 67 [320/1692 (18.87%)]\t\tLoss: 1.03142\n",
            "Training Progress: \tEpoch 67 [640/1692 (37.74%)]\t\tLoss: 0.92534\n",
            "Training Progress: \tEpoch 67 [960/1692 (56.60%)]\t\tLoss: 0.93230\n",
            "Training Progress: \tEpoch 67 [1280/1692 (75.47%)]\t\tLoss: 0.93253\n",
            "Training Progress: \tEpoch 67 [1600/1692 (94.34%)]\t\tLoss: 0.96424\n",
            "\tTrain loss: 0.02483, Accuracy: 1190/1692 (70.33%)\n",
            "\tValidation loss: 0.00430, Accuracy: 100/423 (23.64%)\n",
            "\tTest loss: 0.00417, Accuracy: 106/443 (23.93%)\n",
            "\n",
            "Training Progress: \tEpoch 68 [0/1692 (0.00%)]\t\tLoss: 0.98136\n",
            "Training Progress: \tEpoch 68 [320/1692 (18.87%)]\t\tLoss: 1.01156\n",
            "Training Progress: \tEpoch 68 [640/1692 (37.74%)]\t\tLoss: 0.80278\n",
            "Training Progress: \tEpoch 68 [960/1692 (56.60%)]\t\tLoss: 0.85062\n",
            "Training Progress: \tEpoch 68 [1280/1692 (75.47%)]\t\tLoss: 1.06253\n",
            "Training Progress: \tEpoch 68 [1600/1692 (94.34%)]\t\tLoss: 0.96928\n",
            "\tTrain loss: 0.02464, Accuracy: 1182/1692 (69.86%)\n",
            "\tValidation loss: 0.00432, Accuracy: 102/423 (24.11%)\n",
            "\tTest loss: 0.00418, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 69 [0/1692 (0.00%)]\t\tLoss: 0.99325\n",
            "Training Progress: \tEpoch 69 [320/1692 (18.87%)]\t\tLoss: 0.96046\n",
            "Training Progress: \tEpoch 69 [640/1692 (37.74%)]\t\tLoss: 0.84667\n",
            "Training Progress: \tEpoch 69 [960/1692 (56.60%)]\t\tLoss: 0.99035\n",
            "Training Progress: \tEpoch 69 [1280/1692 (75.47%)]\t\tLoss: 0.87785\n",
            "Training Progress: \tEpoch 69 [1600/1692 (94.34%)]\t\tLoss: 0.95373\n",
            "\tTrain loss: 0.02475, Accuracy: 1160/1692 (68.56%)\n",
            "\tValidation loss: 0.00435, Accuracy: 88/423 (20.80%)\n",
            "\tTest loss: 0.00418, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 70 [0/1692 (0.00%)]\t\tLoss: 0.87439\n",
            "Training Progress: \tEpoch 70 [320/1692 (18.87%)]\t\tLoss: 0.86654\n",
            "Training Progress: \tEpoch 70 [640/1692 (37.74%)]\t\tLoss: 0.95627\n",
            "Training Progress: \tEpoch 70 [960/1692 (56.60%)]\t\tLoss: 0.90199\n",
            "Training Progress: \tEpoch 70 [1280/1692 (75.47%)]\t\tLoss: 0.90265\n",
            "Training Progress: \tEpoch 70 [1600/1692 (94.34%)]\t\tLoss: 1.00257\n",
            "\tTrain loss: 0.02405, Accuracy: 1196/1692 (70.69%)\n",
            "\tValidation loss: 0.00444, Accuracy: 102/423 (24.11%)\n",
            "\tTest loss: 0.00433, Accuracy: 107/443 (24.15%)\n",
            "\n",
            "Training Progress: \tEpoch 71 [0/1692 (0.00%)]\t\tLoss: 0.87736\n",
            "Training Progress: \tEpoch 71 [320/1692 (18.87%)]\t\tLoss: 0.95067\n",
            "Training Progress: \tEpoch 71 [640/1692 (37.74%)]\t\tLoss: 0.82535\n",
            "Training Progress: \tEpoch 71 [960/1692 (56.60%)]\t\tLoss: 0.91427\n",
            "Training Progress: \tEpoch 71 [1280/1692 (75.47%)]\t\tLoss: 1.02173\n",
            "Training Progress: \tEpoch 71 [1600/1692 (94.34%)]\t\tLoss: 0.94812\n",
            "\tTrain loss: 0.02388, Accuracy: 1191/1692 (70.39%)\n",
            "\tValidation loss: 0.00442, Accuracy: 101/423 (23.88%)\n",
            "\tTest loss: 0.00427, Accuracy: 105/443 (23.70%)\n",
            "\n",
            "Training Progress: \tEpoch 72 [0/1692 (0.00%)]\t\tLoss: 0.84976\n",
            "Training Progress: \tEpoch 72 [320/1692 (18.87%)]\t\tLoss: 0.77573\n",
            "Training Progress: \tEpoch 72 [640/1692 (37.74%)]\t\tLoss: 0.79049\n",
            "Training Progress: \tEpoch 72 [960/1692 (56.60%)]\t\tLoss: 0.76926\n",
            "Training Progress: \tEpoch 72 [1280/1692 (75.47%)]\t\tLoss: 0.92281\n",
            "Training Progress: \tEpoch 72 [1600/1692 (94.34%)]\t\tLoss: 0.94324\n",
            "\tTrain loss: 0.02401, Accuracy: 1185/1692 (70.04%)\n",
            "\tValidation loss: 0.00433, Accuracy: 105/423 (24.82%)\n",
            "\tTest loss: 0.00418, Accuracy: 115/443 (25.96%)\n",
            "\n",
            "Training Progress: \tEpoch 73 [0/1692 (0.00%)]\t\tLoss: 0.95746\n",
            "Training Progress: \tEpoch 73 [320/1692 (18.87%)]\t\tLoss: 0.91806\n",
            "Training Progress: \tEpoch 73 [640/1692 (37.74%)]\t\tLoss: 0.78599\n",
            "Training Progress: \tEpoch 73 [960/1692 (56.60%)]\t\tLoss: 0.83201\n",
            "Training Progress: \tEpoch 73 [1280/1692 (75.47%)]\t\tLoss: 0.91209\n",
            "Training Progress: \tEpoch 73 [1600/1692 (94.34%)]\t\tLoss: 1.05972\n",
            "\tTrain loss: 0.02346, Accuracy: 1203/1692 (71.10%)\n",
            "\tValidation loss: 0.00448, Accuracy: 93/423 (21.99%)\n",
            "\tTest loss: 0.00433, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 74 [0/1692 (0.00%)]\t\tLoss: 0.97514\n",
            "Training Progress: \tEpoch 74 [320/1692 (18.87%)]\t\tLoss: 0.96529\n",
            "Training Progress: \tEpoch 74 [640/1692 (37.74%)]\t\tLoss: 0.74016\n",
            "Training Progress: \tEpoch 74 [960/1692 (56.60%)]\t\tLoss: 0.96146\n",
            "Training Progress: \tEpoch 74 [1280/1692 (75.47%)]\t\tLoss: 0.97500\n",
            "Training Progress: \tEpoch 74 [1600/1692 (94.34%)]\t\tLoss: 0.92286\n",
            "\tTrain loss: 0.02319, Accuracy: 1219/1692 (72.04%)\n",
            "\tValidation loss: 0.00440, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00431, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 75 [0/1692 (0.00%)]\t\tLoss: 1.01484\n",
            "Training Progress: \tEpoch 75 [320/1692 (18.87%)]\t\tLoss: 0.86185\n",
            "Training Progress: \tEpoch 75 [640/1692 (37.74%)]\t\tLoss: 0.68900\n",
            "Training Progress: \tEpoch 75 [960/1692 (56.60%)]\t\tLoss: 0.95333\n",
            "Training Progress: \tEpoch 75 [1280/1692 (75.47%)]\t\tLoss: 0.85406\n",
            "Training Progress: \tEpoch 75 [1600/1692 (94.34%)]\t\tLoss: 0.81187\n",
            "\tTrain loss: 0.02238, Accuracy: 1210/1692 (71.51%)\n",
            "\tValidation loss: 0.00454, Accuracy: 98/423 (23.17%)\n",
            "\tTest loss: 0.00444, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Training Progress: \tEpoch 76 [0/1692 (0.00%)]\t\tLoss: 0.77647\n",
            "Training Progress: \tEpoch 76 [320/1692 (18.87%)]\t\tLoss: 0.72846\n",
            "Training Progress: \tEpoch 76 [640/1692 (37.74%)]\t\tLoss: 0.58332\n",
            "Training Progress: \tEpoch 76 [960/1692 (56.60%)]\t\tLoss: 0.81703\n",
            "Training Progress: \tEpoch 76 [1280/1692 (75.47%)]\t\tLoss: 0.76286\n",
            "Training Progress: \tEpoch 76 [1600/1692 (94.34%)]\t\tLoss: 0.97670\n",
            "\tTrain loss: 0.02221, Accuracy: 1234/1692 (72.93%)\n",
            "\tValidation loss: 0.00477, Accuracy: 95/423 (22.46%)\n",
            "\tTest loss: 0.00455, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 77 [0/1692 (0.00%)]\t\tLoss: 0.66173\n",
            "Training Progress: \tEpoch 77 [320/1692 (18.87%)]\t\tLoss: 0.86416\n",
            "Training Progress: \tEpoch 77 [640/1692 (37.74%)]\t\tLoss: 0.76964\n",
            "Training Progress: \tEpoch 77 [960/1692 (56.60%)]\t\tLoss: 0.88253\n",
            "Training Progress: \tEpoch 77 [1280/1692 (75.47%)]\t\tLoss: 0.87948\n",
            "Training Progress: \tEpoch 77 [1600/1692 (94.34%)]\t\tLoss: 0.87746\n",
            "\tTrain loss: 0.02221, Accuracy: 1223/1692 (72.28%)\n",
            "\tValidation loss: 0.00472, Accuracy: 97/423 (22.93%)\n",
            "\tTest loss: 0.00471, Accuracy: 106/443 (23.93%)\n",
            "\n",
            "Training Progress: \tEpoch 78 [0/1692 (0.00%)]\t\tLoss: 0.80640\n",
            "Training Progress: \tEpoch 78 [320/1692 (18.87%)]\t\tLoss: 0.90574\n",
            "Training Progress: \tEpoch 78 [640/1692 (37.74%)]\t\tLoss: 0.84966\n",
            "Training Progress: \tEpoch 78 [960/1692 (56.60%)]\t\tLoss: 0.74212\n",
            "Training Progress: \tEpoch 78 [1280/1692 (75.47%)]\t\tLoss: 0.76381\n",
            "Training Progress: \tEpoch 78 [1600/1692 (94.34%)]\t\tLoss: 0.88370\n",
            "\tTrain loss: 0.02167, Accuracy: 1234/1692 (72.93%)\n",
            "\tValidation loss: 0.00479, Accuracy: 96/423 (22.70%)\n",
            "\tTest loss: 0.00454, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 79 [0/1692 (0.00%)]\t\tLoss: 0.73895\n",
            "Training Progress: \tEpoch 79 [320/1692 (18.87%)]\t\tLoss: 0.83017\n",
            "Training Progress: \tEpoch 79 [640/1692 (37.74%)]\t\tLoss: 0.74862\n",
            "Training Progress: \tEpoch 79 [960/1692 (56.60%)]\t\tLoss: 0.94804\n",
            "Training Progress: \tEpoch 79 [1280/1692 (75.47%)]\t\tLoss: 0.72895\n",
            "Training Progress: \tEpoch 79 [1600/1692 (94.34%)]\t\tLoss: 0.80562\n",
            "\tTrain loss: 0.02165, Accuracy: 1261/1692 (74.53%)\n",
            "\tValidation loss: 0.00483, Accuracy: 94/423 (22.22%)\n",
            "\tTest loss: 0.00466, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 80 [0/1692 (0.00%)]\t\tLoss: 0.78208\n",
            "Training Progress: \tEpoch 80 [320/1692 (18.87%)]\t\tLoss: 0.86477\n",
            "Training Progress: \tEpoch 80 [640/1692 (37.74%)]\t\tLoss: 0.80148\n",
            "Training Progress: \tEpoch 80 [960/1692 (56.60%)]\t\tLoss: 0.84656\n",
            "Training Progress: \tEpoch 80 [1280/1692 (75.47%)]\t\tLoss: 0.92259\n",
            "Training Progress: \tEpoch 80 [1600/1692 (94.34%)]\t\tLoss: 0.87091\n",
            "\tTrain loss: 0.02067, Accuracy: 1268/1692 (74.94%)\n",
            "\tValidation loss: 0.00493, Accuracy: 108/423 (25.53%)\n",
            "\tTest loss: 0.00460, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 81 [0/1692 (0.00%)]\t\tLoss: 0.80692\n",
            "Training Progress: \tEpoch 81 [320/1692 (18.87%)]\t\tLoss: 0.55828\n",
            "Training Progress: \tEpoch 81 [640/1692 (37.74%)]\t\tLoss: 0.79000\n",
            "Training Progress: \tEpoch 81 [960/1692 (56.60%)]\t\tLoss: 0.91725\n",
            "Training Progress: \tEpoch 81 [1280/1692 (75.47%)]\t\tLoss: 0.72569\n",
            "Training Progress: \tEpoch 81 [1600/1692 (94.34%)]\t\tLoss: 1.09263\n",
            "\tTrain loss: 0.02057, Accuracy: 1286/1692 (76.00%)\n",
            "\tValidation loss: 0.00468, Accuracy: 102/423 (24.11%)\n",
            "\tTest loss: 0.00459, Accuracy: 107/443 (24.15%)\n",
            "\n",
            "Training Progress: \tEpoch 82 [0/1692 (0.00%)]\t\tLoss: 0.80731\n",
            "Training Progress: \tEpoch 82 [320/1692 (18.87%)]\t\tLoss: 0.92490\n",
            "Training Progress: \tEpoch 82 [640/1692 (37.74%)]\t\tLoss: 0.73704\n",
            "Training Progress: \tEpoch 82 [960/1692 (56.60%)]\t\tLoss: 0.91392\n",
            "Training Progress: \tEpoch 82 [1280/1692 (75.47%)]\t\tLoss: 0.84318\n",
            "Training Progress: \tEpoch 82 [1600/1692 (94.34%)]\t\tLoss: 0.73919\n",
            "\tTrain loss: 0.02094, Accuracy: 1257/1692 (74.29%)\n",
            "\tValidation loss: 0.00487, Accuracy: 97/423 (22.93%)\n",
            "\tTest loss: 0.00461, Accuracy: 108/443 (24.38%)\n",
            "\n",
            "Training Progress: \tEpoch 83 [0/1692 (0.00%)]\t\tLoss: 0.82675\n",
            "Training Progress: \tEpoch 83 [320/1692 (18.87%)]\t\tLoss: 0.84092\n",
            "Training Progress: \tEpoch 83 [640/1692 (37.74%)]\t\tLoss: 0.79536\n",
            "Training Progress: \tEpoch 83 [960/1692 (56.60%)]\t\tLoss: 0.75266\n",
            "Training Progress: \tEpoch 83 [1280/1692 (75.47%)]\t\tLoss: 0.71006\n",
            "Training Progress: \tEpoch 83 [1600/1692 (94.34%)]\t\tLoss: 0.80860\n",
            "\tTrain loss: 0.01999, Accuracy: 1318/1692 (77.90%)\n",
            "\tValidation loss: 0.00487, Accuracy: 95/423 (22.46%)\n",
            "\tTest loss: 0.00462, Accuracy: 113/443 (25.51%)\n",
            "\n",
            "Training Progress: \tEpoch 84 [0/1692 (0.00%)]\t\tLoss: 0.66706\n",
            "Training Progress: \tEpoch 84 [320/1692 (18.87%)]\t\tLoss: 0.70615\n",
            "Training Progress: \tEpoch 84 [640/1692 (37.74%)]\t\tLoss: 0.69179\n",
            "Training Progress: \tEpoch 84 [960/1692 (56.60%)]\t\tLoss: 0.75070\n",
            "Training Progress: \tEpoch 84 [1280/1692 (75.47%)]\t\tLoss: 0.86429\n",
            "Training Progress: \tEpoch 84 [1600/1692 (94.34%)]\t\tLoss: 0.96646\n",
            "\tTrain loss: 0.01979, Accuracy: 1285/1692 (75.95%)\n",
            "\tValidation loss: 0.00520, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00503, Accuracy: 104/443 (23.48%)\n",
            "\n",
            "Training Progress: \tEpoch 85 [0/1692 (0.00%)]\t\tLoss: 0.76845\n",
            "Training Progress: \tEpoch 85 [320/1692 (18.87%)]\t\tLoss: 0.71986\n",
            "Training Progress: \tEpoch 85 [640/1692 (37.74%)]\t\tLoss: 0.80246\n",
            "Training Progress: \tEpoch 85 [960/1692 (56.60%)]\t\tLoss: 0.65882\n",
            "Training Progress: \tEpoch 85 [1280/1692 (75.47%)]\t\tLoss: 0.66632\n",
            "Training Progress: \tEpoch 85 [1600/1692 (94.34%)]\t\tLoss: 0.88568\n",
            "\tTrain loss: 0.01984, Accuracy: 1283/1692 (75.83%)\n",
            "\tValidation loss: 0.00518, Accuracy: 104/423 (24.59%)\n",
            "\tTest loss: 0.00486, Accuracy: 122/443 (27.54%)\n",
            "\n",
            "Training Progress: \tEpoch 86 [0/1692 (0.00%)]\t\tLoss: 0.89061\n",
            "Training Progress: \tEpoch 86 [320/1692 (18.87%)]\t\tLoss: 0.92167\n",
            "Training Progress: \tEpoch 86 [640/1692 (37.74%)]\t\tLoss: 0.55063\n",
            "Training Progress: \tEpoch 86 [960/1692 (56.60%)]\t\tLoss: 0.69766\n",
            "Training Progress: \tEpoch 86 [1280/1692 (75.47%)]\t\tLoss: 0.95102\n",
            "Training Progress: \tEpoch 86 [1600/1692 (94.34%)]\t\tLoss: 0.95162\n",
            "\tTrain loss: 0.01980, Accuracy: 1303/1692 (77.01%)\n",
            "\tValidation loss: 0.00523, Accuracy: 91/423 (21.51%)\n",
            "\tTest loss: 0.00487, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 87 [0/1692 (0.00%)]\t\tLoss: 0.59241\n",
            "Training Progress: \tEpoch 87 [320/1692 (18.87%)]\t\tLoss: 0.60928\n",
            "Training Progress: \tEpoch 87 [640/1692 (37.74%)]\t\tLoss: 0.57818\n",
            "Training Progress: \tEpoch 87 [960/1692 (56.60%)]\t\tLoss: 0.74691\n",
            "Training Progress: \tEpoch 87 [1280/1692 (75.47%)]\t\tLoss: 0.93187\n",
            "Training Progress: \tEpoch 87 [1600/1692 (94.34%)]\t\tLoss: 0.77435\n",
            "\tTrain loss: 0.01937, Accuracy: 1311/1692 (77.48%)\n",
            "\tValidation loss: 0.00515, Accuracy: 98/423 (23.17%)\n",
            "\tTest loss: 0.00475, Accuracy: 122/443 (27.54%)\n",
            "\n",
            "Training Progress: \tEpoch 88 [0/1692 (0.00%)]\t\tLoss: 0.70007\n",
            "Training Progress: \tEpoch 88 [320/1692 (18.87%)]\t\tLoss: 0.69797\n",
            "Training Progress: \tEpoch 88 [640/1692 (37.74%)]\t\tLoss: 0.58047\n",
            "Training Progress: \tEpoch 88 [960/1692 (56.60%)]\t\tLoss: 0.69629\n",
            "Training Progress: \tEpoch 88 [1280/1692 (75.47%)]\t\tLoss: 0.87086\n",
            "Training Progress: \tEpoch 88 [1600/1692 (94.34%)]\t\tLoss: 0.84211\n",
            "\tTrain loss: 0.01889, Accuracy: 1317/1692 (77.84%)\n",
            "\tValidation loss: 0.00525, Accuracy: 93/423 (21.99%)\n",
            "\tTest loss: 0.00494, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 89 [0/1692 (0.00%)]\t\tLoss: 0.78346\n",
            "Training Progress: \tEpoch 89 [320/1692 (18.87%)]\t\tLoss: 0.64359\n",
            "Training Progress: \tEpoch 89 [640/1692 (37.74%)]\t\tLoss: 0.58084\n",
            "Training Progress: \tEpoch 89 [960/1692 (56.60%)]\t\tLoss: 0.82954\n",
            "Training Progress: \tEpoch 89 [1280/1692 (75.47%)]\t\tLoss: 0.75060\n",
            "Training Progress: \tEpoch 89 [1600/1692 (94.34%)]\t\tLoss: 0.89050\n",
            "\tTrain loss: 0.01831, Accuracy: 1337/1692 (79.02%)\n",
            "\tValidation loss: 0.00522, Accuracy: 98/423 (23.17%)\n",
            "\tTest loss: 0.00498, Accuracy: 120/443 (27.09%)\n",
            "\n",
            "Training Progress: \tEpoch 90 [0/1692 (0.00%)]\t\tLoss: 0.84173\n",
            "Training Progress: \tEpoch 90 [320/1692 (18.87%)]\t\tLoss: 0.81282\n",
            "Training Progress: \tEpoch 90 [640/1692 (37.74%)]\t\tLoss: 0.66203\n",
            "Training Progress: \tEpoch 90 [960/1692 (56.60%)]\t\tLoss: 0.71422\n",
            "Training Progress: \tEpoch 90 [1280/1692 (75.47%)]\t\tLoss: 0.68740\n",
            "Training Progress: \tEpoch 90 [1600/1692 (94.34%)]\t\tLoss: 0.82546\n",
            "\tTrain loss: 0.01855, Accuracy: 1324/1692 (78.25%)\n",
            "\tValidation loss: 0.00546, Accuracy: 95/423 (22.46%)\n",
            "\tTest loss: 0.00502, Accuracy: 112/443 (25.28%)\n",
            "\n",
            "Training Progress: \tEpoch 91 [0/1692 (0.00%)]\t\tLoss: 0.72029\n",
            "Training Progress: \tEpoch 91 [320/1692 (18.87%)]\t\tLoss: 0.61319\n",
            "Training Progress: \tEpoch 91 [640/1692 (37.74%)]\t\tLoss: 0.47767\n",
            "Training Progress: \tEpoch 91 [960/1692 (56.60%)]\t\tLoss: 0.74767\n",
            "Training Progress: \tEpoch 91 [1280/1692 (75.47%)]\t\tLoss: 0.91027\n",
            "Training Progress: \tEpoch 91 [1600/1692 (94.34%)]\t\tLoss: 0.73573\n",
            "\tTrain loss: 0.01773, Accuracy: 1342/1692 (79.31%)\n",
            "\tValidation loss: 0.00531, Accuracy: 100/423 (23.64%)\n",
            "\tTest loss: 0.00493, Accuracy: 119/443 (26.86%)\n",
            "\n",
            "Training Progress: \tEpoch 92 [0/1692 (0.00%)]\t\tLoss: 0.58511\n",
            "Training Progress: \tEpoch 92 [320/1692 (18.87%)]\t\tLoss: 0.65472\n",
            "Training Progress: \tEpoch 92 [640/1692 (37.74%)]\t\tLoss: 0.64579\n",
            "Training Progress: \tEpoch 92 [960/1692 (56.60%)]\t\tLoss: 0.67378\n",
            "Training Progress: \tEpoch 92 [1280/1692 (75.47%)]\t\tLoss: 0.64690\n",
            "Training Progress: \tEpoch 92 [1600/1692 (94.34%)]\t\tLoss: 0.85977\n",
            "\tTrain loss: 0.01735, Accuracy: 1338/1692 (79.08%)\n",
            "\tValidation loss: 0.00528, Accuracy: 89/423 (21.04%)\n",
            "\tTest loss: 0.00501, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 93 [0/1692 (0.00%)]\t\tLoss: 0.50436\n",
            "Training Progress: \tEpoch 93 [320/1692 (18.87%)]\t\tLoss: 0.81502\n",
            "Training Progress: \tEpoch 93 [640/1692 (37.74%)]\t\tLoss: 0.63102\n",
            "Training Progress: \tEpoch 93 [960/1692 (56.60%)]\t\tLoss: 0.63675\n",
            "Training Progress: \tEpoch 93 [1280/1692 (75.47%)]\t\tLoss: 0.64409\n",
            "Training Progress: \tEpoch 93 [1600/1692 (94.34%)]\t\tLoss: 0.74831\n",
            "\tTrain loss: 0.01811, Accuracy: 1334/1692 (78.84%)\n",
            "\tValidation loss: 0.00546, Accuracy: 97/423 (22.93%)\n",
            "\tTest loss: 0.00516, Accuracy: 116/443 (26.19%)\n",
            "\n",
            "Training Progress: \tEpoch 94 [0/1692 (0.00%)]\t\tLoss: 0.63277\n",
            "Training Progress: \tEpoch 94 [320/1692 (18.87%)]\t\tLoss: 0.52896\n",
            "Training Progress: \tEpoch 94 [640/1692 (37.74%)]\t\tLoss: 0.61534\n",
            "Training Progress: \tEpoch 94 [960/1692 (56.60%)]\t\tLoss: 0.69753\n",
            "Training Progress: \tEpoch 94 [1280/1692 (75.47%)]\t\tLoss: 0.71157\n",
            "Training Progress: \tEpoch 94 [1600/1692 (94.34%)]\t\tLoss: 0.89122\n",
            "\tTrain loss: 0.01697, Accuracy: 1358/1692 (80.26%)\n",
            "\tValidation loss: 0.00536, Accuracy: 95/423 (22.46%)\n",
            "\tTest loss: 0.00519, Accuracy: 117/443 (26.41%)\n",
            "\n",
            "Training Progress: \tEpoch 95 [0/1692 (0.00%)]\t\tLoss: 0.58024\n",
            "Training Progress: \tEpoch 95 [320/1692 (18.87%)]\t\tLoss: 0.54921\n",
            "Training Progress: \tEpoch 95 [640/1692 (37.74%)]\t\tLoss: 0.62283\n",
            "Training Progress: \tEpoch 95 [960/1692 (56.60%)]\t\tLoss: 0.82119\n",
            "Training Progress: \tEpoch 95 [1280/1692 (75.47%)]\t\tLoss: 0.74706\n",
            "Training Progress: \tEpoch 95 [1600/1692 (94.34%)]\t\tLoss: 0.74030\n",
            "\tTrain loss: 0.01708, Accuracy: 1371/1692 (81.03%)\n",
            "\tValidation loss: 0.00540, Accuracy: 97/423 (22.93%)\n",
            "\tTest loss: 0.00516, Accuracy: 119/443 (26.86%)\n",
            "\n",
            "Training Progress: \tEpoch 96 [0/1692 (0.00%)]\t\tLoss: 0.59682\n",
            "Training Progress: \tEpoch 96 [320/1692 (18.87%)]\t\tLoss: 0.88897\n",
            "Training Progress: \tEpoch 96 [640/1692 (37.74%)]\t\tLoss: 0.61495\n",
            "Training Progress: \tEpoch 96 [960/1692 (56.60%)]\t\tLoss: 0.65260\n",
            "Training Progress: \tEpoch 96 [1280/1692 (75.47%)]\t\tLoss: 0.78018\n",
            "Training Progress: \tEpoch 96 [1600/1692 (94.34%)]\t\tLoss: 0.75544\n",
            "\tTrain loss: 0.01650, Accuracy: 1376/1692 (81.32%)\n",
            "\tValidation loss: 0.00559, Accuracy: 86/423 (20.33%)\n",
            "\tTest loss: 0.00535, Accuracy: 123/443 (27.77%)\n",
            "\n",
            "Training Progress: \tEpoch 97 [0/1692 (0.00%)]\t\tLoss: 0.61257\n",
            "Training Progress: \tEpoch 97 [320/1692 (18.87%)]\t\tLoss: 0.55737\n",
            "Training Progress: \tEpoch 97 [640/1692 (37.74%)]\t\tLoss: 0.53231\n",
            "Training Progress: \tEpoch 97 [960/1692 (56.60%)]\t\tLoss: 0.67234\n",
            "Training Progress: \tEpoch 97 [1280/1692 (75.47%)]\t\tLoss: 0.78740\n",
            "Training Progress: \tEpoch 97 [1600/1692 (94.34%)]\t\tLoss: 0.89516\n",
            "\tTrain loss: 0.01627, Accuracy: 1355/1692 (80.08%)\n",
            "\tValidation loss: 0.00566, Accuracy: 93/423 (21.99%)\n",
            "\tTest loss: 0.00532, Accuracy: 109/443 (24.60%)\n",
            "\n",
            "Training Progress: \tEpoch 98 [0/1692 (0.00%)]\t\tLoss: 0.57389\n",
            "Training Progress: \tEpoch 98 [320/1692 (18.87%)]\t\tLoss: 0.58583\n",
            "Training Progress: \tEpoch 98 [640/1692 (37.74%)]\t\tLoss: 0.45807\n",
            "Training Progress: \tEpoch 98 [960/1692 (56.60%)]\t\tLoss: 0.66816\n",
            "Training Progress: \tEpoch 98 [1280/1692 (75.47%)]\t\tLoss: 0.75570\n",
            "Training Progress: \tEpoch 98 [1600/1692 (94.34%)]\t\tLoss: 0.70659\n",
            "\tTrain loss: 0.01629, Accuracy: 1367/1692 (80.79%)\n",
            "\tValidation loss: 0.00562, Accuracy: 89/423 (21.04%)\n",
            "\tTest loss: 0.00516, Accuracy: 123/443 (27.77%)\n",
            "\n",
            "Training Progress: \tEpoch 99 [0/1692 (0.00%)]\t\tLoss: 0.57943\n",
            "Training Progress: \tEpoch 99 [320/1692 (18.87%)]\t\tLoss: 0.50934\n",
            "Training Progress: \tEpoch 99 [640/1692 (37.74%)]\t\tLoss: 0.64166\n",
            "Training Progress: \tEpoch 99 [960/1692 (56.60%)]\t\tLoss: 0.61555\n",
            "Training Progress: \tEpoch 99 [1280/1692 (75.47%)]\t\tLoss: 0.83760\n",
            "Training Progress: \tEpoch 99 [1600/1692 (94.34%)]\t\tLoss: 0.79425\n",
            "\tTrain loss: 0.01522, Accuracy: 1399/1692 (82.68%)\n",
            "\tValidation loss: 0.00555, Accuracy: 103/423 (24.35%)\n",
            "\tTest loss: 0.00519, Accuracy: 128/443 (28.89%)\n",
            "\n",
            "Training Progress: \tEpoch 100 [0/1692 (0.00%)]\t\tLoss: 0.65067\n",
            "Training Progress: \tEpoch 100 [320/1692 (18.87%)]\t\tLoss: 0.45964\n",
            "Training Progress: \tEpoch 100 [640/1692 (37.74%)]\t\tLoss: 0.32244\n",
            "Training Progress: \tEpoch 100 [960/1692 (56.60%)]\t\tLoss: 0.54931\n",
            "Training Progress: \tEpoch 100 [1280/1692 (75.47%)]\t\tLoss: 0.66671\n",
            "Training Progress: \tEpoch 100 [1600/1692 (94.34%)]\t\tLoss: 0.62568\n",
            "\tTrain loss: 0.01523, Accuracy: 1379/1692 (81.50%)\n",
            "\tValidation loss: 0.00569, Accuracy: 99/423 (23.40%)\n",
            "\tTest loss: 0.00541, Accuracy: 114/443 (25.73%)\n",
            "\n",
            "Best validation accuracy:\n",
            "0.28368794326241137\n",
            "Best test accuracy:\n",
            "0.28893905191873587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAEICAYAAACkmHavAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0dkb7FVAfA7e"
      },
      "source": [
        "## CNN + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JTUyv1HLfrm2",
        "outputId": "519a1179-f22e-4281-ad7e-f91e9b4be477",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = CNN_LSTM().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=BETAS, eps=EPS, weight_decay=DECAY)\n",
        "train_and_evaluate(model, optimizer, data_loaders, num_epochs=EPOCHS)\n",
        "del model"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Progress: \tEpoch 1 [0/1692 (0.00%)]\t\tLoss: 1.38706\n",
            "Training Progress: \tEpoch 1 [320/1692 (18.87%)]\t\tLoss: 1.39128\n",
            "Training Progress: \tEpoch 1 [640/1692 (37.74%)]\t\tLoss: 1.38681\n",
            "Training Progress: \tEpoch 1 [960/1692 (56.60%)]\t\tLoss: 1.39001\n",
            "Training Progress: \tEpoch 1 [1280/1692 (75.47%)]\t\tLoss: 1.38722\n",
            "Training Progress: \tEpoch 1 [1600/1692 (94.34%)]\t\tLoss: 1.37998\n",
            "\tTrain loss: 0.04336, Accuracy: 458/1692 (27.07%)\n",
            "\tValidation loss: 0.00327, Accuracy: 128/423 (30.26%)\n",
            "\tTest loss: 0.00313, Accuracy: 111/443 (25.06%)\n",
            "\n",
            "Training Progress: \tEpoch 2 [0/1692 (0.00%)]\t\tLoss: 1.38579\n",
            "Training Progress: \tEpoch 2 [320/1692 (18.87%)]\t\tLoss: 1.38267\n",
            "Training Progress: \tEpoch 2 [640/1692 (37.74%)]\t\tLoss: 1.38471\n",
            "Training Progress: \tEpoch 2 [960/1692 (56.60%)]\t\tLoss: 1.36230\n",
            "Training Progress: \tEpoch 2 [1280/1692 (75.47%)]\t\tLoss: 1.35617\n",
            "Training Progress: \tEpoch 2 [1600/1692 (94.34%)]\t\tLoss: 1.31852\n",
            "\tTrain loss: 0.04204, Accuracy: 588/1692 (34.75%)\n",
            "\tValidation loss: 0.00320, Accuracy: 141/423 (33.33%)\n",
            "\tTest loss: 0.00304, Accuracy: 146/443 (32.96%)\n",
            "\n",
            "Training Progress: \tEpoch 3 [0/1692 (0.00%)]\t\tLoss: 1.36780\n",
            "Training Progress: \tEpoch 3 [320/1692 (18.87%)]\t\tLoss: 1.37057\n",
            "Training Progress: \tEpoch 3 [640/1692 (37.74%)]\t\tLoss: 1.37923\n",
            "Training Progress: \tEpoch 3 [960/1692 (56.60%)]\t\tLoss: 1.33345\n",
            "Training Progress: \tEpoch 3 [1280/1692 (75.47%)]\t\tLoss: 1.32694\n",
            "Training Progress: \tEpoch 3 [1600/1692 (94.34%)]\t\tLoss: 1.31448\n",
            "\tTrain loss: 0.04193, Accuracy: 566/1692 (33.45%)\n",
            "\tValidation loss: 0.00318, Accuracy: 138/423 (32.62%)\n",
            "\tTest loss: 0.00304, Accuracy: 125/443 (28.22%)\n",
            "\n",
            "Training Progress: \tEpoch 4 [0/1692 (0.00%)]\t\tLoss: 1.33760\n",
            "Training Progress: \tEpoch 4 [320/1692 (18.87%)]\t\tLoss: 1.35097\n",
            "Training Progress: \tEpoch 4 [640/1692 (37.74%)]\t\tLoss: 1.38273\n",
            "Training Progress: \tEpoch 4 [960/1692 (56.60%)]\t\tLoss: 1.31506\n",
            "Training Progress: \tEpoch 4 [1280/1692 (75.47%)]\t\tLoss: 1.30312\n",
            "Training Progress: \tEpoch 4 [1600/1692 (94.34%)]\t\tLoss: 1.28449\n",
            "\tTrain loss: 0.04056, Accuracy: 602/1692 (35.58%)\n",
            "\tValidation loss: 0.00311, Accuracy: 135/423 (31.91%)\n",
            "\tTest loss: 0.00295, Accuracy: 161/443 (36.34%)\n",
            "\n",
            "Training Progress: \tEpoch 5 [0/1692 (0.00%)]\t\tLoss: 1.38381\n",
            "Training Progress: \tEpoch 5 [320/1692 (18.87%)]\t\tLoss: 1.35295\n",
            "Training Progress: \tEpoch 5 [640/1692 (37.74%)]\t\tLoss: 1.23426\n",
            "Training Progress: \tEpoch 5 [960/1692 (56.60%)]\t\tLoss: 1.26910\n",
            "Training Progress: \tEpoch 5 [1280/1692 (75.47%)]\t\tLoss: 1.25078\n",
            "Training Progress: \tEpoch 5 [1600/1692 (94.34%)]\t\tLoss: 1.27302\n",
            "\tTrain loss: 0.04007, Accuracy: 633/1692 (37.41%)\n",
            "\tValidation loss: 0.00308, Accuracy: 150/423 (35.46%)\n",
            "\tTest loss: 0.00297, Accuracy: 159/443 (35.89%)\n",
            "\n",
            "Training Progress: \tEpoch 6 [0/1692 (0.00%)]\t\tLoss: 1.33908\n",
            "Training Progress: \tEpoch 6 [320/1692 (18.87%)]\t\tLoss: 1.36069\n",
            "Training Progress: \tEpoch 6 [640/1692 (37.74%)]\t\tLoss: 1.29789\n",
            "Training Progress: \tEpoch 6 [960/1692 (56.60%)]\t\tLoss: 1.30122\n",
            "Training Progress: \tEpoch 6 [1280/1692 (75.47%)]\t\tLoss: 1.26702\n",
            "Training Progress: \tEpoch 6 [1600/1692 (94.34%)]\t\tLoss: 1.32964\n",
            "\tTrain loss: 0.03968, Accuracy: 655/1692 (38.71%)\n",
            "\tValidation loss: 0.00306, Accuracy: 153/423 (36.17%)\n",
            "\tTest loss: 0.00292, Accuracy: 153/443 (34.54%)\n",
            "\n",
            "Training Progress: \tEpoch 7 [0/1692 (0.00%)]\t\tLoss: 1.29946\n",
            "Training Progress: \tEpoch 7 [320/1692 (18.87%)]\t\tLoss: 1.28529\n",
            "Training Progress: \tEpoch 7 [640/1692 (37.74%)]\t\tLoss: 1.26269\n",
            "Training Progress: \tEpoch 7 [960/1692 (56.60%)]\t\tLoss: 1.26559\n",
            "Training Progress: \tEpoch 7 [1280/1692 (75.47%)]\t\tLoss: 1.20204\n",
            "Training Progress: \tEpoch 7 [1600/1692 (94.34%)]\t\tLoss: 1.28492\n",
            "\tTrain loss: 0.03885, Accuracy: 680/1692 (40.19%)\n",
            "\tValidation loss: 0.00303, Accuracy: 155/423 (36.64%)\n",
            "\tTest loss: 0.00289, Accuracy: 160/443 (36.12%)\n",
            "\n",
            "Training Progress: \tEpoch 8 [0/1692 (0.00%)]\t\tLoss: 1.31225\n",
            "Training Progress: \tEpoch 8 [320/1692 (18.87%)]\t\tLoss: 1.30348\n",
            "Training Progress: \tEpoch 8 [640/1692 (37.74%)]\t\tLoss: 1.17992\n",
            "Training Progress: \tEpoch 8 [960/1692 (56.60%)]\t\tLoss: 1.23287\n",
            "Training Progress: \tEpoch 8 [1280/1692 (75.47%)]\t\tLoss: 1.17768\n",
            "Training Progress: \tEpoch 8 [1600/1692 (94.34%)]\t\tLoss: 1.24635\n",
            "\tTrain loss: 0.03916, Accuracy: 665/1692 (39.30%)\n",
            "\tValidation loss: 0.00304, Accuracy: 159/423 (37.59%)\n",
            "\tTest loss: 0.00292, Accuracy: 149/443 (33.63%)\n",
            "\n",
            "Training Progress: \tEpoch 9 [0/1692 (0.00%)]\t\tLoss: 1.29540\n",
            "Training Progress: \tEpoch 9 [320/1692 (18.87%)]\t\tLoss: 1.26046\n",
            "Training Progress: \tEpoch 9 [640/1692 (37.74%)]\t\tLoss: 1.23955\n",
            "Training Progress: \tEpoch 9 [960/1692 (56.60%)]\t\tLoss: 1.23509\n",
            "Training Progress: \tEpoch 9 [1280/1692 (75.47%)]\t\tLoss: 1.29896\n",
            "Training Progress: \tEpoch 9 [1600/1692 (94.34%)]\t\tLoss: 1.29856\n",
            "\tTrain loss: 0.03803, Accuracy: 746/1692 (44.09%)\n",
            "\tValidation loss: 0.00303, Accuracy: 160/423 (37.83%)\n",
            "\tTest loss: 0.00287, Accuracy: 161/443 (36.34%)\n",
            "\n",
            "Training Progress: \tEpoch 10 [0/1692 (0.00%)]\t\tLoss: 1.14856\n",
            "Training Progress: \tEpoch 10 [320/1692 (18.87%)]\t\tLoss: 1.26457\n",
            "Training Progress: \tEpoch 10 [640/1692 (37.74%)]\t\tLoss: 1.14172\n",
            "Training Progress: \tEpoch 10 [960/1692 (56.60%)]\t\tLoss: 1.27595\n",
            "Training Progress: \tEpoch 10 [1280/1692 (75.47%)]\t\tLoss: 1.21988\n",
            "Training Progress: \tEpoch 10 [1600/1692 (94.34%)]\t\tLoss: 1.31797\n",
            "\tTrain loss: 0.03766, Accuracy: 683/1692 (40.37%)\n",
            "\tValidation loss: 0.00302, Accuracy: 148/423 (34.99%)\n",
            "\tTest loss: 0.00289, Accuracy: 157/443 (35.44%)\n",
            "\n",
            "Training Progress: \tEpoch 11 [0/1692 (0.00%)]\t\tLoss: 1.34409\n",
            "Training Progress: \tEpoch 11 [320/1692 (18.87%)]\t\tLoss: 1.26551\n",
            "Training Progress: \tEpoch 11 [640/1692 (37.74%)]\t\tLoss: 1.17417\n",
            "Training Progress: \tEpoch 11 [960/1692 (56.60%)]\t\tLoss: 1.29720\n",
            "Training Progress: \tEpoch 11 [1280/1692 (75.47%)]\t\tLoss: 1.24203\n",
            "Training Progress: \tEpoch 11 [1600/1692 (94.34%)]\t\tLoss: 1.23493\n",
            "\tTrain loss: 0.03823, Accuracy: 673/1692 (39.78%)\n",
            "\tValidation loss: 0.00305, Accuracy: 156/423 (36.88%)\n",
            "\tTest loss: 0.00292, Accuracy: 165/443 (37.25%)\n",
            "\n",
            "Training Progress: \tEpoch 12 [0/1692 (0.00%)]\t\tLoss: 1.22232\n",
            "Training Progress: \tEpoch 12 [320/1692 (18.87%)]\t\tLoss: 1.24468\n",
            "Training Progress: \tEpoch 12 [640/1692 (37.74%)]\t\tLoss: 1.17376\n",
            "Training Progress: \tEpoch 12 [960/1692 (56.60%)]\t\tLoss: 1.23415\n",
            "Training Progress: \tEpoch 12 [1280/1692 (75.47%)]\t\tLoss: 1.20503\n",
            "Training Progress: \tEpoch 12 [1600/1692 (94.34%)]\t\tLoss: 1.28763\n",
            "\tTrain loss: 0.03872, Accuracy: 667/1692 (39.42%)\n",
            "\tValidation loss: 0.00314, Accuracy: 133/423 (31.44%)\n",
            "\tTest loss: 0.00297, Accuracy: 149/443 (33.63%)\n",
            "\n",
            "Training Progress: \tEpoch 13 [0/1692 (0.00%)]\t\tLoss: 1.21292\n",
            "Training Progress: \tEpoch 13 [320/1692 (18.87%)]\t\tLoss: 1.18497\n",
            "Training Progress: \tEpoch 13 [640/1692 (37.74%)]\t\tLoss: 1.15390\n",
            "Training Progress: \tEpoch 13 [960/1692 (56.60%)]\t\tLoss: 1.21281\n",
            "Training Progress: \tEpoch 13 [1280/1692 (75.47%)]\t\tLoss: 1.28663\n",
            "Training Progress: \tEpoch 13 [1600/1692 (94.34%)]\t\tLoss: 1.32455\n",
            "\tTrain loss: 0.03804, Accuracy: 685/1692 (40.48%)\n",
            "\tValidation loss: 0.00307, Accuracy: 145/423 (34.28%)\n",
            "\tTest loss: 0.00292, Accuracy: 157/443 (35.44%)\n",
            "\n",
            "Training Progress: \tEpoch 14 [0/1692 (0.00%)]\t\tLoss: 1.30948\n",
            "Training Progress: \tEpoch 14 [320/1692 (18.87%)]\t\tLoss: 1.17917\n",
            "Training Progress: \tEpoch 14 [640/1692 (37.74%)]\t\tLoss: 1.16367\n",
            "Training Progress: \tEpoch 14 [960/1692 (56.60%)]\t\tLoss: 1.17696\n",
            "Training Progress: \tEpoch 14 [1280/1692 (75.47%)]\t\tLoss: 1.24981\n",
            "Training Progress: \tEpoch 14 [1600/1692 (94.34%)]\t\tLoss: 1.21373\n",
            "\tTrain loss: 0.03723, Accuracy: 747/1692 (44.15%)\n",
            "\tValidation loss: 0.00303, Accuracy: 143/423 (33.81%)\n",
            "\tTest loss: 0.00290, Accuracy: 161/443 (36.34%)\n",
            "\n",
            "Training Progress: \tEpoch 15 [0/1692 (0.00%)]\t\tLoss: 1.22962\n",
            "Training Progress: \tEpoch 15 [320/1692 (18.87%)]\t\tLoss: 1.27800\n",
            "Training Progress: \tEpoch 15 [640/1692 (37.74%)]\t\tLoss: 1.30513\n",
            "Training Progress: \tEpoch 15 [960/1692 (56.60%)]\t\tLoss: 1.20539\n",
            "Training Progress: \tEpoch 15 [1280/1692 (75.47%)]\t\tLoss: 1.14932\n",
            "Training Progress: \tEpoch 15 [1600/1692 (94.34%)]\t\tLoss: 1.25525\n",
            "\tTrain loss: 0.03682, Accuracy: 762/1692 (45.04%)\n",
            "\tValidation loss: 0.00301, Accuracy: 150/423 (35.46%)\n",
            "\tTest loss: 0.00286, Accuracy: 163/443 (36.79%)\n",
            "\n",
            "Training Progress: \tEpoch 16 [0/1692 (0.00%)]\t\tLoss: 1.27022\n",
            "Training Progress: \tEpoch 16 [320/1692 (18.87%)]\t\tLoss: 1.27953\n",
            "Training Progress: \tEpoch 16 [640/1692 (37.74%)]\t\tLoss: 1.04874\n",
            "Training Progress: \tEpoch 16 [960/1692 (56.60%)]\t\tLoss: 1.14623\n",
            "Training Progress: \tEpoch 16 [1280/1692 (75.47%)]\t\tLoss: 1.17541\n",
            "Training Progress: \tEpoch 16 [1600/1692 (94.34%)]\t\tLoss: 1.24646\n",
            "\tTrain loss: 0.03578, Accuracy: 789/1692 (46.63%)\n",
            "\tValidation loss: 0.00299, Accuracy: 152/423 (35.93%)\n",
            "\tTest loss: 0.00286, Accuracy: 173/443 (39.05%)\n",
            "\n",
            "Training Progress: \tEpoch 17 [0/1692 (0.00%)]\t\tLoss: 1.24477\n",
            "Training Progress: \tEpoch 17 [320/1692 (18.87%)]\t\tLoss: 1.17036\n",
            "Training Progress: \tEpoch 17 [640/1692 (37.74%)]\t\tLoss: 1.09756\n",
            "Training Progress: \tEpoch 17 [960/1692 (56.60%)]\t\tLoss: 1.09445\n",
            "Training Progress: \tEpoch 17 [1280/1692 (75.47%)]\t\tLoss: 1.13664\n",
            "Training Progress: \tEpoch 17 [1600/1692 (94.34%)]\t\tLoss: 1.35237\n",
            "\tTrain loss: 0.03755, Accuracy: 701/1692 (41.43%)\n",
            "\tValidation loss: 0.00311, Accuracy: 123/423 (29.08%)\n",
            "\tTest loss: 0.00296, Accuracy: 153/443 (34.54%)\n",
            "\n",
            "Training Progress: \tEpoch 18 [0/1692 (0.00%)]\t\tLoss: 1.21857\n",
            "Training Progress: \tEpoch 18 [320/1692 (18.87%)]\t\tLoss: 1.15601\n",
            "Training Progress: \tEpoch 18 [640/1692 (37.74%)]\t\tLoss: 1.11314\n",
            "Training Progress: \tEpoch 18 [960/1692 (56.60%)]\t\tLoss: 1.19765\n",
            "Training Progress: \tEpoch 18 [1280/1692 (75.47%)]\t\tLoss: 1.25740\n",
            "Training Progress: \tEpoch 18 [1600/1692 (94.34%)]\t\tLoss: 1.17966\n",
            "\tTrain loss: 0.03597, Accuracy: 754/1692 (44.56%)\n",
            "\tValidation loss: 0.00308, Accuracy: 148/423 (34.99%)\n",
            "\tTest loss: 0.00295, Accuracy: 162/443 (36.57%)\n",
            "\n",
            "Training Progress: \tEpoch 19 [0/1692 (0.00%)]\t\tLoss: 1.22474\n",
            "Training Progress: \tEpoch 19 [320/1692 (18.87%)]\t\tLoss: 1.32237\n",
            "Training Progress: \tEpoch 19 [640/1692 (37.74%)]\t\tLoss: 1.06738\n",
            "Training Progress: \tEpoch 19 [960/1692 (56.60%)]\t\tLoss: 1.12423\n",
            "Training Progress: \tEpoch 19 [1280/1692 (75.47%)]\t\tLoss: 1.22650\n",
            "Training Progress: \tEpoch 19 [1600/1692 (94.34%)]\t\tLoss: 1.21609\n",
            "\tTrain loss: 0.03471, Accuracy: 843/1692 (49.82%)\n",
            "\tValidation loss: 0.00298, Accuracy: 149/423 (35.22%)\n",
            "\tTest loss: 0.00280, Accuracy: 178/443 (40.18%)\n",
            "\n",
            "Training Progress: \tEpoch 20 [0/1692 (0.00%)]\t\tLoss: 1.27726\n",
            "Training Progress: \tEpoch 20 [320/1692 (18.87%)]\t\tLoss: 1.28775\n",
            "Training Progress: \tEpoch 20 [640/1692 (37.74%)]\t\tLoss: 1.02785\n",
            "Training Progress: \tEpoch 20 [960/1692 (56.60%)]\t\tLoss: 1.05376\n",
            "Training Progress: \tEpoch 20 [1280/1692 (75.47%)]\t\tLoss: 1.13728\n",
            "Training Progress: \tEpoch 20 [1600/1692 (94.34%)]\t\tLoss: 1.23147\n",
            "\tTrain loss: 0.03537, Accuracy: 774/1692 (45.74%)\n",
            "\tValidation loss: 0.00306, Accuracy: 140/423 (33.10%)\n",
            "\tTest loss: 0.00289, Accuracy: 167/443 (37.70%)\n",
            "\n",
            "Training Progress: \tEpoch 21 [0/1692 (0.00%)]\t\tLoss: 1.21889\n",
            "Training Progress: \tEpoch 21 [320/1692 (18.87%)]\t\tLoss: 1.30633\n",
            "Training Progress: \tEpoch 21 [640/1692 (37.74%)]\t\tLoss: 1.12987\n",
            "Training Progress: \tEpoch 21 [960/1692 (56.60%)]\t\tLoss: 1.05906\n",
            "Training Progress: \tEpoch 21 [1280/1692 (75.47%)]\t\tLoss: 1.16923\n",
            "Training Progress: \tEpoch 21 [1600/1692 (94.34%)]\t\tLoss: 1.35863\n",
            "\tTrain loss: 0.03372, Accuracy: 858/1692 (50.71%)\n",
            "\tValidation loss: 0.00299, Accuracy: 156/423 (36.88%)\n",
            "\tTest loss: 0.00283, Accuracy: 175/443 (39.50%)\n",
            "\n",
            "Training Progress: \tEpoch 22 [0/1692 (0.00%)]\t\tLoss: 1.09444\n",
            "Training Progress: \tEpoch 22 [320/1692 (18.87%)]\t\tLoss: 1.15577\n",
            "Training Progress: \tEpoch 22 [640/1692 (37.74%)]\t\tLoss: 1.11925\n",
            "Training Progress: \tEpoch 22 [960/1692 (56.60%)]\t\tLoss: 1.10107\n",
            "Training Progress: \tEpoch 22 [1280/1692 (75.47%)]\t\tLoss: 1.29472\n",
            "Training Progress: \tEpoch 22 [1600/1692 (94.34%)]\t\tLoss: 1.30061\n",
            "\tTrain loss: 0.03481, Accuracy: 798/1692 (47.16%)\n",
            "\tValidation loss: 0.00308, Accuracy: 143/423 (33.81%)\n",
            "\tTest loss: 0.00292, Accuracy: 162/443 (36.57%)\n",
            "\n",
            "Training Progress: \tEpoch 23 [0/1692 (0.00%)]\t\tLoss: 1.06675\n",
            "Training Progress: \tEpoch 23 [320/1692 (18.87%)]\t\tLoss: 1.15532\n",
            "Training Progress: \tEpoch 23 [640/1692 (37.74%)]\t\tLoss: 1.13149\n",
            "Training Progress: \tEpoch 23 [960/1692 (56.60%)]\t\tLoss: 1.12183\n",
            "Training Progress: \tEpoch 23 [1280/1692 (75.47%)]\t\tLoss: 1.18569\n",
            "Training Progress: \tEpoch 23 [1600/1692 (94.34%)]\t\tLoss: 1.11619\n",
            "\tTrain loss: 0.03303, Accuracy: 871/1692 (51.48%)\n",
            "\tValidation loss: 0.00307, Accuracy: 148/423 (34.99%)\n",
            "\tTest loss: 0.00292, Accuracy: 166/443 (37.47%)\n",
            "\n",
            "Training Progress: \tEpoch 24 [0/1692 (0.00%)]\t\tLoss: 1.14499\n",
            "Training Progress: \tEpoch 24 [320/1692 (18.87%)]\t\tLoss: 1.34817\n",
            "Training Progress: \tEpoch 24 [640/1692 (37.74%)]\t\tLoss: 1.07727\n",
            "Training Progress: \tEpoch 24 [960/1692 (56.60%)]\t\tLoss: 1.06135\n",
            "Training Progress: \tEpoch 24 [1280/1692 (75.47%)]\t\tLoss: 1.15544\n",
            "Training Progress: \tEpoch 24 [1600/1692 (94.34%)]\t\tLoss: 1.17546\n",
            "\tTrain loss: 0.03367, Accuracy: 844/1692 (49.88%)\n",
            "\tValidation loss: 0.00306, Accuracy: 143/423 (33.81%)\n",
            "\tTest loss: 0.00287, Accuracy: 163/443 (36.79%)\n",
            "\n",
            "Training Progress: \tEpoch 25 [0/1692 (0.00%)]\t\tLoss: 1.06425\n",
            "Training Progress: \tEpoch 25 [320/1692 (18.87%)]\t\tLoss: 1.09111\n",
            "Training Progress: \tEpoch 25 [640/1692 (37.74%)]\t\tLoss: 0.98002\n",
            "Training Progress: \tEpoch 25 [960/1692 (56.60%)]\t\tLoss: 1.09586\n",
            "Training Progress: \tEpoch 25 [1280/1692 (75.47%)]\t\tLoss: 1.00060\n",
            "Training Progress: \tEpoch 25 [1600/1692 (94.34%)]\t\tLoss: 1.14624\n",
            "\tTrain loss: 0.03227, Accuracy: 872/1692 (51.54%)\n",
            "\tValidation loss: 0.00307, Accuracy: 150/423 (35.46%)\n",
            "\tTest loss: 0.00294, Accuracy: 168/443 (37.92%)\n",
            "\n",
            "Training Progress: \tEpoch 26 [0/1692 (0.00%)]\t\tLoss: 1.07148\n",
            "Training Progress: \tEpoch 26 [320/1692 (18.87%)]\t\tLoss: 1.25701\n",
            "Training Progress: \tEpoch 26 [640/1692 (37.74%)]\t\tLoss: 1.05739\n",
            "Training Progress: \tEpoch 26 [960/1692 (56.60%)]\t\tLoss: 1.21629\n",
            "Training Progress: \tEpoch 26 [1280/1692 (75.47%)]\t\tLoss: 1.06920\n",
            "Training Progress: \tEpoch 26 [1600/1692 (94.34%)]\t\tLoss: 1.24431\n",
            "\tTrain loss: 0.03230, Accuracy: 902/1692 (53.31%)\n",
            "\tValidation loss: 0.00308, Accuracy: 155/423 (36.64%)\n",
            "\tTest loss: 0.00293, Accuracy: 164/443 (37.02%)\n",
            "\n",
            "Training Progress: \tEpoch 27 [0/1692 (0.00%)]\t\tLoss: 1.25613\n",
            "Training Progress: \tEpoch 27 [320/1692 (18.87%)]\t\tLoss: 1.25011\n",
            "Training Progress: \tEpoch 27 [640/1692 (37.74%)]\t\tLoss: 0.87480\n",
            "Training Progress: \tEpoch 27 [960/1692 (56.60%)]\t\tLoss: 0.90524\n",
            "Training Progress: \tEpoch 27 [1280/1692 (75.47%)]\t\tLoss: 1.05424\n",
            "Training Progress: \tEpoch 27 [1600/1692 (94.34%)]\t\tLoss: 1.08032\n",
            "\tTrain loss: 0.03107, Accuracy: 928/1692 (54.85%)\n",
            "\tValidation loss: 0.00305, Accuracy: 160/423 (37.83%)\n",
            "\tTest loss: 0.00289, Accuracy: 184/443 (41.53%)\n",
            "\n",
            "Training Progress: \tEpoch 28 [0/1692 (0.00%)]\t\tLoss: 1.01268\n",
            "Training Progress: \tEpoch 28 [320/1692 (18.87%)]\t\tLoss: 1.19236\n",
            "Training Progress: \tEpoch 28 [640/1692 (37.74%)]\t\tLoss: 0.94555\n",
            "Training Progress: \tEpoch 28 [960/1692 (56.60%)]\t\tLoss: 1.40955\n",
            "Training Progress: \tEpoch 28 [1280/1692 (75.47%)]\t\tLoss: 1.07985\n",
            "Training Progress: \tEpoch 28 [1600/1692 (94.34%)]\t\tLoss: 1.21070\n",
            "\tTrain loss: 0.03245, Accuracy: 889/1692 (52.54%)\n",
            "\tValidation loss: 0.00303, Accuracy: 151/423 (35.70%)\n",
            "\tTest loss: 0.00290, Accuracy: 169/443 (38.15%)\n",
            "\n",
            "Training Progress: \tEpoch 29 [0/1692 (0.00%)]\t\tLoss: 1.11713\n",
            "Training Progress: \tEpoch 29 [320/1692 (18.87%)]\t\tLoss: 1.15385\n",
            "Training Progress: \tEpoch 29 [640/1692 (37.74%)]\t\tLoss: 0.96495\n",
            "Training Progress: \tEpoch 29 [960/1692 (56.60%)]\t\tLoss: 1.02401\n",
            "Training Progress: \tEpoch 29 [1280/1692 (75.47%)]\t\tLoss: 1.14180\n",
            "Training Progress: \tEpoch 29 [1600/1692 (94.34%)]\t\tLoss: 1.08205\n",
            "\tTrain loss: 0.03189, Accuracy: 858/1692 (50.71%)\n",
            "\tValidation loss: 0.00321, Accuracy: 147/423 (34.75%)\n",
            "\tTest loss: 0.00299, Accuracy: 165/443 (37.25%)\n",
            "\n",
            "Training Progress: \tEpoch 30 [0/1692 (0.00%)]\t\tLoss: 0.99523\n",
            "Training Progress: \tEpoch 30 [320/1692 (18.87%)]\t\tLoss: 1.11793\n",
            "Training Progress: \tEpoch 30 [640/1692 (37.74%)]\t\tLoss: 0.90703\n",
            "Training Progress: \tEpoch 30 [960/1692 (56.60%)]\t\tLoss: 1.12335\n",
            "Training Progress: \tEpoch 30 [1280/1692 (75.47%)]\t\tLoss: 1.09291\n",
            "Training Progress: \tEpoch 30 [1600/1692 (94.34%)]\t\tLoss: 1.24268\n",
            "\tTrain loss: 0.03136, Accuracy: 932/1692 (55.08%)\n",
            "\tValidation loss: 0.00311, Accuracy: 159/423 (37.59%)\n",
            "\tTest loss: 0.00298, Accuracy: 169/443 (38.15%)\n",
            "\n",
            "Training Progress: \tEpoch 31 [0/1692 (0.00%)]\t\tLoss: 0.96617\n",
            "Training Progress: \tEpoch 31 [320/1692 (18.87%)]\t\tLoss: 1.10724\n",
            "Training Progress: \tEpoch 31 [640/1692 (37.74%)]\t\tLoss: 0.91901\n",
            "Training Progress: \tEpoch 31 [960/1692 (56.60%)]\t\tLoss: 1.15469\n",
            "Training Progress: \tEpoch 31 [1280/1692 (75.47%)]\t\tLoss: 1.08909\n",
            "Training Progress: \tEpoch 31 [1600/1692 (94.34%)]\t\tLoss: 1.12165\n",
            "\tTrain loss: 0.02926, Accuracy: 977/1692 (57.74%)\n",
            "\tValidation loss: 0.00305, Accuracy: 159/423 (37.59%)\n",
            "\tTest loss: 0.00289, Accuracy: 187/443 (42.21%)\n",
            "\n",
            "Training Progress: \tEpoch 32 [0/1692 (0.00%)]\t\tLoss: 0.91149\n",
            "Training Progress: \tEpoch 32 [320/1692 (18.87%)]\t\tLoss: 1.24039\n",
            "Training Progress: \tEpoch 32 [640/1692 (37.74%)]\t\tLoss: 0.91070\n",
            "Training Progress: \tEpoch 32 [960/1692 (56.60%)]\t\tLoss: 0.94491\n",
            "Training Progress: \tEpoch 32 [1280/1692 (75.47%)]\t\tLoss: 0.93384\n",
            "Training Progress: \tEpoch 32 [1600/1692 (94.34%)]\t\tLoss: 1.13649\n",
            "\tTrain loss: 0.02947, Accuracy: 998/1692 (58.98%)\n",
            "\tValidation loss: 0.00303, Accuracy: 161/423 (38.06%)\n",
            "\tTest loss: 0.00284, Accuracy: 187/443 (42.21%)\n",
            "\n",
            "Training Progress: \tEpoch 33 [0/1692 (0.00%)]\t\tLoss: 0.97015\n",
            "Training Progress: \tEpoch 33 [320/1692 (18.87%)]\t\tLoss: 1.11815\n",
            "Training Progress: \tEpoch 33 [640/1692 (37.74%)]\t\tLoss: 0.87779\n",
            "Training Progress: \tEpoch 33 [960/1692 (56.60%)]\t\tLoss: 0.92015\n",
            "Training Progress: \tEpoch 33 [1280/1692 (75.47%)]\t\tLoss: 1.05258\n",
            "Training Progress: \tEpoch 33 [1600/1692 (94.34%)]\t\tLoss: 1.39158\n",
            "\tTrain loss: 0.02909, Accuracy: 990/1692 (58.51%)\n",
            "\tValidation loss: 0.00306, Accuracy: 170/423 (40.19%)\n",
            "\tTest loss: 0.00288, Accuracy: 198/443 (44.70%)\n",
            "\n",
            "Training Progress: \tEpoch 34 [0/1692 (0.00%)]\t\tLoss: 1.05973\n",
            "Training Progress: \tEpoch 34 [320/1692 (18.87%)]\t\tLoss: 1.12667\n",
            "Training Progress: \tEpoch 34 [640/1692 (37.74%)]\t\tLoss: 0.91613\n",
            "Training Progress: \tEpoch 34 [960/1692 (56.60%)]\t\tLoss: 0.97536\n",
            "Training Progress: \tEpoch 34 [1280/1692 (75.47%)]\t\tLoss: 1.03353\n",
            "Training Progress: \tEpoch 34 [1600/1692 (94.34%)]\t\tLoss: 1.08001\n",
            "\tTrain loss: 0.02877, Accuracy: 984/1692 (58.16%)\n",
            "\tValidation loss: 0.00303, Accuracy: 174/423 (41.13%)\n",
            "\tTest loss: 0.00287, Accuracy: 198/443 (44.70%)\n",
            "\n",
            "Training Progress: \tEpoch 35 [0/1692 (0.00%)]\t\tLoss: 1.17097\n",
            "Training Progress: \tEpoch 35 [320/1692 (18.87%)]\t\tLoss: 1.19496\n",
            "Training Progress: \tEpoch 35 [640/1692 (37.74%)]\t\tLoss: 0.94920\n",
            "Training Progress: \tEpoch 35 [960/1692 (56.60%)]\t\tLoss: 1.12140\n",
            "Training Progress: \tEpoch 35 [1280/1692 (75.47%)]\t\tLoss: 1.10246\n",
            "Training Progress: \tEpoch 35 [1600/1692 (94.34%)]\t\tLoss: 1.30380\n",
            "\tTrain loss: 0.02735, Accuracy: 1058/1692 (62.53%)\n",
            "\tValidation loss: 0.00290, Accuracy: 180/423 (42.55%)\n",
            "\tTest loss: 0.00274, Accuracy: 205/443 (46.28%)\n",
            "\n",
            "Training Progress: \tEpoch 36 [0/1692 (0.00%)]\t\tLoss: 1.03796\n",
            "Training Progress: \tEpoch 36 [320/1692 (18.87%)]\t\tLoss: 1.11090\n",
            "Training Progress: \tEpoch 36 [640/1692 (37.74%)]\t\tLoss: 0.82338\n",
            "Training Progress: \tEpoch 36 [960/1692 (56.60%)]\t\tLoss: 1.00739\n",
            "Training Progress: \tEpoch 36 [1280/1692 (75.47%)]\t\tLoss: 0.93201\n",
            "Training Progress: \tEpoch 36 [1600/1692 (94.34%)]\t\tLoss: 1.08129\n",
            "\tTrain loss: 0.02721, Accuracy: 1046/1692 (61.82%)\n",
            "\tValidation loss: 0.00306, Accuracy: 173/423 (40.90%)\n",
            "\tTest loss: 0.00282, Accuracy: 196/443 (44.24%)\n",
            "\n",
            "Training Progress: \tEpoch 37 [0/1692 (0.00%)]\t\tLoss: 1.02064\n",
            "Training Progress: \tEpoch 37 [320/1692 (18.87%)]\t\tLoss: 1.18751\n",
            "Training Progress: \tEpoch 37 [640/1692 (37.74%)]\t\tLoss: 0.87467\n",
            "Training Progress: \tEpoch 37 [960/1692 (56.60%)]\t\tLoss: 1.02237\n",
            "Training Progress: \tEpoch 37 [1280/1692 (75.47%)]\t\tLoss: 0.91604\n",
            "Training Progress: \tEpoch 37 [1600/1692 (94.34%)]\t\tLoss: 1.04566\n",
            "\tTrain loss: 0.02504, Accuracy: 1119/1692 (66.13%)\n",
            "\tValidation loss: 0.00299, Accuracy: 183/423 (43.26%)\n",
            "\tTest loss: 0.00276, Accuracy: 213/443 (48.08%)\n",
            "\n",
            "Training Progress: \tEpoch 38 [0/1692 (0.00%)]\t\tLoss: 0.97984\n",
            "Training Progress: \tEpoch 38 [320/1692 (18.87%)]\t\tLoss: 1.08986\n",
            "Training Progress: \tEpoch 38 [640/1692 (37.74%)]\t\tLoss: 0.85326\n",
            "Training Progress: \tEpoch 38 [960/1692 (56.60%)]\t\tLoss: 0.98178\n",
            "Training Progress: \tEpoch 38 [1280/1692 (75.47%)]\t\tLoss: 1.03483\n",
            "Training Progress: \tEpoch 38 [1600/1692 (94.34%)]\t\tLoss: 1.11786\n",
            "\tTrain loss: 0.02563, Accuracy: 1096/1692 (64.78%)\n",
            "\tValidation loss: 0.00309, Accuracy: 168/423 (39.72%)\n",
            "\tTest loss: 0.00288, Accuracy: 198/443 (44.70%)\n",
            "\n",
            "Training Progress: \tEpoch 39 [0/1692 (0.00%)]\t\tLoss: 0.97901\n",
            "Training Progress: \tEpoch 39 [320/1692 (18.87%)]\t\tLoss: 1.12486\n",
            "Training Progress: \tEpoch 39 [640/1692 (37.74%)]\t\tLoss: 0.91336\n",
            "Training Progress: \tEpoch 39 [960/1692 (56.60%)]\t\tLoss: 0.98263\n",
            "Training Progress: \tEpoch 39 [1280/1692 (75.47%)]\t\tLoss: 1.07701\n",
            "Training Progress: \tEpoch 39 [1600/1692 (94.34%)]\t\tLoss: 1.13584\n",
            "\tTrain loss: 0.02475, Accuracy: 1170/1692 (69.15%)\n",
            "\tValidation loss: 0.00285, Accuracy: 186/423 (43.97%)\n",
            "\tTest loss: 0.00272, Accuracy: 215/443 (48.53%)\n",
            "\n",
            "Training Progress: \tEpoch 40 [0/1692 (0.00%)]\t\tLoss: 1.04294\n",
            "Training Progress: \tEpoch 40 [320/1692 (18.87%)]\t\tLoss: 0.98802\n",
            "Training Progress: \tEpoch 40 [640/1692 (37.74%)]\t\tLoss: 0.85339\n",
            "Training Progress: \tEpoch 40 [960/1692 (56.60%)]\t\tLoss: 0.92534\n",
            "Training Progress: \tEpoch 40 [1280/1692 (75.47%)]\t\tLoss: 0.90414\n",
            "Training Progress: \tEpoch 40 [1600/1692 (94.34%)]\t\tLoss: 1.11202\n",
            "\tTrain loss: 0.02531, Accuracy: 1116/1692 (65.96%)\n",
            "\tValidation loss: 0.00304, Accuracy: 180/423 (42.55%)\n",
            "\tTest loss: 0.00288, Accuracy: 201/443 (45.37%)\n",
            "\n",
            "Training Progress: \tEpoch 41 [0/1692 (0.00%)]\t\tLoss: 0.88226\n",
            "Training Progress: \tEpoch 41 [320/1692 (18.87%)]\t\tLoss: 1.18079\n",
            "Training Progress: \tEpoch 41 [640/1692 (37.74%)]\t\tLoss: 0.74350\n",
            "Training Progress: \tEpoch 41 [960/1692 (56.60%)]\t\tLoss: 1.00301\n",
            "Training Progress: \tEpoch 41 [1280/1692 (75.47%)]\t\tLoss: 0.87550\n",
            "Training Progress: \tEpoch 41 [1600/1692 (94.34%)]\t\tLoss: 0.96790\n",
            "\tTrain loss: 0.02503, Accuracy: 1092/1692 (64.54%)\n",
            "\tValidation loss: 0.00301, Accuracy: 175/423 (41.37%)\n",
            "\tTest loss: 0.00279, Accuracy: 208/443 (46.95%)\n",
            "\n",
            "Training Progress: \tEpoch 42 [0/1692 (0.00%)]\t\tLoss: 0.77523\n",
            "Training Progress: \tEpoch 42 [320/1692 (18.87%)]\t\tLoss: 1.05099\n",
            "Training Progress: \tEpoch 42 [640/1692 (37.74%)]\t\tLoss: 0.81217\n",
            "Training Progress: \tEpoch 42 [960/1692 (56.60%)]\t\tLoss: 0.87277\n",
            "Training Progress: \tEpoch 42 [1280/1692 (75.47%)]\t\tLoss: 1.04069\n",
            "Training Progress: \tEpoch 42 [1600/1692 (94.34%)]\t\tLoss: 0.92693\n",
            "\tTrain loss: 0.02540, Accuracy: 1097/1692 (64.83%)\n",
            "\tValidation loss: 0.00301, Accuracy: 171/423 (40.43%)\n",
            "\tTest loss: 0.00286, Accuracy: 194/443 (43.79%)\n",
            "\n",
            "Training Progress: \tEpoch 43 [0/1692 (0.00%)]\t\tLoss: 0.86994\n",
            "Training Progress: \tEpoch 43 [320/1692 (18.87%)]\t\tLoss: 1.12980\n",
            "Training Progress: \tEpoch 43 [640/1692 (37.74%)]\t\tLoss: 0.69624\n",
            "Training Progress: \tEpoch 43 [960/1692 (56.60%)]\t\tLoss: 1.03070\n",
            "Training Progress: \tEpoch 43 [1280/1692 (75.47%)]\t\tLoss: 0.84749\n",
            "Training Progress: \tEpoch 43 [1600/1692 (94.34%)]\t\tLoss: 1.09178\n",
            "\tTrain loss: 0.02264, Accuracy: 1181/1692 (69.80%)\n",
            "\tValidation loss: 0.00299, Accuracy: 177/423 (41.84%)\n",
            "\tTest loss: 0.00278, Accuracy: 213/443 (48.08%)\n",
            "\n",
            "Training Progress: \tEpoch 44 [0/1692 (0.00%)]\t\tLoss: 0.88210\n",
            "Training Progress: \tEpoch 44 [320/1692 (18.87%)]\t\tLoss: 1.20972\n",
            "Training Progress: \tEpoch 44 [640/1692 (37.74%)]\t\tLoss: 0.81550\n",
            "Training Progress: \tEpoch 44 [960/1692 (56.60%)]\t\tLoss: 1.02954\n",
            "Training Progress: \tEpoch 44 [1280/1692 (75.47%)]\t\tLoss: 1.10389\n",
            "Training Progress: \tEpoch 44 [1600/1692 (94.34%)]\t\tLoss: 0.94992\n",
            "\tTrain loss: 0.02310, Accuracy: 1186/1692 (70.09%)\n",
            "\tValidation loss: 0.00292, Accuracy: 183/423 (43.26%)\n",
            "\tTest loss: 0.00273, Accuracy: 213/443 (48.08%)\n",
            "\n",
            "Training Progress: \tEpoch 45 [0/1692 (0.00%)]\t\tLoss: 0.87933\n",
            "Training Progress: \tEpoch 45 [320/1692 (18.87%)]\t\tLoss: 0.96023\n",
            "Training Progress: \tEpoch 45 [640/1692 (37.74%)]\t\tLoss: 0.66236\n",
            "Training Progress: \tEpoch 45 [960/1692 (56.60%)]\t\tLoss: 0.88195\n",
            "Training Progress: \tEpoch 45 [1280/1692 (75.47%)]\t\tLoss: 1.03600\n",
            "Training Progress: \tEpoch 45 [1600/1692 (94.34%)]\t\tLoss: 0.79384\n",
            "\tTrain loss: 0.02432, Accuracy: 1134/1692 (67.02%)\n",
            "\tValidation loss: 0.00324, Accuracy: 178/423 (42.08%)\n",
            "\tTest loss: 0.00298, Accuracy: 211/443 (47.63%)\n",
            "\n",
            "Training Progress: \tEpoch 46 [0/1692 (0.00%)]\t\tLoss: 0.94108\n",
            "Training Progress: \tEpoch 46 [320/1692 (18.87%)]\t\tLoss: 0.99798\n",
            "Training Progress: \tEpoch 46 [640/1692 (37.74%)]\t\tLoss: 0.77520\n",
            "Training Progress: \tEpoch 46 [960/1692 (56.60%)]\t\tLoss: 0.98942\n",
            "Training Progress: \tEpoch 46 [1280/1692 (75.47%)]\t\tLoss: 0.89865\n",
            "Training Progress: \tEpoch 46 [1600/1692 (94.34%)]\t\tLoss: 1.07167\n",
            "\tTrain loss: 0.02147, Accuracy: 1226/1692 (72.46%)\n",
            "\tValidation loss: 0.00283, Accuracy: 187/423 (44.21%)\n",
            "\tTest loss: 0.00263, Accuracy: 235/443 (53.05%)\n",
            "\n",
            "Training Progress: \tEpoch 47 [0/1692 (0.00%)]\t\tLoss: 0.75761\n",
            "Training Progress: \tEpoch 47 [320/1692 (18.87%)]\t\tLoss: 1.23016\n",
            "Training Progress: \tEpoch 47 [640/1692 (37.74%)]\t\tLoss: 0.69379\n",
            "Training Progress: \tEpoch 47 [960/1692 (56.60%)]\t\tLoss: 0.93517\n",
            "Training Progress: \tEpoch 47 [1280/1692 (75.47%)]\t\tLoss: 0.64264\n",
            "Training Progress: \tEpoch 47 [1600/1692 (94.34%)]\t\tLoss: 1.03075\n",
            "\tTrain loss: 0.02281, Accuracy: 1168/1692 (69.03%)\n",
            "\tValidation loss: 0.00304, Accuracy: 184/423 (43.50%)\n",
            "\tTest loss: 0.00290, Accuracy: 205/443 (46.28%)\n",
            "\n",
            "Training Progress: \tEpoch 48 [0/1692 (0.00%)]\t\tLoss: 0.80497\n",
            "Training Progress: \tEpoch 48 [320/1692 (18.87%)]\t\tLoss: 0.91095\n",
            "Training Progress: \tEpoch 48 [640/1692 (37.74%)]\t\tLoss: 0.76349\n",
            "Training Progress: \tEpoch 48 [960/1692 (56.60%)]\t\tLoss: 0.80677\n",
            "Training Progress: \tEpoch 48 [1280/1692 (75.47%)]\t\tLoss: 0.84143\n",
            "Training Progress: \tEpoch 48 [1600/1692 (94.34%)]\t\tLoss: 1.06722\n",
            "\tTrain loss: 0.02213, Accuracy: 1188/1692 (70.21%)\n",
            "\tValidation loss: 0.00313, Accuracy: 172/423 (40.66%)\n",
            "\tTest loss: 0.00292, Accuracy: 201/443 (45.37%)\n",
            "\n",
            "Training Progress: \tEpoch 49 [0/1692 (0.00%)]\t\tLoss: 0.76691\n",
            "Training Progress: \tEpoch 49 [320/1692 (18.87%)]\t\tLoss: 1.25256\n",
            "Training Progress: \tEpoch 49 [640/1692 (37.74%)]\t\tLoss: 0.77028\n",
            "Training Progress: \tEpoch 49 [960/1692 (56.60%)]\t\tLoss: 0.94333\n",
            "Training Progress: \tEpoch 49 [1280/1692 (75.47%)]\t\tLoss: 0.77645\n",
            "Training Progress: \tEpoch 49 [1600/1692 (94.34%)]\t\tLoss: 1.06180\n",
            "\tTrain loss: 0.02129, Accuracy: 1208/1692 (71.39%)\n",
            "\tValidation loss: 0.00315, Accuracy: 178/423 (42.08%)\n",
            "\tTest loss: 0.00290, Accuracy: 219/443 (49.44%)\n",
            "\n",
            "Training Progress: \tEpoch 50 [0/1692 (0.00%)]\t\tLoss: 0.64581\n",
            "Training Progress: \tEpoch 50 [320/1692 (18.87%)]\t\tLoss: 1.02144\n",
            "Training Progress: \tEpoch 50 [640/1692 (37.74%)]\t\tLoss: 0.64777\n",
            "Training Progress: \tEpoch 50 [960/1692 (56.60%)]\t\tLoss: 0.77128\n",
            "Training Progress: \tEpoch 50 [1280/1692 (75.47%)]\t\tLoss: 0.86842\n",
            "Training Progress: \tEpoch 50 [1600/1692 (94.34%)]\t\tLoss: 1.10256\n",
            "\tTrain loss: 0.02029, Accuracy: 1230/1692 (72.70%)\n",
            "\tValidation loss: 0.00325, Accuracy: 191/423 (45.15%)\n",
            "\tTest loss: 0.00303, Accuracy: 212/443 (47.86%)\n",
            "\n",
            "Training Progress: \tEpoch 51 [0/1692 (0.00%)]\t\tLoss: 0.62965\n",
            "Training Progress: \tEpoch 51 [320/1692 (18.87%)]\t\tLoss: 1.01572\n",
            "Training Progress: \tEpoch 51 [640/1692 (37.74%)]\t\tLoss: 0.80364\n",
            "Training Progress: \tEpoch 51 [960/1692 (56.60%)]\t\tLoss: 0.93087\n",
            "Training Progress: \tEpoch 51 [1280/1692 (75.47%)]\t\tLoss: 0.97044\n",
            "Training Progress: \tEpoch 51 [1600/1692 (94.34%)]\t\tLoss: 0.82796\n",
            "\tTrain loss: 0.01928, Accuracy: 1275/1692 (75.35%)\n",
            "\tValidation loss: 0.00296, Accuracy: 186/423 (43.97%)\n",
            "\tTest loss: 0.00278, Accuracy: 222/443 (50.11%)\n",
            "\n",
            "Training Progress: \tEpoch 52 [0/1692 (0.00%)]\t\tLoss: 0.70470\n",
            "Training Progress: \tEpoch 52 [320/1692 (18.87%)]\t\tLoss: 0.82674\n",
            "Training Progress: \tEpoch 52 [640/1692 (37.74%)]\t\tLoss: 0.64824\n",
            "Training Progress: \tEpoch 52 [960/1692 (56.60%)]\t\tLoss: 0.95568\n",
            "Training Progress: \tEpoch 52 [1280/1692 (75.47%)]\t\tLoss: 0.92731\n",
            "Training Progress: \tEpoch 52 [1600/1692 (94.34%)]\t\tLoss: 1.01748\n",
            "\tTrain loss: 0.02067, Accuracy: 1235/1692 (72.99%)\n",
            "\tValidation loss: 0.00295, Accuracy: 184/423 (43.50%)\n",
            "\tTest loss: 0.00279, Accuracy: 214/443 (48.31%)\n",
            "\n",
            "Training Progress: \tEpoch 53 [0/1692 (0.00%)]\t\tLoss: 0.99000\n",
            "Training Progress: \tEpoch 53 [320/1692 (18.87%)]\t\tLoss: 0.89780\n",
            "Training Progress: \tEpoch 53 [640/1692 (37.74%)]\t\tLoss: 0.84636\n",
            "Training Progress: \tEpoch 53 [960/1692 (56.60%)]\t\tLoss: 0.85697\n",
            "Training Progress: \tEpoch 53 [1280/1692 (75.47%)]\t\tLoss: 0.67861\n",
            "Training Progress: \tEpoch 53 [1600/1692 (94.34%)]\t\tLoss: 0.99998\n",
            "\tTrain loss: 0.01881, Accuracy: 1277/1692 (75.47%)\n",
            "\tValidation loss: 0.00308, Accuracy: 191/423 (45.15%)\n",
            "\tTest loss: 0.00283, Accuracy: 227/443 (51.24%)\n",
            "\n",
            "Training Progress: \tEpoch 54 [0/1692 (0.00%)]\t\tLoss: 0.60081\n",
            "Training Progress: \tEpoch 54 [320/1692 (18.87%)]\t\tLoss: 1.13898\n",
            "Training Progress: \tEpoch 54 [640/1692 (37.74%)]\t\tLoss: 0.62326\n",
            "Training Progress: \tEpoch 54 [960/1692 (56.60%)]\t\tLoss: 0.72125\n",
            "Training Progress: \tEpoch 54 [1280/1692 (75.47%)]\t\tLoss: 0.56075\n",
            "Training Progress: \tEpoch 54 [1600/1692 (94.34%)]\t\tLoss: 0.66295\n",
            "\tTrain loss: 0.02037, Accuracy: 1244/1692 (73.52%)\n",
            "\tValidation loss: 0.00326, Accuracy: 180/423 (42.55%)\n",
            "\tTest loss: 0.00307, Accuracy: 215/443 (48.53%)\n",
            "\n",
            "Training Progress: \tEpoch 55 [0/1692 (0.00%)]\t\tLoss: 0.91605\n",
            "Training Progress: \tEpoch 55 [320/1692 (18.87%)]\t\tLoss: 1.12787\n",
            "Training Progress: \tEpoch 55 [640/1692 (37.74%)]\t\tLoss: 0.75990\n",
            "Training Progress: \tEpoch 55 [960/1692 (56.60%)]\t\tLoss: 0.84688\n",
            "Training Progress: \tEpoch 55 [1280/1692 (75.47%)]\t\tLoss: 0.94086\n",
            "Training Progress: \tEpoch 55 [1600/1692 (94.34%)]\t\tLoss: 0.76785\n",
            "\tTrain loss: 0.01905, Accuracy: 1279/1692 (75.59%)\n",
            "\tValidation loss: 0.00304, Accuracy: 186/423 (43.97%)\n",
            "\tTest loss: 0.00288, Accuracy: 218/443 (49.21%)\n",
            "\n",
            "Training Progress: \tEpoch 56 [0/1692 (0.00%)]\t\tLoss: 0.76716\n",
            "Training Progress: \tEpoch 56 [320/1692 (18.87%)]\t\tLoss: 1.12971\n",
            "Training Progress: \tEpoch 56 [640/1692 (37.74%)]\t\tLoss: 0.59652\n",
            "Training Progress: \tEpoch 56 [960/1692 (56.60%)]\t\tLoss: 0.81371\n",
            "Training Progress: \tEpoch 56 [1280/1692 (75.47%)]\t\tLoss: 0.75514\n",
            "Training Progress: \tEpoch 56 [1600/1692 (94.34%)]\t\tLoss: 1.07333\n",
            "\tTrain loss: 0.01972, Accuracy: 1249/1692 (73.82%)\n",
            "\tValidation loss: 0.00311, Accuracy: 182/423 (43.03%)\n",
            "\tTest loss: 0.00278, Accuracy: 231/443 (52.14%)\n",
            "\n",
            "Training Progress: \tEpoch 57 [0/1692 (0.00%)]\t\tLoss: 0.96799\n",
            "Training Progress: \tEpoch 57 [320/1692 (18.87%)]\t\tLoss: 0.89923\n",
            "Training Progress: \tEpoch 57 [640/1692 (37.74%)]\t\tLoss: 0.69895\n",
            "Training Progress: \tEpoch 57 [960/1692 (56.60%)]\t\tLoss: 0.71800\n",
            "Training Progress: \tEpoch 57 [1280/1692 (75.47%)]\t\tLoss: 0.88841\n",
            "Training Progress: \tEpoch 57 [1600/1692 (94.34%)]\t\tLoss: 0.87058\n",
            "\tTrain loss: 0.01945, Accuracy: 1268/1692 (74.94%)\n",
            "\tValidation loss: 0.00319, Accuracy: 185/423 (43.74%)\n",
            "\tTest loss: 0.00288, Accuracy: 223/443 (50.34%)\n",
            "\n",
            "Training Progress: \tEpoch 58 [0/1692 (0.00%)]\t\tLoss: 0.74185\n",
            "Training Progress: \tEpoch 58 [320/1692 (18.87%)]\t\tLoss: 0.79113\n",
            "Training Progress: \tEpoch 58 [640/1692 (37.74%)]\t\tLoss: 0.64789\n",
            "Training Progress: \tEpoch 58 [960/1692 (56.60%)]\t\tLoss: 0.67100\n",
            "Training Progress: \tEpoch 58 [1280/1692 (75.47%)]\t\tLoss: 0.85870\n",
            "Training Progress: \tEpoch 58 [1600/1692 (94.34%)]\t\tLoss: 0.99816\n",
            "\tTrain loss: 0.01757, Accuracy: 1317/1692 (77.84%)\n",
            "\tValidation loss: 0.00320, Accuracy: 192/423 (45.39%)\n",
            "\tTest loss: 0.00296, Accuracy: 225/443 (50.79%)\n",
            "\n",
            "Training Progress: \tEpoch 59 [0/1692 (0.00%)]\t\tLoss: 0.85002\n",
            "Training Progress: \tEpoch 59 [320/1692 (18.87%)]\t\tLoss: 0.75233\n",
            "Training Progress: \tEpoch 59 [640/1692 (37.74%)]\t\tLoss: 0.37998\n",
            "Training Progress: \tEpoch 59 [960/1692 (56.60%)]\t\tLoss: 0.80898\n",
            "Training Progress: \tEpoch 59 [1280/1692 (75.47%)]\t\tLoss: 0.65505\n",
            "Training Progress: \tEpoch 59 [1600/1692 (94.34%)]\t\tLoss: 0.98406\n",
            "\tTrain loss: 0.01707, Accuracy: 1328/1692 (78.49%)\n",
            "\tValidation loss: 0.00333, Accuracy: 180/423 (42.55%)\n",
            "\tTest loss: 0.00293, Accuracy: 220/443 (49.66%)\n",
            "\n",
            "Training Progress: \tEpoch 60 [0/1692 (0.00%)]\t\tLoss: 0.83496\n",
            "Training Progress: \tEpoch 60 [320/1692 (18.87%)]\t\tLoss: 1.01684\n",
            "Training Progress: \tEpoch 60 [640/1692 (37.74%)]\t\tLoss: 0.79271\n",
            "Training Progress: \tEpoch 60 [960/1692 (56.60%)]\t\tLoss: 0.65358\n",
            "Training Progress: \tEpoch 60 [1280/1692 (75.47%)]\t\tLoss: 0.89306\n",
            "Training Progress: \tEpoch 60 [1600/1692 (94.34%)]\t\tLoss: 0.72828\n",
            "\tTrain loss: 0.01706, Accuracy: 1326/1692 (78.37%)\n",
            "\tValidation loss: 0.00316, Accuracy: 185/423 (43.74%)\n",
            "\tTest loss: 0.00291, Accuracy: 217/443 (48.98%)\n",
            "\n",
            "Training Progress: \tEpoch 61 [0/1692 (0.00%)]\t\tLoss: 0.83661\n",
            "Training Progress: \tEpoch 61 [320/1692 (18.87%)]\t\tLoss: 0.81761\n",
            "Training Progress: \tEpoch 61 [640/1692 (37.74%)]\t\tLoss: 0.56581\n",
            "Training Progress: \tEpoch 61 [960/1692 (56.60%)]\t\tLoss: 0.80704\n",
            "Training Progress: \tEpoch 61 [1280/1692 (75.47%)]\t\tLoss: 0.75904\n",
            "Training Progress: \tEpoch 61 [1600/1692 (94.34%)]\t\tLoss: 0.75438\n",
            "\tTrain loss: 0.01803, Accuracy: 1310/1692 (77.42%)\n",
            "\tValidation loss: 0.00328, Accuracy: 183/423 (43.26%)\n",
            "\tTest loss: 0.00306, Accuracy: 206/443 (46.50%)\n",
            "\n",
            "Training Progress: \tEpoch 62 [0/1692 (0.00%)]\t\tLoss: 0.71135\n",
            "Training Progress: \tEpoch 62 [320/1692 (18.87%)]\t\tLoss: 0.92353\n",
            "Training Progress: \tEpoch 62 [640/1692 (37.74%)]\t\tLoss: 0.52613\n",
            "Training Progress: \tEpoch 62 [960/1692 (56.60%)]\t\tLoss: 0.72815\n",
            "Training Progress: \tEpoch 62 [1280/1692 (75.47%)]\t\tLoss: 0.69643\n",
            "Training Progress: \tEpoch 62 [1600/1692 (94.34%)]\t\tLoss: 0.72240\n",
            "\tTrain loss: 0.01791, Accuracy: 1297/1692 (76.65%)\n",
            "\tValidation loss: 0.00313, Accuracy: 190/423 (44.92%)\n",
            "\tTest loss: 0.00291, Accuracy: 222/443 (50.11%)\n",
            "\n",
            "Training Progress: \tEpoch 63 [0/1692 (0.00%)]\t\tLoss: 0.60653\n",
            "Training Progress: \tEpoch 63 [320/1692 (18.87%)]\t\tLoss: 1.14822\n",
            "Training Progress: \tEpoch 63 [640/1692 (37.74%)]\t\tLoss: 0.67817\n",
            "Training Progress: \tEpoch 63 [960/1692 (56.60%)]\t\tLoss: 0.71859\n",
            "Training Progress: \tEpoch 63 [1280/1692 (75.47%)]\t\tLoss: 0.53761\n",
            "Training Progress: \tEpoch 63 [1600/1692 (94.34%)]\t\tLoss: 0.74324\n",
            "\tTrain loss: 0.01591, Accuracy: 1364/1692 (80.61%)\n",
            "\tValidation loss: 0.00315, Accuracy: 189/423 (44.68%)\n",
            "\tTest loss: 0.00297, Accuracy: 215/443 (48.53%)\n",
            "\n",
            "Training Progress: \tEpoch 64 [0/1692 (0.00%)]\t\tLoss: 0.65707\n",
            "Training Progress: \tEpoch 64 [320/1692 (18.87%)]\t\tLoss: 0.67664\n",
            "Training Progress: \tEpoch 64 [640/1692 (37.74%)]\t\tLoss: 0.65771\n",
            "Training Progress: \tEpoch 64 [960/1692 (56.60%)]\t\tLoss: 0.65382\n",
            "Training Progress: \tEpoch 64 [1280/1692 (75.47%)]\t\tLoss: 0.76393\n",
            "Training Progress: \tEpoch 64 [1600/1692 (94.34%)]\t\tLoss: 0.66786\n",
            "\tTrain loss: 0.01472, Accuracy: 1399/1692 (82.68%)\n",
            "\tValidation loss: 0.00312, Accuracy: 185/423 (43.74%)\n",
            "\tTest loss: 0.00286, Accuracy: 227/443 (51.24%)\n",
            "\n",
            "Training Progress: \tEpoch 65 [0/1692 (0.00%)]\t\tLoss: 0.84740\n",
            "Training Progress: \tEpoch 65 [320/1692 (18.87%)]\t\tLoss: 0.87687\n",
            "Training Progress: \tEpoch 65 [640/1692 (37.74%)]\t\tLoss: 0.49254\n",
            "Training Progress: \tEpoch 65 [960/1692 (56.60%)]\t\tLoss: 0.68082\n",
            "Training Progress: \tEpoch 65 [1280/1692 (75.47%)]\t\tLoss: 0.64933\n",
            "Training Progress: \tEpoch 65 [1600/1692 (94.34%)]\t\tLoss: 0.79259\n",
            "\tTrain loss: 0.01677, Accuracy: 1326/1692 (78.37%)\n",
            "\tValidation loss: 0.00357, Accuracy: 187/423 (44.21%)\n",
            "\tTest loss: 0.00332, Accuracy: 211/443 (47.63%)\n",
            "\n",
            "Training Progress: \tEpoch 66 [0/1692 (0.00%)]\t\tLoss: 0.64710\n",
            "Training Progress: \tEpoch 66 [320/1692 (18.87%)]\t\tLoss: 1.06043\n",
            "Training Progress: \tEpoch 66 [640/1692 (37.74%)]\t\tLoss: 0.59145\n",
            "Training Progress: \tEpoch 66 [960/1692 (56.60%)]\t\tLoss: 0.84784\n",
            "Training Progress: \tEpoch 66 [1280/1692 (75.47%)]\t\tLoss: 0.59158\n",
            "Training Progress: \tEpoch 66 [1600/1692 (94.34%)]\t\tLoss: 0.79328\n",
            "\tTrain loss: 0.01415, Accuracy: 1413/1692 (83.51%)\n",
            "\tValidation loss: 0.00324, Accuracy: 184/423 (43.50%)\n",
            "\tTest loss: 0.00300, Accuracy: 217/443 (48.98%)\n",
            "\n",
            "Training Progress: \tEpoch 67 [0/1692 (0.00%)]\t\tLoss: 0.70335\n",
            "Training Progress: \tEpoch 67 [320/1692 (18.87%)]\t\tLoss: 0.81996\n",
            "Training Progress: \tEpoch 67 [640/1692 (37.74%)]\t\tLoss: 0.55104\n",
            "Training Progress: \tEpoch 67 [960/1692 (56.60%)]\t\tLoss: 0.68852\n",
            "Training Progress: \tEpoch 67 [1280/1692 (75.47%)]\t\tLoss: 0.73373\n",
            "Training Progress: \tEpoch 67 [1600/1692 (94.34%)]\t\tLoss: 0.62535\n",
            "\tTrain loss: 0.01426, Accuracy: 1391/1692 (82.21%)\n",
            "\tValidation loss: 0.00326, Accuracy: 198/423 (46.81%)\n",
            "\tTest loss: 0.00305, Accuracy: 224/443 (50.56%)\n",
            "\n",
            "Training Progress: \tEpoch 68 [0/1692 (0.00%)]\t\tLoss: 0.72737\n",
            "Training Progress: \tEpoch 68 [320/1692 (18.87%)]\t\tLoss: 1.01174\n",
            "Training Progress: \tEpoch 68 [640/1692 (37.74%)]\t\tLoss: 0.72935\n",
            "Training Progress: \tEpoch 68 [960/1692 (56.60%)]\t\tLoss: 0.69567\n",
            "Training Progress: \tEpoch 68 [1280/1692 (75.47%)]\t\tLoss: 0.64844\n",
            "Training Progress: \tEpoch 68 [1600/1692 (94.34%)]\t\tLoss: 0.56463\n",
            "\tTrain loss: 0.01505, Accuracy: 1389/1692 (82.09%)\n",
            "\tValidation loss: 0.00326, Accuracy: 191/423 (45.15%)\n",
            "\tTest loss: 0.00296, Accuracy: 219/443 (49.44%)\n",
            "\n",
            "Training Progress: \tEpoch 69 [0/1692 (0.00%)]\t\tLoss: 0.58602\n",
            "Training Progress: \tEpoch 69 [320/1692 (18.87%)]\t\tLoss: 1.09912\n",
            "Training Progress: \tEpoch 69 [640/1692 (37.74%)]\t\tLoss: 0.38875\n",
            "Training Progress: \tEpoch 69 [960/1692 (56.60%)]\t\tLoss: 0.91085\n",
            "Training Progress: \tEpoch 69 [1280/1692 (75.47%)]\t\tLoss: 0.69150\n",
            "Training Progress: \tEpoch 69 [1600/1692 (94.34%)]\t\tLoss: 0.62018\n",
            "\tTrain loss: 0.01456, Accuracy: 1398/1692 (82.62%)\n",
            "\tValidation loss: 0.00321, Accuracy: 192/423 (45.39%)\n",
            "\tTest loss: 0.00300, Accuracy: 222/443 (50.11%)\n",
            "\n",
            "Training Progress: \tEpoch 70 [0/1692 (0.00%)]\t\tLoss: 0.75176\n",
            "Training Progress: \tEpoch 70 [320/1692 (18.87%)]\t\tLoss: 0.97031\n",
            "Training Progress: \tEpoch 70 [640/1692 (37.74%)]\t\tLoss: 0.65471\n",
            "Training Progress: \tEpoch 70 [960/1692 (56.60%)]\t\tLoss: 0.76615\n",
            "Training Progress: \tEpoch 70 [1280/1692 (75.47%)]\t\tLoss: 0.83044\n",
            "Training Progress: \tEpoch 70 [1600/1692 (94.34%)]\t\tLoss: 0.72916\n",
            "\tTrain loss: 0.01248, Accuracy: 1469/1692 (86.82%)\n",
            "\tValidation loss: 0.00306, Accuracy: 191/423 (45.15%)\n",
            "\tTest loss: 0.00283, Accuracy: 231/443 (52.14%)\n",
            "\n",
            "Training Progress: \tEpoch 71 [0/1692 (0.00%)]\t\tLoss: 1.09000\n",
            "Training Progress: \tEpoch 71 [320/1692 (18.87%)]\t\tLoss: 0.86922\n",
            "Training Progress: \tEpoch 71 [640/1692 (37.74%)]\t\tLoss: 0.81233\n",
            "Training Progress: \tEpoch 71 [960/1692 (56.60%)]\t\tLoss: 0.64571\n",
            "Training Progress: \tEpoch 71 [1280/1692 (75.47%)]\t\tLoss: 0.56290\n",
            "Training Progress: \tEpoch 71 [1600/1692 (94.34%)]\t\tLoss: 0.63728\n",
            "\tTrain loss: 0.01356, Accuracy: 1411/1692 (83.39%)\n",
            "\tValidation loss: 0.00327, Accuracy: 204/423 (48.23%)\n",
            "\tTest loss: 0.00313, Accuracy: 221/443 (49.89%)\n",
            "\n",
            "Training Progress: \tEpoch 72 [0/1692 (0.00%)]\t\tLoss: 0.64593\n",
            "Training Progress: \tEpoch 72 [320/1692 (18.87%)]\t\tLoss: 1.04868\n",
            "Training Progress: \tEpoch 72 [640/1692 (37.74%)]\t\tLoss: 0.49221\n",
            "Training Progress: \tEpoch 72 [960/1692 (56.60%)]\t\tLoss: 0.60438\n",
            "Training Progress: \tEpoch 72 [1280/1692 (75.47%)]\t\tLoss: 0.57478\n",
            "Training Progress: \tEpoch 72 [1600/1692 (94.34%)]\t\tLoss: 0.77432\n",
            "\tTrain loss: 0.01418, Accuracy: 1404/1692 (82.98%)\n",
            "\tValidation loss: 0.00324, Accuracy: 192/423 (45.39%)\n",
            "\tTest loss: 0.00295, Accuracy: 221/443 (49.89%)\n",
            "\n",
            "Training Progress: \tEpoch 73 [0/1692 (0.00%)]\t\tLoss: 0.41434\n",
            "Training Progress: \tEpoch 73 [320/1692 (18.87%)]\t\tLoss: 0.73879\n",
            "Training Progress: \tEpoch 73 [640/1692 (37.74%)]\t\tLoss: 0.55920\n",
            "Training Progress: \tEpoch 73 [960/1692 (56.60%)]\t\tLoss: 0.61369\n",
            "Training Progress: \tEpoch 73 [1280/1692 (75.47%)]\t\tLoss: 0.92970\n",
            "Training Progress: \tEpoch 73 [1600/1692 (94.34%)]\t\tLoss: 0.60410\n",
            "\tTrain loss: 0.01325, Accuracy: 1417/1692 (83.75%)\n",
            "\tValidation loss: 0.00320, Accuracy: 200/423 (47.28%)\n",
            "\tTest loss: 0.00292, Accuracy: 228/443 (51.47%)\n",
            "\n",
            "Training Progress: \tEpoch 74 [0/1692 (0.00%)]\t\tLoss: 0.65806\n",
            "Training Progress: \tEpoch 74 [320/1692 (18.87%)]\t\tLoss: 0.89654\n",
            "Training Progress: \tEpoch 74 [640/1692 (37.74%)]\t\tLoss: 0.48859\n",
            "Training Progress: \tEpoch 74 [960/1692 (56.60%)]\t\tLoss: 0.72184\n",
            "Training Progress: \tEpoch 74 [1280/1692 (75.47%)]\t\tLoss: 0.75082\n",
            "Training Progress: \tEpoch 74 [1600/1692 (94.34%)]\t\tLoss: 0.58960\n",
            "\tTrain loss: 0.01233, Accuracy: 1463/1692 (86.47%)\n",
            "\tValidation loss: 0.00324, Accuracy: 193/423 (45.63%)\n",
            "\tTest loss: 0.00293, Accuracy: 232/443 (52.37%)\n",
            "\n",
            "Training Progress: \tEpoch 75 [0/1692 (0.00%)]\t\tLoss: 0.65483\n",
            "Training Progress: \tEpoch 75 [320/1692 (18.87%)]\t\tLoss: 0.58239\n",
            "Training Progress: \tEpoch 75 [640/1692 (37.74%)]\t\tLoss: 0.49805\n",
            "Training Progress: \tEpoch 75 [960/1692 (56.60%)]\t\tLoss: 0.69168\n",
            "Training Progress: \tEpoch 75 [1280/1692 (75.47%)]\t\tLoss: 0.64298\n",
            "Training Progress: \tEpoch 75 [1600/1692 (94.34%)]\t\tLoss: 0.66309\n",
            "\tTrain loss: 0.01329, Accuracy: 1437/1692 (84.93%)\n",
            "\tValidation loss: 0.00328, Accuracy: 188/423 (44.44%)\n",
            "\tTest loss: 0.00306, Accuracy: 218/443 (49.21%)\n",
            "\n",
            "Training Progress: \tEpoch 76 [0/1692 (0.00%)]\t\tLoss: 0.83456\n",
            "Training Progress: \tEpoch 76 [320/1692 (18.87%)]\t\tLoss: 0.86921\n",
            "Training Progress: \tEpoch 76 [640/1692 (37.74%)]\t\tLoss: 0.66876\n",
            "Training Progress: \tEpoch 76 [960/1692 (56.60%)]\t\tLoss: 0.58010\n",
            "Training Progress: \tEpoch 76 [1280/1692 (75.47%)]\t\tLoss: 0.94125\n",
            "Training Progress: \tEpoch 76 [1600/1692 (94.34%)]\t\tLoss: 0.60228\n",
            "\tTrain loss: 0.01209, Accuracy: 1480/1692 (87.47%)\n",
            "\tValidation loss: 0.00311, Accuracy: 195/423 (46.10%)\n",
            "\tTest loss: 0.00288, Accuracy: 226/443 (51.02%)\n",
            "\n",
            "Training Progress: \tEpoch 77 [0/1692 (0.00%)]\t\tLoss: 0.57125\n",
            "Training Progress: \tEpoch 77 [320/1692 (18.87%)]\t\tLoss: 0.89889\n",
            "Training Progress: \tEpoch 77 [640/1692 (37.74%)]\t\tLoss: 0.45493\n",
            "Training Progress: \tEpoch 77 [960/1692 (56.60%)]\t\tLoss: 0.50107\n",
            "Training Progress: \tEpoch 77 [1280/1692 (75.47%)]\t\tLoss: 0.54735\n",
            "Training Progress: \tEpoch 77 [1600/1692 (94.34%)]\t\tLoss: 0.46705\n",
            "\tTrain loss: 0.01319, Accuracy: 1426/1692 (84.28%)\n",
            "\tValidation loss: 0.00359, Accuracy: 183/423 (43.26%)\n",
            "\tTest loss: 0.00327, Accuracy: 217/443 (48.98%)\n",
            "\n",
            "Training Progress: \tEpoch 78 [0/1692 (0.00%)]\t\tLoss: 0.63450\n",
            "Training Progress: \tEpoch 78 [320/1692 (18.87%)]\t\tLoss: 0.83792\n",
            "Training Progress: \tEpoch 78 [640/1692 (37.74%)]\t\tLoss: 0.56933\n",
            "Training Progress: \tEpoch 78 [960/1692 (56.60%)]\t\tLoss: 0.69921\n",
            "Training Progress: \tEpoch 78 [1280/1692 (75.47%)]\t\tLoss: 0.63113\n",
            "Training Progress: \tEpoch 78 [1600/1692 (94.34%)]\t\tLoss: 0.49098\n",
            "\tTrain loss: 0.01130, Accuracy: 1484/1692 (87.71%)\n",
            "\tValidation loss: 0.00318, Accuracy: 196/423 (46.34%)\n",
            "\tTest loss: 0.00285, Accuracy: 237/443 (53.50%)\n",
            "\n",
            "Training Progress: \tEpoch 79 [0/1692 (0.00%)]\t\tLoss: 0.49795\n",
            "Training Progress: \tEpoch 79 [320/1692 (18.87%)]\t\tLoss: 0.87756\n",
            "Training Progress: \tEpoch 79 [640/1692 (37.74%)]\t\tLoss: 0.51365\n",
            "Training Progress: \tEpoch 79 [960/1692 (56.60%)]\t\tLoss: 0.57618\n",
            "Training Progress: \tEpoch 79 [1280/1692 (75.47%)]\t\tLoss: 0.44506\n",
            "Training Progress: \tEpoch 79 [1600/1692 (94.34%)]\t\tLoss: 0.60790\n",
            "\tTrain loss: 0.01105, Accuracy: 1474/1692 (87.12%)\n",
            "\tValidation loss: 0.00343, Accuracy: 198/423 (46.81%)\n",
            "\tTest loss: 0.00313, Accuracy: 224/443 (50.56%)\n",
            "\n",
            "Training Progress: \tEpoch 80 [0/1692 (0.00%)]\t\tLoss: 0.47569\n",
            "Training Progress: \tEpoch 80 [320/1692 (18.87%)]\t\tLoss: 0.81773\n",
            "Training Progress: \tEpoch 80 [640/1692 (37.74%)]\t\tLoss: 0.48496\n",
            "Training Progress: \tEpoch 80 [960/1692 (56.60%)]\t\tLoss: 0.51555\n",
            "Training Progress: \tEpoch 80 [1280/1692 (75.47%)]\t\tLoss: 0.59077\n",
            "Training Progress: \tEpoch 80 [1600/1692 (94.34%)]\t\tLoss: 0.70184\n",
            "\tTrain loss: 0.01012, Accuracy: 1504/1692 (88.89%)\n",
            "\tValidation loss: 0.00362, Accuracy: 203/423 (47.99%)\n",
            "\tTest loss: 0.00336, Accuracy: 222/443 (50.11%)\n",
            "\n",
            "Training Progress: \tEpoch 81 [0/1692 (0.00%)]\t\tLoss: 0.61318\n",
            "Training Progress: \tEpoch 81 [320/1692 (18.87%)]\t\tLoss: 0.63191\n",
            "Training Progress: \tEpoch 81 [640/1692 (37.74%)]\t\tLoss: 0.48478\n",
            "Training Progress: \tEpoch 81 [960/1692 (56.60%)]\t\tLoss: 0.55048\n",
            "Training Progress: \tEpoch 81 [1280/1692 (75.47%)]\t\tLoss: 0.43243\n",
            "Training Progress: \tEpoch 81 [1600/1692 (94.34%)]\t\tLoss: 0.47640\n",
            "\tTrain loss: 0.01190, Accuracy: 1460/1692 (86.29%)\n",
            "\tValidation loss: 0.00348, Accuracy: 181/423 (42.79%)\n",
            "\tTest loss: 0.00316, Accuracy: 221/443 (49.89%)\n",
            "\n",
            "Training Progress: \tEpoch 82 [0/1692 (0.00%)]\t\tLoss: 0.37384\n",
            "Training Progress: \tEpoch 82 [320/1692 (18.87%)]\t\tLoss: 0.89357\n",
            "Training Progress: \tEpoch 82 [640/1692 (37.74%)]\t\tLoss: 0.33708\n",
            "Training Progress: \tEpoch 82 [960/1692 (56.60%)]\t\tLoss: 0.57774\n",
            "Training Progress: \tEpoch 82 [1280/1692 (75.47%)]\t\tLoss: 0.81156\n",
            "Training Progress: \tEpoch 82 [1600/1692 (94.34%)]\t\tLoss: 0.56465\n",
            "\tTrain loss: 0.00935, Accuracy: 1530/1692 (90.43%)\n",
            "\tValidation loss: 0.00342, Accuracy: 191/423 (45.15%)\n",
            "\tTest loss: 0.00313, Accuracy: 224/443 (50.56%)\n",
            "\n",
            "Training Progress: \tEpoch 83 [0/1692 (0.00%)]\t\tLoss: 0.64939\n",
            "Training Progress: \tEpoch 83 [320/1692 (18.87%)]\t\tLoss: 0.66000\n",
            "Training Progress: \tEpoch 83 [640/1692 (37.74%)]\t\tLoss: 0.37525\n",
            "Training Progress: \tEpoch 83 [960/1692 (56.60%)]\t\tLoss: 0.59663\n",
            "Training Progress: \tEpoch 83 [1280/1692 (75.47%)]\t\tLoss: 0.63167\n",
            "Training Progress: \tEpoch 83 [1600/1692 (94.34%)]\t\tLoss: 0.40336\n",
            "\tTrain loss: 0.01019, Accuracy: 1523/1692 (90.01%)\n",
            "\tValidation loss: 0.00330, Accuracy: 185/423 (43.74%)\n",
            "\tTest loss: 0.00299, Accuracy: 221/443 (49.89%)\n",
            "\n",
            "Training Progress: \tEpoch 84 [0/1692 (0.00%)]\t\tLoss: 0.48969\n",
            "Training Progress: \tEpoch 84 [320/1692 (18.87%)]\t\tLoss: 0.81718\n",
            "Training Progress: \tEpoch 84 [640/1692 (37.74%)]\t\tLoss: 0.47666\n",
            "Training Progress: \tEpoch 84 [960/1692 (56.60%)]\t\tLoss: 0.49196\n",
            "Training Progress: \tEpoch 84 [1280/1692 (75.47%)]\t\tLoss: 0.66293\n",
            "Training Progress: \tEpoch 84 [1600/1692 (94.34%)]\t\tLoss: 0.63973\n",
            "\tTrain loss: 0.01221, Accuracy: 1451/1692 (85.76%)\n",
            "\tValidation loss: 0.00341, Accuracy: 185/423 (43.74%)\n",
            "\tTest loss: 0.00306, Accuracy: 220/443 (49.66%)\n",
            "\n",
            "Training Progress: \tEpoch 85 [0/1692 (0.00%)]\t\tLoss: 0.49555\n",
            "Training Progress: \tEpoch 85 [320/1692 (18.87%)]\t\tLoss: 0.85238\n",
            "Training Progress: \tEpoch 85 [640/1692 (37.74%)]\t\tLoss: 0.56541\n",
            "Training Progress: \tEpoch 85 [960/1692 (56.60%)]\t\tLoss: 0.56030\n",
            "Training Progress: \tEpoch 85 [1280/1692 (75.47%)]\t\tLoss: 0.58011\n",
            "Training Progress: \tEpoch 85 [1600/1692 (94.34%)]\t\tLoss: 0.48554\n",
            "\tTrain loss: 0.00957, Accuracy: 1519/1692 (89.78%)\n",
            "\tValidation loss: 0.00346, Accuracy: 187/423 (44.21%)\n",
            "\tTest loss: 0.00311, Accuracy: 219/443 (49.44%)\n",
            "\n",
            "Training Progress: \tEpoch 86 [0/1692 (0.00%)]\t\tLoss: 0.45902\n",
            "Training Progress: \tEpoch 86 [320/1692 (18.87%)]\t\tLoss: 0.94933\n",
            "Training Progress: \tEpoch 86 [640/1692 (37.74%)]\t\tLoss: 0.37626\n",
            "Training Progress: \tEpoch 86 [960/1692 (56.60%)]\t\tLoss: 0.69458\n",
            "Training Progress: \tEpoch 86 [1280/1692 (75.47%)]\t\tLoss: 0.52826\n",
            "Training Progress: \tEpoch 86 [1600/1692 (94.34%)]\t\tLoss: 0.42517\n",
            "\tTrain loss: 0.00933, Accuracy: 1532/1692 (90.54%)\n",
            "\tValidation loss: 0.00330, Accuracy: 189/423 (44.68%)\n",
            "\tTest loss: 0.00309, Accuracy: 220/443 (49.66%)\n",
            "\n",
            "Training Progress: \tEpoch 87 [0/1692 (0.00%)]\t\tLoss: 0.70227\n",
            "Training Progress: \tEpoch 87 [320/1692 (18.87%)]\t\tLoss: 0.72695\n",
            "Training Progress: \tEpoch 87 [640/1692 (37.74%)]\t\tLoss: 0.54516\n",
            "Training Progress: \tEpoch 87 [960/1692 (56.60%)]\t\tLoss: 0.55190\n",
            "Training Progress: \tEpoch 87 [1280/1692 (75.47%)]\t\tLoss: 0.50666\n",
            "Training Progress: \tEpoch 87 [1600/1692 (94.34%)]\t\tLoss: 0.63970\n",
            "\tTrain loss: 0.01009, Accuracy: 1486/1692 (87.83%)\n",
            "\tValidation loss: 0.00348, Accuracy: 187/423 (44.21%)\n",
            "\tTest loss: 0.00326, Accuracy: 221/443 (49.89%)\n",
            "\n",
            "Training Progress: \tEpoch 88 [0/1692 (0.00%)]\t\tLoss: 0.32868\n",
            "Training Progress: \tEpoch 88 [320/1692 (18.87%)]\t\tLoss: 0.52300\n",
            "Training Progress: \tEpoch 88 [640/1692 (37.74%)]\t\tLoss: 0.39371\n",
            "Training Progress: \tEpoch 88 [960/1692 (56.60%)]\t\tLoss: 0.73898\n",
            "Training Progress: \tEpoch 88 [1280/1692 (75.47%)]\t\tLoss: 0.44764\n",
            "Training Progress: \tEpoch 88 [1600/1692 (94.34%)]\t\tLoss: 0.37179\n",
            "\tTrain loss: 0.00944, Accuracy: 1496/1692 (88.42%)\n",
            "\tValidation loss: 0.00339, Accuracy: 196/423 (46.34%)\n",
            "\tTest loss: 0.00308, Accuracy: 223/443 (50.34%)\n",
            "\n",
            "Training Progress: \tEpoch 89 [0/1692 (0.00%)]\t\tLoss: 0.67004\n",
            "Training Progress: \tEpoch 89 [320/1692 (18.87%)]\t\tLoss: 0.86212\n",
            "Training Progress: \tEpoch 89 [640/1692 (37.74%)]\t\tLoss: 0.51073\n",
            "Training Progress: \tEpoch 89 [960/1692 (56.60%)]\t\tLoss: 0.56787\n",
            "Training Progress: \tEpoch 89 [1280/1692 (75.47%)]\t\tLoss: 0.39084\n",
            "Training Progress: \tEpoch 89 [1600/1692 (94.34%)]\t\tLoss: 0.54909\n",
            "\tTrain loss: 0.00915, Accuracy: 1516/1692 (89.60%)\n",
            "\tValidation loss: 0.00338, Accuracy: 194/423 (45.86%)\n",
            "\tTest loss: 0.00315, Accuracy: 222/443 (50.11%)\n",
            "\n",
            "Training Progress: \tEpoch 90 [0/1692 (0.00%)]\t\tLoss: 0.33616\n",
            "Training Progress: \tEpoch 90 [320/1692 (18.87%)]\t\tLoss: 0.63760\n",
            "Training Progress: \tEpoch 90 [640/1692 (37.74%)]\t\tLoss: 0.55988\n",
            "Training Progress: \tEpoch 90 [960/1692 (56.60%)]\t\tLoss: 0.73812\n",
            "Training Progress: \tEpoch 90 [1280/1692 (75.47%)]\t\tLoss: 0.65502\n",
            "Training Progress: \tEpoch 90 [1600/1692 (94.34%)]\t\tLoss: 0.41870\n",
            "\tTrain loss: 0.00828, Accuracy: 1548/1692 (91.49%)\n",
            "\tValidation loss: 0.00386, Accuracy: 184/423 (43.50%)\n",
            "\tTest loss: 0.00345, Accuracy: 216/443 (48.76%)\n",
            "\n",
            "Training Progress: \tEpoch 91 [0/1692 (0.00%)]\t\tLoss: 0.70156\n",
            "Training Progress: \tEpoch 91 [320/1692 (18.87%)]\t\tLoss: 0.49715\n",
            "Training Progress: \tEpoch 91 [640/1692 (37.74%)]\t\tLoss: 0.32191\n",
            "Training Progress: \tEpoch 91 [960/1692 (56.60%)]\t\tLoss: 0.54081\n",
            "Training Progress: \tEpoch 91 [1280/1692 (75.47%)]\t\tLoss: 0.30156\n",
            "Training Progress: \tEpoch 91 [1600/1692 (94.34%)]\t\tLoss: 0.49721\n",
            "\tTrain loss: 0.00839, Accuracy: 1536/1692 (90.78%)\n",
            "\tValidation loss: 0.00355, Accuracy: 193/423 (45.63%)\n",
            "\tTest loss: 0.00330, Accuracy: 212/443 (47.86%)\n",
            "\n",
            "Training Progress: \tEpoch 92 [0/1692 (0.00%)]\t\tLoss: 0.40956\n",
            "Training Progress: \tEpoch 92 [320/1692 (18.87%)]\t\tLoss: 0.86811\n",
            "Training Progress: \tEpoch 92 [640/1692 (37.74%)]\t\tLoss: 0.63109\n",
            "Training Progress: \tEpoch 92 [960/1692 (56.60%)]\t\tLoss: 0.61879\n",
            "Training Progress: \tEpoch 92 [1280/1692 (75.47%)]\t\tLoss: 0.43553\n",
            "Training Progress: \tEpoch 92 [1600/1692 (94.34%)]\t\tLoss: 0.48761\n",
            "\tTrain loss: 0.00831, Accuracy: 1551/1692 (91.67%)\n",
            "\tValidation loss: 0.00364, Accuracy: 202/423 (47.75%)\n",
            "\tTest loss: 0.00335, Accuracy: 213/443 (48.08%)\n",
            "\n",
            "Training Progress: \tEpoch 93 [0/1692 (0.00%)]\t\tLoss: 0.65431\n",
            "Training Progress: \tEpoch 93 [320/1692 (18.87%)]\t\tLoss: 0.89607\n",
            "Training Progress: \tEpoch 93 [640/1692 (37.74%)]\t\tLoss: 0.53762\n",
            "Training Progress: \tEpoch 93 [960/1692 (56.60%)]\t\tLoss: 0.42835\n",
            "Training Progress: \tEpoch 93 [1280/1692 (75.47%)]\t\tLoss: 0.39374\n",
            "Training Progress: \tEpoch 93 [1600/1692 (94.34%)]\t\tLoss: 0.51415\n",
            "\tTrain loss: 0.00823, Accuracy: 1547/1692 (91.43%)\n",
            "\tValidation loss: 0.00381, Accuracy: 184/423 (43.50%)\n",
            "\tTest loss: 0.00361, Accuracy: 205/443 (46.28%)\n",
            "\n",
            "Training Progress: \tEpoch 94 [0/1692 (0.00%)]\t\tLoss: 0.49306\n",
            "Training Progress: \tEpoch 94 [320/1692 (18.87%)]\t\tLoss: 0.77886\n",
            "Training Progress: \tEpoch 94 [640/1692 (37.74%)]\t\tLoss: 0.50251\n",
            "Training Progress: \tEpoch 94 [960/1692 (56.60%)]\t\tLoss: 0.80228\n",
            "Training Progress: \tEpoch 94 [1280/1692 (75.47%)]\t\tLoss: 0.37564\n",
            "Training Progress: \tEpoch 94 [1600/1692 (94.34%)]\t\tLoss: 0.55386\n",
            "\tTrain loss: 0.00842, Accuracy: 1537/1692 (90.84%)\n",
            "\tValidation loss: 0.00367, Accuracy: 183/423 (43.26%)\n",
            "\tTest loss: 0.00330, Accuracy: 211/443 (47.63%)\n",
            "\n",
            "Training Progress: \tEpoch 95 [0/1692 (0.00%)]\t\tLoss: 0.51153\n",
            "Training Progress: \tEpoch 95 [320/1692 (18.87%)]\t\tLoss: 0.72259\n",
            "Training Progress: \tEpoch 95 [640/1692 (37.74%)]\t\tLoss: 0.38888\n",
            "Training Progress: \tEpoch 95 [960/1692 (56.60%)]\t\tLoss: 0.50771\n",
            "Training Progress: \tEpoch 95 [1280/1692 (75.47%)]\t\tLoss: 0.40321\n",
            "Training Progress: \tEpoch 95 [1600/1692 (94.34%)]\t\tLoss: 0.69037\n",
            "\tTrain loss: 0.00793, Accuracy: 1554/1692 (91.84%)\n",
            "\tValidation loss: 0.00351, Accuracy: 177/423 (41.84%)\n",
            "\tTest loss: 0.00320, Accuracy: 217/443 (48.98%)\n",
            "\n",
            "Training Progress: \tEpoch 96 [0/1692 (0.00%)]\t\tLoss: 0.61514\n",
            "Training Progress: \tEpoch 96 [320/1692 (18.87%)]\t\tLoss: 0.88880\n",
            "Training Progress: \tEpoch 96 [640/1692 (37.74%)]\t\tLoss: 0.53304\n",
            "Training Progress: \tEpoch 96 [960/1692 (56.60%)]\t\tLoss: 0.61883\n",
            "Training Progress: \tEpoch 96 [1280/1692 (75.47%)]\t\tLoss: 0.49158\n",
            "Training Progress: \tEpoch 96 [1600/1692 (94.34%)]\t\tLoss: 0.42235\n",
            "\tTrain loss: 0.00816, Accuracy: 1541/1692 (91.08%)\n",
            "\tValidation loss: 0.00347, Accuracy: 180/423 (42.55%)\n",
            "\tTest loss: 0.00324, Accuracy: 200/443 (45.15%)\n",
            "\n",
            "Training Progress: \tEpoch 97 [0/1692 (0.00%)]\t\tLoss: 0.37734\n",
            "Training Progress: \tEpoch 97 [320/1692 (18.87%)]\t\tLoss: 0.72232\n",
            "Training Progress: \tEpoch 97 [640/1692 (37.74%)]\t\tLoss: 0.45855\n",
            "Training Progress: \tEpoch 97 [960/1692 (56.60%)]\t\tLoss: 0.35600\n",
            "Training Progress: \tEpoch 97 [1280/1692 (75.47%)]\t\tLoss: 0.39892\n",
            "Training Progress: \tEpoch 97 [1600/1692 (94.34%)]\t\tLoss: 0.59850\n",
            "\tTrain loss: 0.00670, Accuracy: 1573/1692 (92.97%)\n",
            "\tValidation loss: 0.00362, Accuracy: 191/423 (45.15%)\n",
            "\tTest loss: 0.00330, Accuracy: 217/443 (48.98%)\n",
            "\n",
            "Training Progress: \tEpoch 98 [0/1692 (0.00%)]\t\tLoss: 0.59573\n",
            "Training Progress: \tEpoch 98 [320/1692 (18.87%)]\t\tLoss: 0.89443\n",
            "Training Progress: \tEpoch 98 [640/1692 (37.74%)]\t\tLoss: 0.46949\n",
            "Training Progress: \tEpoch 98 [960/1692 (56.60%)]\t\tLoss: 0.44971\n",
            "Training Progress: \tEpoch 98 [1280/1692 (75.47%)]\t\tLoss: 0.71315\n",
            "Training Progress: \tEpoch 98 [1600/1692 (94.34%)]\t\tLoss: 0.54408\n",
            "\tTrain loss: 0.00726, Accuracy: 1586/1692 (93.74%)\n",
            "\tValidation loss: 0.00329, Accuracy: 194/423 (45.86%)\n",
            "\tTest loss: 0.00305, Accuracy: 220/443 (49.66%)\n",
            "\n",
            "Training Progress: \tEpoch 99 [0/1692 (0.00%)]\t\tLoss: 0.50978\n",
            "Training Progress: \tEpoch 99 [320/1692 (18.87%)]\t\tLoss: 0.79645\n",
            "Training Progress: \tEpoch 99 [640/1692 (37.74%)]\t\tLoss: 0.28325\n",
            "Training Progress: \tEpoch 99 [960/1692 (56.60%)]\t\tLoss: 0.57411\n",
            "Training Progress: \tEpoch 99 [1280/1692 (75.47%)]\t\tLoss: 0.45691\n",
            "Training Progress: \tEpoch 99 [1600/1692 (94.34%)]\t\tLoss: 0.31003\n",
            "\tTrain loss: 0.00633, Accuracy: 1593/1692 (94.15%)\n",
            "\tValidation loss: 0.00373, Accuracy: 185/423 (43.74%)\n",
            "\tTest loss: 0.00337, Accuracy: 212/443 (47.86%)\n",
            "\n",
            "Training Progress: \tEpoch 100 [0/1692 (0.00%)]\t\tLoss: 0.48490\n",
            "Training Progress: \tEpoch 100 [320/1692 (18.87%)]\t\tLoss: 0.67081\n",
            "Training Progress: \tEpoch 100 [640/1692 (37.74%)]\t\tLoss: 0.21965\n",
            "Training Progress: \tEpoch 100 [960/1692 (56.60%)]\t\tLoss: 0.59138\n",
            "Training Progress: \tEpoch 100 [1280/1692 (75.47%)]\t\tLoss: 0.53539\n",
            "Training Progress: \tEpoch 100 [1600/1692 (94.34%)]\t\tLoss: 0.67690\n",
            "\tTrain loss: 0.00740, Accuracy: 1563/1692 (92.38%)\n",
            "\tValidation loss: 0.00347, Accuracy: 192/423 (45.39%)\n",
            "\tTest loss: 0.00325, Accuracy: 210/443 (47.40%)\n",
            "\n",
            "Best validation accuracy:\n",
            "0.48226950354609927\n",
            "Best test accuracy:\n",
            "0.5349887133182845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAEICAYAAACkmHavAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jRWbk2VnfCy0"
      },
      "source": [
        "## CNN + GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ivhCRh-a_jx4",
        "outputId": "28b5739a-99a2-407b-b374-95dd38dad19d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = CNN_GRU().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=BETAS, eps=EPS, weight_decay=DECAY)\n",
        "train_and_evaluate(model, optimizer, data_loaders, num_epochs=EPOCHS)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Progress: \tEpoch 1 [0/1692 (0.00%)]\t\tLoss: 1.39187\n",
            "Training Progress: \tEpoch 1 [320/1692 (18.87%)]\t\tLoss: 1.39417\n",
            "Training Progress: \tEpoch 1 [640/1692 (37.74%)]\t\tLoss: 1.39754\n",
            "Training Progress: \tEpoch 1 [960/1692 (56.60%)]\t\tLoss: 1.38685\n",
            "Training Progress: \tEpoch 1 [1280/1692 (75.47%)]\t\tLoss: 1.37070\n",
            "Training Progress: \tEpoch 1 [1600/1692 (94.34%)]\t\tLoss: 1.37474\n",
            "\tTrain loss: 0.04309, Accuracy: 496/1692 (29.31%)\n",
            "\tValidation loss: 0.00325, Accuracy: 120/423 (28.37%)\n",
            "\tTest loss: 0.00310, Accuracy: 123/443 (27.77%)\n",
            "\n",
            "Training Progress: \tEpoch 2 [0/1692 (0.00%)]\t\tLoss: 1.37358\n",
            "Training Progress: \tEpoch 2 [320/1692 (18.87%)]\t\tLoss: 1.39494\n",
            "Training Progress: \tEpoch 2 [640/1692 (37.74%)]\t\tLoss: 1.37944\n",
            "Training Progress: \tEpoch 2 [960/1692 (56.60%)]\t\tLoss: 1.34335\n",
            "Training Progress: \tEpoch 2 [1280/1692 (75.47%)]\t\tLoss: 1.34306\n",
            "Training Progress: \tEpoch 2 [1600/1692 (94.34%)]\t\tLoss: 1.31966\n",
            "\tTrain loss: 0.04167, Accuracy: 593/1692 (35.05%)\n",
            "\tValidation loss: 0.00316, Accuracy: 147/423 (34.75%)\n",
            "\tTest loss: 0.00301, Accuracy: 165/443 (37.25%)\n",
            "\n",
            "Training Progress: \tEpoch 3 [0/1692 (0.00%)]\t\tLoss: 1.33439\n",
            "Training Progress: \tEpoch 3 [320/1692 (18.87%)]\t\tLoss: 1.36980\n",
            "Training Progress: \tEpoch 3 [640/1692 (37.74%)]\t\tLoss: 1.32892\n",
            "Training Progress: \tEpoch 3 [960/1692 (56.60%)]\t\tLoss: 1.31912\n",
            "Training Progress: \tEpoch 3 [1280/1692 (75.47%)]\t\tLoss: 1.32621\n",
            "Training Progress: \tEpoch 3 [1600/1692 (94.34%)]\t\tLoss: 1.23791\n",
            "\tTrain loss: 0.04135, Accuracy: 577/1692 (34.10%)\n",
            "\tValidation loss: 0.00313, Accuracy: 143/423 (33.81%)\n",
            "\tTest loss: 0.00300, Accuracy: 161/443 (36.34%)\n",
            "\n",
            "Training Progress: \tEpoch 4 [0/1692 (0.00%)]\t\tLoss: 1.31285\n",
            "Training Progress: \tEpoch 4 [320/1692 (18.87%)]\t\tLoss: 1.35736\n",
            "Training Progress: \tEpoch 4 [640/1692 (37.74%)]\t\tLoss: 1.23613\n",
            "Training Progress: \tEpoch 4 [960/1692 (56.60%)]\t\tLoss: 1.31758\n",
            "Training Progress: \tEpoch 4 [1280/1692 (75.47%)]\t\tLoss: 1.32296\n",
            "Training Progress: \tEpoch 4 [1600/1692 (94.34%)]\t\tLoss: 1.24410\n",
            "\tTrain loss: 0.04005, Accuracy: 677/1692 (40.01%)\n",
            "\tValidation loss: 0.00307, Accuracy: 161/423 (38.06%)\n",
            "\tTest loss: 0.00288, Accuracy: 181/443 (40.86%)\n",
            "\n",
            "Training Progress: \tEpoch 5 [0/1692 (0.00%)]\t\tLoss: 1.28138\n",
            "Training Progress: \tEpoch 5 [320/1692 (18.87%)]\t\tLoss: 1.41581\n",
            "Training Progress: \tEpoch 5 [640/1692 (37.74%)]\t\tLoss: 1.14491\n",
            "Training Progress: \tEpoch 5 [960/1692 (56.60%)]\t\tLoss: 1.26109\n",
            "Training Progress: \tEpoch 5 [1280/1692 (75.47%)]\t\tLoss: 1.29966\n",
            "Training Progress: \tEpoch 5 [1600/1692 (94.34%)]\t\tLoss: 1.22100\n",
            "\tTrain loss: 0.03895, Accuracy: 696/1692 (41.13%)\n",
            "\tValidation loss: 0.00300, Accuracy: 161/423 (38.06%)\n",
            "\tTest loss: 0.00279, Accuracy: 184/443 (41.53%)\n",
            "\n",
            "Training Progress: \tEpoch 6 [0/1692 (0.00%)]\t\tLoss: 1.27952\n",
            "Training Progress: \tEpoch 6 [320/1692 (18.87%)]\t\tLoss: 1.28400\n",
            "Training Progress: \tEpoch 6 [640/1692 (37.74%)]\t\tLoss: 1.20472\n",
            "Training Progress: \tEpoch 6 [960/1692 (56.60%)]\t\tLoss: 1.24893\n",
            "Training Progress: \tEpoch 6 [1280/1692 (75.47%)]\t\tLoss: 1.26326\n",
            "Training Progress: \tEpoch 6 [1600/1692 (94.34%)]\t\tLoss: 1.29467\n",
            "\tTrain loss: 0.03848, Accuracy: 692/1692 (40.90%)\n",
            "\tValidation loss: 0.00298, Accuracy: 168/423 (39.72%)\n",
            "\tTest loss: 0.00275, Accuracy: 196/443 (44.24%)\n",
            "\n",
            "Training Progress: \tEpoch 7 [0/1692 (0.00%)]\t\tLoss: 1.36717\n",
            "Training Progress: \tEpoch 7 [320/1692 (18.87%)]\t\tLoss: 1.33453\n",
            "Training Progress: \tEpoch 7 [640/1692 (37.74%)]\t\tLoss: 1.11629\n",
            "Training Progress: \tEpoch 7 [960/1692 (56.60%)]\t\tLoss: 1.24956\n",
            "Training Progress: \tEpoch 7 [1280/1692 (75.47%)]\t\tLoss: 1.26851\n",
            "Training Progress: \tEpoch 7 [1600/1692 (94.34%)]\t\tLoss: 1.17626\n",
            "\tTrain loss: 0.03834, Accuracy: 694/1692 (41.02%)\n",
            "\tValidation loss: 0.00302, Accuracy: 165/423 (39.01%)\n",
            "\tTest loss: 0.00277, Accuracy: 185/443 (41.76%)\n",
            "\n",
            "Training Progress: \tEpoch 8 [0/1692 (0.00%)]\t\tLoss: 1.26822\n",
            "Training Progress: \tEpoch 8 [320/1692 (18.87%)]\t\tLoss: 1.42511\n",
            "Training Progress: \tEpoch 8 [640/1692 (37.74%)]\t\tLoss: 1.12040\n",
            "Training Progress: \tEpoch 8 [960/1692 (56.60%)]\t\tLoss: 1.23988\n",
            "Training Progress: \tEpoch 8 [1280/1692 (75.47%)]\t\tLoss: 1.22700\n",
            "Training Progress: \tEpoch 8 [1600/1692 (94.34%)]\t\tLoss: 1.25955\n",
            "\tTrain loss: 0.03762, Accuracy: 761/1692 (44.98%)\n",
            "\tValidation loss: 0.00294, Accuracy: 177/423 (41.84%)\n",
            "\tTest loss: 0.00272, Accuracy: 196/443 (44.24%)\n",
            "\n",
            "Training Progress: \tEpoch 9 [0/1692 (0.00%)]\t\tLoss: 1.32478\n",
            "Training Progress: \tEpoch 9 [320/1692 (18.87%)]\t\tLoss: 1.33707\n",
            "Training Progress: \tEpoch 9 [640/1692 (37.74%)]\t\tLoss: 1.07865\n",
            "Training Progress: \tEpoch 9 [960/1692 (56.60%)]\t\tLoss: 1.20789\n",
            "Training Progress: \tEpoch 9 [1280/1692 (75.47%)]\t\tLoss: 1.25026\n",
            "Training Progress: \tEpoch 9 [1600/1692 (94.34%)]\t\tLoss: 1.32938\n",
            "\tTrain loss: 0.03688, Accuracy: 770/1692 (45.51%)\n",
            "\tValidation loss: 0.00293, Accuracy: 174/423 (41.13%)\n",
            "\tTest loss: 0.00270, Accuracy: 205/443 (46.28%)\n",
            "\n",
            "Training Progress: \tEpoch 10 [0/1692 (0.00%)]\t\tLoss: 1.09135\n",
            "Training Progress: \tEpoch 10 [320/1692 (18.87%)]\t\tLoss: 1.23910\n",
            "Training Progress: \tEpoch 10 [640/1692 (37.74%)]\t\tLoss: 1.05736\n",
            "Training Progress: \tEpoch 10 [960/1692 (56.60%)]\t\tLoss: 1.20604\n",
            "Training Progress: \tEpoch 10 [1280/1692 (75.47%)]\t\tLoss: 1.25882\n",
            "Training Progress: \tEpoch 10 [1600/1692 (94.34%)]\t\tLoss: 1.18736\n",
            "\tTrain loss: 0.03523, Accuracy: 836/1692 (49.41%)\n",
            "\tValidation loss: 0.00286, Accuracy: 175/423 (41.37%)\n",
            "\tTest loss: 0.00261, Accuracy: 204/443 (46.05%)\n",
            "\n",
            "Training Progress: \tEpoch 11 [0/1692 (0.00%)]\t\tLoss: 1.31304\n",
            "Training Progress: \tEpoch 11 [320/1692 (18.87%)]\t\tLoss: 1.32217\n",
            "Training Progress: \tEpoch 11 [640/1692 (37.74%)]\t\tLoss: 1.06178\n",
            "Training Progress: \tEpoch 11 [960/1692 (56.60%)]\t\tLoss: 1.12248\n",
            "Training Progress: \tEpoch 11 [1280/1692 (75.47%)]\t\tLoss: 1.21344\n",
            "Training Progress: \tEpoch 11 [1600/1692 (94.34%)]\t\tLoss: 1.27271\n",
            "\tTrain loss: 0.03532, Accuracy: 824/1692 (48.70%)\n",
            "\tValidation loss: 0.00292, Accuracy: 170/423 (40.19%)\n",
            "\tTest loss: 0.00264, Accuracy: 201/443 (45.37%)\n",
            "\n",
            "Training Progress: \tEpoch 12 [0/1692 (0.00%)]\t\tLoss: 1.09587\n",
            "Training Progress: \tEpoch 12 [320/1692 (18.87%)]\t\tLoss: 1.29698\n",
            "Training Progress: \tEpoch 12 [640/1692 (37.74%)]\t\tLoss: 1.05700\n",
            "Training Progress: \tEpoch 12 [960/1692 (56.60%)]\t\tLoss: 1.13114\n",
            "Training Progress: \tEpoch 12 [1280/1692 (75.47%)]\t\tLoss: 1.08035\n",
            "Training Progress: \tEpoch 12 [1600/1692 (94.34%)]\t\tLoss: 1.28498\n",
            "\tTrain loss: 0.03453, Accuracy: 845/1692 (49.94%)\n",
            "\tValidation loss: 0.00286, Accuracy: 176/423 (41.61%)\n",
            "\tTest loss: 0.00260, Accuracy: 215/443 (48.53%)\n",
            "\n",
            "Training Progress: \tEpoch 13 [0/1692 (0.00%)]\t\tLoss: 1.19860\n",
            "Training Progress: \tEpoch 13 [320/1692 (18.87%)]\t\tLoss: 1.46290\n",
            "Training Progress: \tEpoch 13 [640/1692 (37.74%)]\t\tLoss: 1.08146\n",
            "Training Progress: \tEpoch 13 [960/1692 (56.60%)]\t\tLoss: 1.19380\n",
            "Training Progress: \tEpoch 13 [1280/1692 (75.47%)]\t\tLoss: 1.04790\n",
            "Training Progress: \tEpoch 13 [1600/1692 (94.34%)]\t\tLoss: 1.26221\n",
            "\tTrain loss: 0.03290, Accuracy: 907/1692 (53.61%)\n",
            "\tValidation loss: 0.00276, Accuracy: 199/423 (47.04%)\n",
            "\tTest loss: 0.00251, Accuracy: 217/443 (48.98%)\n",
            "\n",
            "Training Progress: \tEpoch 14 [0/1692 (0.00%)]\t\tLoss: 1.30501\n",
            "Training Progress: \tEpoch 14 [320/1692 (18.87%)]\t\tLoss: 1.45751\n",
            "Training Progress: \tEpoch 14 [640/1692 (37.74%)]\t\tLoss: 0.96722\n",
            "Training Progress: \tEpoch 14 [960/1692 (56.60%)]\t\tLoss: 1.10779\n",
            "Training Progress: \tEpoch 14 [1280/1692 (75.47%)]\t\tLoss: 1.00963\n",
            "Training Progress: \tEpoch 14 [1600/1692 (94.34%)]\t\tLoss: 1.15374\n",
            "\tTrain loss: 0.03244, Accuracy: 921/1692 (54.43%)\n",
            "\tValidation loss: 0.00272, Accuracy: 188/423 (44.44%)\n",
            "\tTest loss: 0.00250, Accuracy: 216/443 (48.76%)\n",
            "\n",
            "Training Progress: \tEpoch 15 [0/1692 (0.00%)]\t\tLoss: 1.24838\n",
            "Training Progress: \tEpoch 15 [320/1692 (18.87%)]\t\tLoss: 1.43461\n",
            "Training Progress: \tEpoch 15 [640/1692 (37.74%)]\t\tLoss: 1.16615\n",
            "Training Progress: \tEpoch 15 [960/1692 (56.60%)]\t\tLoss: 1.14442\n",
            "Training Progress: \tEpoch 15 [1280/1692 (75.47%)]\t\tLoss: 1.02695\n",
            "Training Progress: \tEpoch 15 [1600/1692 (94.34%)]\t\tLoss: 1.23497\n",
            "\tTrain loss: 0.03198, Accuracy: 939/1692 (55.50%)\n",
            "\tValidation loss: 0.00268, Accuracy: 203/423 (47.99%)\n",
            "\tTest loss: 0.00250, Accuracy: 221/443 (49.89%)\n",
            "\n",
            "Training Progress: \tEpoch 16 [0/1692 (0.00%)]\t\tLoss: 1.07502\n",
            "Training Progress: \tEpoch 16 [320/1692 (18.87%)]\t\tLoss: 1.35983\n",
            "Training Progress: \tEpoch 16 [640/1692 (37.74%)]\t\tLoss: 1.04261\n",
            "Training Progress: \tEpoch 16 [960/1692 (56.60%)]\t\tLoss: 1.11425\n",
            "Training Progress: \tEpoch 16 [1280/1692 (75.47%)]\t\tLoss: 1.06577\n",
            "Training Progress: \tEpoch 16 [1600/1692 (94.34%)]\t\tLoss: 1.11295\n",
            "\tTrain loss: 0.03144, Accuracy: 950/1692 (56.15%)\n",
            "\tValidation loss: 0.00271, Accuracy: 209/423 (49.41%)\n",
            "\tTest loss: 0.00251, Accuracy: 225/443 (50.79%)\n",
            "\n",
            "Training Progress: \tEpoch 17 [0/1692 (0.00%)]\t\tLoss: 1.11266\n",
            "Training Progress: \tEpoch 17 [320/1692 (18.87%)]\t\tLoss: 1.34530\n",
            "Training Progress: \tEpoch 17 [640/1692 (37.74%)]\t\tLoss: 1.00741\n",
            "Training Progress: \tEpoch 17 [960/1692 (56.60%)]\t\tLoss: 1.08113\n",
            "Training Progress: \tEpoch 17 [1280/1692 (75.47%)]\t\tLoss: 0.92174\n",
            "Training Progress: \tEpoch 17 [1600/1692 (94.34%)]\t\tLoss: 1.18516\n",
            "\tTrain loss: 0.03130, Accuracy: 925/1692 (54.67%)\n",
            "\tValidation loss: 0.00268, Accuracy: 207/423 (48.94%)\n",
            "\tTest loss: 0.00255, Accuracy: 225/443 (50.79%)\n",
            "\n",
            "Training Progress: \tEpoch 18 [0/1692 (0.00%)]\t\tLoss: 1.06573\n",
            "Training Progress: \tEpoch 18 [320/1692 (18.87%)]\t\tLoss: 1.23730\n",
            "Training Progress: \tEpoch 18 [640/1692 (37.74%)]\t\tLoss: 1.04350\n",
            "Training Progress: \tEpoch 18 [960/1692 (56.60%)]\t\tLoss: 1.08485\n",
            "Training Progress: \tEpoch 18 [1280/1692 (75.47%)]\t\tLoss: 0.96846\n",
            "Training Progress: \tEpoch 18 [1600/1692 (94.34%)]\t\tLoss: 1.14801\n",
            "\tTrain loss: 0.03081, Accuracy: 962/1692 (56.86%)\n",
            "\tValidation loss: 0.00267, Accuracy: 200/423 (47.28%)\n",
            "\tTest loss: 0.00250, Accuracy: 230/443 (51.92%)\n",
            "\n",
            "Training Progress: \tEpoch 19 [0/1692 (0.00%)]\t\tLoss: 1.06326\n",
            "Training Progress: \tEpoch 19 [320/1692 (18.87%)]\t\tLoss: 1.36679\n",
            "Training Progress: \tEpoch 19 [640/1692 (37.74%)]\t\tLoss: 1.03792\n",
            "Training Progress: \tEpoch 19 [960/1692 (56.60%)]\t\tLoss: 1.11028\n",
            "Training Progress: \tEpoch 19 [1280/1692 (75.47%)]\t\tLoss: 0.94547\n",
            "Training Progress: \tEpoch 19 [1600/1692 (94.34%)]\t\tLoss: 1.07852\n",
            "\tTrain loss: 0.02996, Accuracy: 1003/1692 (59.28%)\n",
            "\tValidation loss: 0.00258, Accuracy: 207/423 (48.94%)\n",
            "\tTest loss: 0.00246, Accuracy: 226/443 (51.02%)\n",
            "\n",
            "Training Progress: \tEpoch 20 [0/1692 (0.00%)]\t\tLoss: 1.08738\n",
            "Training Progress: \tEpoch 20 [320/1692 (18.87%)]\t\tLoss: 1.28680\n",
            "Training Progress: \tEpoch 20 [640/1692 (37.74%)]\t\tLoss: 1.09019\n",
            "Training Progress: \tEpoch 20 [960/1692 (56.60%)]\t\tLoss: 1.11866\n",
            "Training Progress: \tEpoch 20 [1280/1692 (75.47%)]\t\tLoss: 1.11005\n",
            "Training Progress: \tEpoch 20 [1600/1692 (94.34%)]\t\tLoss: 1.00601\n",
            "\tTrain loss: 0.02932, Accuracy: 1023/1692 (60.46%)\n",
            "\tValidation loss: 0.00259, Accuracy: 204/423 (48.23%)\n",
            "\tTest loss: 0.00242, Accuracy: 230/443 (51.92%)\n",
            "\n",
            "Training Progress: \tEpoch 21 [0/1692 (0.00%)]\t\tLoss: 1.03089\n",
            "Training Progress: \tEpoch 21 [320/1692 (18.87%)]\t\tLoss: 1.35951\n",
            "Training Progress: \tEpoch 21 [640/1692 (37.74%)]\t\tLoss: 1.11200\n",
            "Training Progress: \tEpoch 21 [960/1692 (56.60%)]\t\tLoss: 0.99366\n",
            "Training Progress: \tEpoch 21 [1280/1692 (75.47%)]\t\tLoss: 1.01375\n",
            "Training Progress: \tEpoch 21 [1600/1692 (94.34%)]\t\tLoss: 1.09111\n",
            "\tTrain loss: 0.02863, Accuracy: 1041/1692 (61.52%)\n",
            "\tValidation loss: 0.00263, Accuracy: 200/423 (47.28%)\n",
            "\tTest loss: 0.00249, Accuracy: 227/443 (51.24%)\n",
            "\n",
            "Training Progress: \tEpoch 22 [0/1692 (0.00%)]\t\tLoss: 0.94610\n",
            "Training Progress: \tEpoch 22 [320/1692 (18.87%)]\t\tLoss: 1.23997\n",
            "Training Progress: \tEpoch 22 [640/1692 (37.74%)]\t\tLoss: 0.89002\n",
            "Training Progress: \tEpoch 22 [960/1692 (56.60%)]\t\tLoss: 1.11549\n",
            "Training Progress: \tEpoch 22 [1280/1692 (75.47%)]\t\tLoss: 0.87316\n",
            "Training Progress: \tEpoch 22 [1600/1692 (94.34%)]\t\tLoss: 1.04349\n",
            "\tTrain loss: 0.02889, Accuracy: 1009/1692 (59.63%)\n",
            "\tValidation loss: 0.00268, Accuracy: 196/423 (46.34%)\n",
            "\tTest loss: 0.00242, Accuracy: 238/443 (53.72%)\n",
            "\n",
            "Training Progress: \tEpoch 23 [0/1692 (0.00%)]\t\tLoss: 1.05931\n",
            "Training Progress: \tEpoch 23 [320/1692 (18.87%)]\t\tLoss: 1.18321\n",
            "Training Progress: \tEpoch 23 [640/1692 (37.74%)]\t\tLoss: 1.21244\n",
            "Training Progress: \tEpoch 23 [960/1692 (56.60%)]\t\tLoss: 1.04480\n",
            "Training Progress: \tEpoch 23 [1280/1692 (75.47%)]\t\tLoss: 0.87043\n",
            "Training Progress: \tEpoch 23 [1600/1692 (94.34%)]\t\tLoss: 1.06730\n",
            "\tTrain loss: 0.02801, Accuracy: 1025/1692 (60.58%)\n",
            "\tValidation loss: 0.00266, Accuracy: 200/423 (47.28%)\n",
            "\tTest loss: 0.00238, Accuracy: 232/443 (52.37%)\n",
            "\n",
            "Training Progress: \tEpoch 24 [0/1692 (0.00%)]\t\tLoss: 1.01042\n",
            "Training Progress: \tEpoch 24 [320/1692 (18.87%)]\t\tLoss: 1.30152\n",
            "Training Progress: \tEpoch 24 [640/1692 (37.74%)]\t\tLoss: 1.06670\n",
            "Training Progress: \tEpoch 24 [960/1692 (56.60%)]\t\tLoss: 1.00134\n",
            "Training Progress: \tEpoch 24 [1280/1692 (75.47%)]\t\tLoss: 0.76566\n",
            "Training Progress: \tEpoch 24 [1600/1692 (94.34%)]\t\tLoss: 0.99851\n",
            "\tTrain loss: 0.02763, Accuracy: 1055/1692 (62.35%)\n",
            "\tValidation loss: 0.00271, Accuracy: 194/423 (45.86%)\n",
            "\tTest loss: 0.00247, Accuracy: 237/443 (53.50%)\n",
            "\n",
            "Training Progress: \tEpoch 25 [0/1692 (0.00%)]\t\tLoss: 0.96032\n",
            "Training Progress: \tEpoch 25 [320/1692 (18.87%)]\t\tLoss: 1.05499\n",
            "Training Progress: \tEpoch 25 [640/1692 (37.74%)]\t\tLoss: 0.96112\n",
            "Training Progress: \tEpoch 25 [960/1692 (56.60%)]\t\tLoss: 1.00897\n",
            "Training Progress: \tEpoch 25 [1280/1692 (75.47%)]\t\tLoss: 0.93684\n",
            "Training Progress: \tEpoch 25 [1600/1692 (94.34%)]\t\tLoss: 0.85191\n",
            "\tTrain loss: 0.02731, Accuracy: 1051/1692 (62.12%)\n",
            "\tValidation loss: 0.00283, Accuracy: 197/423 (46.57%)\n",
            "\tTest loss: 0.00257, Accuracy: 223/443 (50.34%)\n",
            "\n",
            "Training Progress: \tEpoch 26 [0/1692 (0.00%)]\t\tLoss: 1.01784\n",
            "Training Progress: \tEpoch 26 [320/1692 (18.87%)]\t\tLoss: 1.12061\n",
            "Training Progress: \tEpoch 26 [640/1692 (37.74%)]\t\tLoss: 1.07303\n",
            "Training Progress: \tEpoch 26 [960/1692 (56.60%)]\t\tLoss: 1.12745\n",
            "Training Progress: \tEpoch 26 [1280/1692 (75.47%)]\t\tLoss: 0.95487\n",
            "Training Progress: \tEpoch 26 [1600/1692 (94.34%)]\t\tLoss: 1.02818\n",
            "\tTrain loss: 0.02618, Accuracy: 1109/1692 (65.54%)\n",
            "\tValidation loss: 0.00266, Accuracy: 202/423 (47.75%)\n",
            "\tTest loss: 0.00247, Accuracy: 230/443 (51.92%)\n",
            "\n",
            "Training Progress: \tEpoch 27 [0/1692 (0.00%)]\t\tLoss: 1.00828\n",
            "Training Progress: \tEpoch 27 [320/1692 (18.87%)]\t\tLoss: 1.07469\n",
            "Training Progress: \tEpoch 27 [640/1692 (37.74%)]\t\tLoss: 0.92324\n",
            "Training Progress: \tEpoch 27 [960/1692 (56.60%)]\t\tLoss: 0.95410\n",
            "Training Progress: \tEpoch 27 [1280/1692 (75.47%)]\t\tLoss: 0.97626\n",
            "Training Progress: \tEpoch 27 [1600/1692 (94.34%)]\t\tLoss: 0.93671\n",
            "\tTrain loss: 0.02688, Accuracy: 1084/1692 (64.07%)\n",
            "\tValidation loss: 0.00274, Accuracy: 202/423 (47.75%)\n",
            "\tTest loss: 0.00256, Accuracy: 229/443 (51.69%)\n",
            "\n",
            "Training Progress: \tEpoch 28 [0/1692 (0.00%)]\t\tLoss: 1.23205\n",
            "Training Progress: \tEpoch 28 [320/1692 (18.87%)]\t\tLoss: 1.19124\n",
            "Training Progress: \tEpoch 28 [640/1692 (37.74%)]\t\tLoss: 0.94384\n",
            "Training Progress: \tEpoch 28 [960/1692 (56.60%)]\t\tLoss: 0.91343\n",
            "Training Progress: \tEpoch 28 [1280/1692 (75.47%)]\t\tLoss: 1.02769\n",
            "Training Progress: \tEpoch 28 [1600/1692 (94.34%)]\t\tLoss: 1.04937\n",
            "\tTrain loss: 0.02512, Accuracy: 1144/1692 (67.61%)\n",
            "\tValidation loss: 0.00263, Accuracy: 203/423 (47.99%)\n",
            "\tTest loss: 0.00250, Accuracy: 237/443 (53.50%)\n",
            "\n",
            "Training Progress: \tEpoch 29 [0/1692 (0.00%)]\t\tLoss: 0.82323\n",
            "Training Progress: \tEpoch 29 [320/1692 (18.87%)]\t\tLoss: 1.25094\n",
            "Training Progress: \tEpoch 29 [640/1692 (37.74%)]\t\tLoss: 0.93137\n",
            "Training Progress: \tEpoch 29 [960/1692 (56.60%)]\t\tLoss: 1.03725\n",
            "Training Progress: \tEpoch 29 [1280/1692 (75.47%)]\t\tLoss: 0.79063\n",
            "Training Progress: \tEpoch 29 [1600/1692 (94.34%)]\t\tLoss: 0.94994\n",
            "\tTrain loss: 0.02379, Accuracy: 1154/1692 (68.20%)\n",
            "\tValidation loss: 0.00274, Accuracy: 198/423 (46.81%)\n",
            "\tTest loss: 0.00259, Accuracy: 230/443 (51.92%)\n",
            "\n",
            "Training Progress: \tEpoch 30 [0/1692 (0.00%)]\t\tLoss: 0.86456\n",
            "Training Progress: \tEpoch 30 [320/1692 (18.87%)]\t\tLoss: 1.07835\n",
            "Training Progress: \tEpoch 30 [640/1692 (37.74%)]\t\tLoss: 1.00756\n",
            "Training Progress: \tEpoch 30 [960/1692 (56.60%)]\t\tLoss: 0.97551\n",
            "Training Progress: \tEpoch 30 [1280/1692 (75.47%)]\t\tLoss: 1.08172\n",
            "Training Progress: \tEpoch 30 [1600/1692 (94.34%)]\t\tLoss: 0.99645\n",
            "\tTrain loss: 0.02356, Accuracy: 1174/1692 (69.39%)\n",
            "\tValidation loss: 0.00273, Accuracy: 209/423 (49.41%)\n",
            "\tTest loss: 0.00263, Accuracy: 234/443 (52.82%)\n",
            "\n",
            "Training Progress: \tEpoch 31 [0/1692 (0.00%)]\t\tLoss: 0.73207\n",
            "Training Progress: \tEpoch 31 [320/1692 (18.87%)]\t\tLoss: 1.29544\n",
            "Training Progress: \tEpoch 31 [640/1692 (37.74%)]\t\tLoss: 1.04546\n",
            "Training Progress: \tEpoch 31 [960/1692 (56.60%)]\t\tLoss: 0.91122\n",
            "Training Progress: \tEpoch 31 [1280/1692 (75.47%)]\t\tLoss: 0.99740\n",
            "Training Progress: \tEpoch 31 [1600/1692 (94.34%)]\t\tLoss: 0.97779\n",
            "\tTrain loss: 0.02433, Accuracy: 1129/1692 (66.73%)\n",
            "\tValidation loss: 0.00286, Accuracy: 204/423 (48.23%)\n",
            "\tTest loss: 0.00274, Accuracy: 218/443 (49.21%)\n",
            "\n",
            "Training Progress: \tEpoch 32 [0/1692 (0.00%)]\t\tLoss: 0.75373\n",
            "Training Progress: \tEpoch 32 [320/1692 (18.87%)]\t\tLoss: 1.11119\n",
            "Training Progress: \tEpoch 32 [640/1692 (37.74%)]\t\tLoss: 1.04696\n",
            "Training Progress: \tEpoch 32 [960/1692 (56.60%)]\t\tLoss: 0.83781\n",
            "Training Progress: \tEpoch 32 [1280/1692 (75.47%)]\t\tLoss: 0.76000\n",
            "Training Progress: \tEpoch 32 [1600/1692 (94.34%)]\t\tLoss: 0.91125\n",
            "\tTrain loss: 0.02297, Accuracy: 1201/1692 (70.98%)\n",
            "\tValidation loss: 0.00273, Accuracy: 202/423 (47.75%)\n",
            "\tTest loss: 0.00255, Accuracy: 233/443 (52.60%)\n",
            "\n",
            "Training Progress: \tEpoch 33 [0/1692 (0.00%)]\t\tLoss: 0.79158\n",
            "Training Progress: \tEpoch 33 [320/1692 (18.87%)]\t\tLoss: 1.02885\n",
            "Training Progress: \tEpoch 33 [640/1692 (37.74%)]\t\tLoss: 0.89459\n",
            "Training Progress: \tEpoch 33 [960/1692 (56.60%)]\t\tLoss: 0.84608\n",
            "Training Progress: \tEpoch 33 [1280/1692 (75.47%)]\t\tLoss: 1.02781\n",
            "Training Progress: \tEpoch 33 [1600/1692 (94.34%)]\t\tLoss: 0.88677\n",
            "\tTrain loss: 0.02573, Accuracy: 1091/1692 (64.48%)\n",
            "\tValidation loss: 0.00286, Accuracy: 200/423 (47.28%)\n",
            "\tTest loss: 0.00283, Accuracy: 203/443 (45.82%)\n",
            "\n",
            "Training Progress: \tEpoch 34 [0/1692 (0.00%)]\t\tLoss: 0.84833\n",
            "Training Progress: \tEpoch 34 [320/1692 (18.87%)]\t\tLoss: 1.18480\n",
            "Training Progress: \tEpoch 34 [640/1692 (37.74%)]\t\tLoss: 0.93984\n",
            "Training Progress: \tEpoch 34 [960/1692 (56.60%)]\t\tLoss: 1.03517\n",
            "Training Progress: \tEpoch 34 [1280/1692 (75.47%)]\t\tLoss: 0.80348\n",
            "Training Progress: \tEpoch 34 [1600/1692 (94.34%)]\t\tLoss: 0.95345\n",
            "\tTrain loss: 0.02349, Accuracy: 1155/1692 (68.26%)\n",
            "\tValidation loss: 0.00265, Accuracy: 211/423 (49.88%)\n",
            "\tTest loss: 0.00250, Accuracy: 238/443 (53.72%)\n",
            "\n",
            "Training Progress: \tEpoch 35 [0/1692 (0.00%)]\t\tLoss: 0.92347\n",
            "Training Progress: \tEpoch 35 [320/1692 (18.87%)]\t\tLoss: 1.26165\n",
            "Training Progress: \tEpoch 35 [640/1692 (37.74%)]\t\tLoss: 1.06985\n",
            "Training Progress: \tEpoch 35 [960/1692 (56.60%)]\t\tLoss: 1.00238\n",
            "Training Progress: \tEpoch 35 [1280/1692 (75.47%)]\t\tLoss: 0.91787\n",
            "Training Progress: \tEpoch 35 [1600/1692 (94.34%)]\t\tLoss: 1.16767\n",
            "\tTrain loss: 0.02320, Accuracy: 1179/1692 (69.68%)\n",
            "\tValidation loss: 0.00274, Accuracy: 203/423 (47.99%)\n",
            "\tTest loss: 0.00257, Accuracy: 238/443 (53.72%)\n",
            "\n",
            "Training Progress: \tEpoch 36 [0/1692 (0.00%)]\t\tLoss: 0.77386\n",
            "Training Progress: \tEpoch 36 [320/1692 (18.87%)]\t\tLoss: 0.84840\n",
            "Training Progress: \tEpoch 36 [640/1692 (37.74%)]\t\tLoss: 0.92267\n",
            "Training Progress: \tEpoch 36 [960/1692 (56.60%)]\t\tLoss: 0.90553\n",
            "Training Progress: \tEpoch 36 [1280/1692 (75.47%)]\t\tLoss: 0.87493\n",
            "Training Progress: \tEpoch 36 [1600/1692 (94.34%)]\t\tLoss: 1.02347\n",
            "\tTrain loss: 0.02314, Accuracy: 1174/1692 (69.39%)\n",
            "\tValidation loss: 0.00281, Accuracy: 198/423 (46.81%)\n",
            "\tTest loss: 0.00265, Accuracy: 223/443 (50.34%)\n",
            "\n",
            "Training Progress: \tEpoch 37 [0/1692 (0.00%)]\t\tLoss: 0.82302\n",
            "Training Progress: \tEpoch 37 [320/1692 (18.87%)]\t\tLoss: 0.87632\n",
            "Training Progress: \tEpoch 37 [640/1692 (37.74%)]\t\tLoss: 0.76993\n",
            "Training Progress: \tEpoch 37 [960/1692 (56.60%)]\t\tLoss: 0.79144\n",
            "Training Progress: \tEpoch 37 [1280/1692 (75.47%)]\t\tLoss: 0.99174\n",
            "Training Progress: \tEpoch 37 [1600/1692 (94.34%)]\t\tLoss: 0.90761\n",
            "\tTrain loss: 0.02101, Accuracy: 1236/1692 (73.05%)\n",
            "\tValidation loss: 0.00274, Accuracy: 205/423 (48.46%)\n",
            "\tTest loss: 0.00264, Accuracy: 229/443 (51.69%)\n",
            "\n",
            "Training Progress: \tEpoch 38 [0/1692 (0.00%)]\t\tLoss: 0.77489\n",
            "Training Progress: \tEpoch 38 [320/1692 (18.87%)]\t\tLoss: 1.17312\n",
            "Training Progress: \tEpoch 38 [640/1692 (37.74%)]\t\tLoss: 0.98371\n",
            "Training Progress: \tEpoch 38 [960/1692 (56.60%)]\t\tLoss: 0.82078\n",
            "Training Progress: \tEpoch 38 [1280/1692 (75.47%)]\t\tLoss: 1.01123\n",
            "Training Progress: \tEpoch 38 [1600/1692 (94.34%)]\t\tLoss: 0.87143\n",
            "\tTrain loss: 0.02018, Accuracy: 1285/1692 (75.95%)\n",
            "\tValidation loss: 0.00264, Accuracy: 213/423 (50.35%)\n",
            "\tTest loss: 0.00259, Accuracy: 239/443 (53.95%)\n",
            "\n",
            "Training Progress: \tEpoch 39 [0/1692 (0.00%)]\t\tLoss: 0.61359\n",
            "Training Progress: \tEpoch 39 [320/1692 (18.87%)]\t\tLoss: 1.02856\n",
            "Training Progress: \tEpoch 39 [640/1692 (37.74%)]\t\tLoss: 0.95289\n",
            "Training Progress: \tEpoch 39 [960/1692 (56.60%)]\t\tLoss: 0.84047\n",
            "Training Progress: \tEpoch 39 [1280/1692 (75.47%)]\t\tLoss: 0.74731\n",
            "Training Progress: \tEpoch 39 [1600/1692 (94.34%)]\t\tLoss: 0.84300\n",
            "\tTrain loss: 0.02044, Accuracy: 1221/1692 (72.16%)\n",
            "\tValidation loss: 0.00276, Accuracy: 209/423 (49.41%)\n",
            "\tTest loss: 0.00265, Accuracy: 227/443 (51.24%)\n",
            "\n",
            "Training Progress: \tEpoch 40 [0/1692 (0.00%)]\t\tLoss: 0.79607\n",
            "Training Progress: \tEpoch 40 [320/1692 (18.87%)]\t\tLoss: 1.13155\n",
            "Training Progress: \tEpoch 40 [640/1692 (37.74%)]\t\tLoss: 0.91338\n",
            "Training Progress: \tEpoch 40 [960/1692 (56.60%)]\t\tLoss: 0.99144\n",
            "Training Progress: \tEpoch 40 [1280/1692 (75.47%)]\t\tLoss: 1.15454\n",
            "Training Progress: \tEpoch 40 [1600/1692 (94.34%)]\t\tLoss: 0.79949\n",
            "\tTrain loss: 0.02036, Accuracy: 1238/1692 (73.17%)\n",
            "\tValidation loss: 0.00272, Accuracy: 216/423 (51.06%)\n",
            "\tTest loss: 0.00254, Accuracy: 237/443 (53.50%)\n",
            "\n",
            "Training Progress: \tEpoch 41 [0/1692 (0.00%)]\t\tLoss: 0.76092\n",
            "Training Progress: \tEpoch 41 [320/1692 (18.87%)]\t\tLoss: 1.08296\n",
            "Training Progress: \tEpoch 41 [640/1692 (37.74%)]\t\tLoss: 0.92560\n",
            "Training Progress: \tEpoch 41 [960/1692 (56.60%)]\t\tLoss: 0.71614\n",
            "Training Progress: \tEpoch 41 [1280/1692 (75.47%)]\t\tLoss: 0.70424\n",
            "Training Progress: \tEpoch 41 [1600/1692 (94.34%)]\t\tLoss: 0.78422\n",
            "\tTrain loss: 0.02101, Accuracy: 1227/1692 (72.52%)\n",
            "\tValidation loss: 0.00283, Accuracy: 215/423 (50.83%)\n",
            "\tTest loss: 0.00270, Accuracy: 228/443 (51.47%)\n",
            "\n",
            "Training Progress: \tEpoch 42 [0/1692 (0.00%)]\t\tLoss: 0.78192\n",
            "Training Progress: \tEpoch 42 [320/1692 (18.87%)]\t\tLoss: 0.78443\n",
            "Training Progress: \tEpoch 42 [640/1692 (37.74%)]\t\tLoss: 0.84790\n",
            "Training Progress: \tEpoch 42 [960/1692 (56.60%)]\t\tLoss: 0.87933\n",
            "Training Progress: \tEpoch 42 [1280/1692 (75.47%)]\t\tLoss: 0.64109\n",
            "Training Progress: \tEpoch 42 [1600/1692 (94.34%)]\t\tLoss: 0.85774\n",
            "\tTrain loss: 0.01909, Accuracy: 1300/1692 (76.83%)\n",
            "\tValidation loss: 0.00273, Accuracy: 221/423 (52.25%)\n",
            "\tTest loss: 0.00270, Accuracy: 230/443 (51.92%)\n",
            "\n",
            "Training Progress: \tEpoch 43 [0/1692 (0.00%)]\t\tLoss: 0.60849\n",
            "Training Progress: \tEpoch 43 [320/1692 (18.87%)]\t\tLoss: 1.04761\n",
            "Training Progress: \tEpoch 43 [640/1692 (37.74%)]\t\tLoss: 0.99037\n",
            "Training Progress: \tEpoch 43 [960/1692 (56.60%)]\t\tLoss: 0.81473\n",
            "Training Progress: \tEpoch 43 [1280/1692 (75.47%)]\t\tLoss: 0.66208\n",
            "Training Progress: \tEpoch 43 [1600/1692 (94.34%)]\t\tLoss: 0.77261\n",
            "\tTrain loss: 0.01851, Accuracy: 1302/1692 (76.95%)\n",
            "\tValidation loss: 0.00276, Accuracy: 218/423 (51.54%)\n",
            "\tTest loss: 0.00272, Accuracy: 236/443 (53.27%)\n",
            "\n",
            "Training Progress: \tEpoch 44 [0/1692 (0.00%)]\t\tLoss: 0.76869\n",
            "Training Progress: \tEpoch 44 [320/1692 (18.87%)]\t\tLoss: 1.08777\n",
            "Training Progress: \tEpoch 44 [640/1692 (37.74%)]\t\tLoss: 0.86237\n",
            "Training Progress: \tEpoch 44 [960/1692 (56.60%)]\t\tLoss: 0.93420\n",
            "Training Progress: \tEpoch 44 [1280/1692 (75.47%)]\t\tLoss: 0.74396\n",
            "Training Progress: \tEpoch 44 [1600/1692 (94.34%)]\t\tLoss: 0.93593\n",
            "\tTrain loss: 0.01775, Accuracy: 1355/1692 (80.08%)\n",
            "\tValidation loss: 0.00267, Accuracy: 222/423 (52.48%)\n",
            "\tTest loss: 0.00263, Accuracy: 230/443 (51.92%)\n",
            "\n",
            "Training Progress: \tEpoch 45 [0/1692 (0.00%)]\t\tLoss: 0.73072\n",
            "Training Progress: \tEpoch 45 [320/1692 (18.87%)]\t\tLoss: 0.93253\n",
            "Training Progress: \tEpoch 45 [640/1692 (37.74%)]\t\tLoss: 0.97148\n",
            "Training Progress: \tEpoch 45 [960/1692 (56.60%)]\t\tLoss: 0.83928\n",
            "Training Progress: \tEpoch 45 [1280/1692 (75.47%)]\t\tLoss: 1.00571\n",
            "Training Progress: \tEpoch 45 [1600/1692 (94.34%)]\t\tLoss: 0.75469\n",
            "\tTrain loss: 0.01852, Accuracy: 1304/1692 (77.07%)\n",
            "\tValidation loss: 0.00281, Accuracy: 202/423 (47.75%)\n",
            "\tTest loss: 0.00272, Accuracy: 231/443 (52.14%)\n",
            "\n",
            "Training Progress: \tEpoch 46 [0/1692 (0.00%)]\t\tLoss: 0.62280\n",
            "Training Progress: \tEpoch 46 [320/1692 (18.87%)]\t\tLoss: 0.75648\n",
            "Training Progress: \tEpoch 46 [640/1692 (37.74%)]\t\tLoss: 0.84532\n",
            "Training Progress: \tEpoch 46 [960/1692 (56.60%)]\t\tLoss: 0.85005\n",
            "Training Progress: \tEpoch 46 [1280/1692 (75.47%)]\t\tLoss: 0.77840\n",
            "Training Progress: \tEpoch 46 [1600/1692 (94.34%)]\t\tLoss: 0.88300\n",
            "\tTrain loss: 0.01753, Accuracy: 1331/1692 (78.66%)\n",
            "\tValidation loss: 0.00281, Accuracy: 221/423 (52.25%)\n",
            "\tTest loss: 0.00270, Accuracy: 228/443 (51.47%)\n",
            "\n",
            "Training Progress: \tEpoch 47 [0/1692 (0.00%)]\t\tLoss: 0.80064\n",
            "Training Progress: \tEpoch 47 [320/1692 (18.87%)]\t\tLoss: 0.75268\n",
            "Training Progress: \tEpoch 47 [640/1692 (37.74%)]\t\tLoss: 0.99326\n",
            "Training Progress: \tEpoch 47 [960/1692 (56.60%)]\t\tLoss: 0.70883\n",
            "Training Progress: \tEpoch 47 [1280/1692 (75.47%)]\t\tLoss: 0.62157\n",
            "Training Progress: \tEpoch 47 [1600/1692 (94.34%)]\t\tLoss: 0.76417\n",
            "\tTrain loss: 0.01599, Accuracy: 1368/1692 (80.85%)\n",
            "\tValidation loss: 0.00277, Accuracy: 221/423 (52.25%)\n",
            "\tTest loss: 0.00269, Accuracy: 232/443 (52.37%)\n",
            "\n",
            "Training Progress: \tEpoch 48 [0/1692 (0.00%)]\t\tLoss: 0.75583\n",
            "Training Progress: \tEpoch 48 [320/1692 (18.87%)]\t\tLoss: 0.79816\n",
            "Training Progress: \tEpoch 48 [640/1692 (37.74%)]\t\tLoss: 0.69662\n",
            "Training Progress: \tEpoch 48 [960/1692 (56.60%)]\t\tLoss: 0.77394\n",
            "Training Progress: \tEpoch 48 [1280/1692 (75.47%)]\t\tLoss: 0.95538\n",
            "Training Progress: \tEpoch 48 [1600/1692 (94.34%)]\t\tLoss: 0.98717\n",
            "\tTrain loss: 0.01821, Accuracy: 1277/1692 (75.47%)\n",
            "\tValidation loss: 0.00303, Accuracy: 203/423 (47.99%)\n",
            "\tTest loss: 0.00289, Accuracy: 222/443 (50.11%)\n",
            "\n",
            "Training Progress: \tEpoch 49 [0/1692 (0.00%)]\t\tLoss: 0.79327\n",
            "Training Progress: \tEpoch 49 [320/1692 (18.87%)]\t\tLoss: 0.83092\n",
            "Training Progress: \tEpoch 49 [640/1692 (37.74%)]\t\tLoss: 0.88586\n",
            "Training Progress: \tEpoch 49 [960/1692 (56.60%)]\t\tLoss: 0.86894\n",
            "Training Progress: \tEpoch 49 [1280/1692 (75.47%)]\t\tLoss: 0.74410\n",
            "Training Progress: \tEpoch 49 [1600/1692 (94.34%)]\t\tLoss: 0.78596\n",
            "\tTrain loss: 0.01454, Accuracy: 1389/1692 (82.09%)\n",
            "\tValidation loss: 0.00280, Accuracy: 220/423 (52.01%)\n",
            "\tTest loss: 0.00273, Accuracy: 232/443 (52.37%)\n",
            "\n",
            "Training Progress: \tEpoch 50 [0/1692 (0.00%)]\t\tLoss: 0.78304\n",
            "Training Progress: \tEpoch 50 [320/1692 (18.87%)]\t\tLoss: 0.85230\n",
            "Training Progress: \tEpoch 50 [640/1692 (37.74%)]\t\tLoss: 0.72357\n",
            "Training Progress: \tEpoch 50 [960/1692 (56.60%)]\t\tLoss: 0.91960\n",
            "Training Progress: \tEpoch 50 [1280/1692 (75.47%)]\t\tLoss: 0.63049\n",
            "Training Progress: \tEpoch 50 [1600/1692 (94.34%)]\t\tLoss: 0.70311\n",
            "\tTrain loss: 0.01617, Accuracy: 1329/1692 (78.55%)\n",
            "\tValidation loss: 0.00295, Accuracy: 207/423 (48.94%)\n",
            "\tTest loss: 0.00273, Accuracy: 237/443 (53.50%)\n",
            "\n",
            "Training Progress: \tEpoch 51 [0/1692 (0.00%)]\t\tLoss: 0.52848\n",
            "Training Progress: \tEpoch 51 [320/1692 (18.87%)]\t\tLoss: 0.79319\n",
            "Training Progress: \tEpoch 51 [640/1692 (37.74%)]\t\tLoss: 0.68390\n",
            "Training Progress: \tEpoch 51 [960/1692 (56.60%)]\t\tLoss: 0.78819\n",
            "Training Progress: \tEpoch 51 [1280/1692 (75.47%)]\t\tLoss: 0.66175\n",
            "Training Progress: \tEpoch 51 [1600/1692 (94.34%)]\t\tLoss: 0.61349\n",
            "\tTrain loss: 0.01519, Accuracy: 1359/1692 (80.32%)\n",
            "\tValidation loss: 0.00298, Accuracy: 203/423 (47.99%)\n",
            "\tTest loss: 0.00286, Accuracy: 224/443 (50.56%)\n",
            "\n",
            "Training Progress: \tEpoch 52 [0/1692 (0.00%)]\t\tLoss: 0.75509\n",
            "Training Progress: \tEpoch 52 [320/1692 (18.87%)]\t\tLoss: 1.03722\n",
            "Training Progress: \tEpoch 52 [640/1692 (37.74%)]\t\tLoss: 0.76479\n",
            "Training Progress: \tEpoch 52 [960/1692 (56.60%)]\t\tLoss: 0.60614\n",
            "Training Progress: \tEpoch 52 [1280/1692 (75.47%)]\t\tLoss: 0.48079\n",
            "Training Progress: \tEpoch 52 [1600/1692 (94.34%)]\t\tLoss: 0.52616\n",
            "\tTrain loss: 0.01503, Accuracy: 1380/1692 (81.56%)\n",
            "\tValidation loss: 0.00294, Accuracy: 210/423 (49.65%)\n",
            "\tTest loss: 0.00288, Accuracy: 228/443 (51.47%)\n",
            "\n",
            "Training Progress: \tEpoch 53 [0/1692 (0.00%)]\t\tLoss: 0.78056\n",
            "Training Progress: \tEpoch 53 [320/1692 (18.87%)]\t\tLoss: 0.96611\n",
            "Training Progress: \tEpoch 53 [640/1692 (37.74%)]\t\tLoss: 0.82484\n",
            "Training Progress: \tEpoch 53 [960/1692 (56.60%)]\t\tLoss: 0.79148\n",
            "Training Progress: \tEpoch 53 [1280/1692 (75.47%)]\t\tLoss: 0.62198\n",
            "Training Progress: \tEpoch 53 [1600/1692 (94.34%)]\t\tLoss: 0.92500\n",
            "\tTrain loss: 0.01522, Accuracy: 1385/1692 (81.86%)\n",
            "\tValidation loss: 0.00278, Accuracy: 214/423 (50.59%)\n",
            "\tTest loss: 0.00275, Accuracy: 231/443 (52.14%)\n",
            "\n",
            "Training Progress: \tEpoch 54 [0/1692 (0.00%)]\t\tLoss: 0.69277\n",
            "Training Progress: \tEpoch 54 [320/1692 (18.87%)]\t\tLoss: 0.86188\n",
            "Training Progress: \tEpoch 54 [640/1692 (37.74%)]\t\tLoss: 0.51178\n",
            "Training Progress: \tEpoch 54 [960/1692 (56.60%)]\t\tLoss: 0.71874\n",
            "Training Progress: \tEpoch 54 [1280/1692 (75.47%)]\t\tLoss: 0.54875\n",
            "Training Progress: \tEpoch 54 [1600/1692 (94.34%)]\t\tLoss: 0.61767\n",
            "\tTrain loss: 0.01484, Accuracy: 1389/1692 (82.09%)\n",
            "\tValidation loss: 0.00300, Accuracy: 205/423 (48.46%)\n",
            "\tTest loss: 0.00293, Accuracy: 225/443 (50.79%)\n",
            "\n",
            "Training Progress: \tEpoch 55 [0/1692 (0.00%)]\t\tLoss: 0.61221\n",
            "Training Progress: \tEpoch 55 [320/1692 (18.87%)]\t\tLoss: 0.88795\n",
            "Training Progress: \tEpoch 55 [640/1692 (37.74%)]\t\tLoss: 0.84670\n",
            "Training Progress: \tEpoch 55 [960/1692 (56.60%)]\t\tLoss: 0.74587\n",
            "Training Progress: \tEpoch 55 [1280/1692 (75.47%)]\t\tLoss: 0.61000\n",
            "Training Progress: \tEpoch 55 [1600/1692 (94.34%)]\t\tLoss: 0.76066\n",
            "\tTrain loss: 0.01393, Accuracy: 1408/1692 (83.22%)\n",
            "\tValidation loss: 0.00298, Accuracy: 209/423 (49.41%)\n",
            "\tTest loss: 0.00300, Accuracy: 226/443 (51.02%)\n",
            "\n",
            "Training Progress: \tEpoch 56 [0/1692 (0.00%)]\t\tLoss: 0.79564\n",
            "Training Progress: \tEpoch 56 [320/1692 (18.87%)]\t\tLoss: 0.87274\n",
            "Training Progress: \tEpoch 56 [640/1692 (37.74%)]\t\tLoss: 0.89904\n",
            "Training Progress: \tEpoch 56 [960/1692 (56.60%)]\t\tLoss: 0.46874\n",
            "Training Progress: \tEpoch 56 [1280/1692 (75.47%)]\t\tLoss: 0.71133\n",
            "Training Progress: \tEpoch 56 [1600/1692 (94.34%)]\t\tLoss: 0.79251\n",
            "\tTrain loss: 0.01442, Accuracy: 1389/1692 (82.09%)\n",
            "\tValidation loss: 0.00302, Accuracy: 213/423 (50.35%)\n",
            "\tTest loss: 0.00299, Accuracy: 227/443 (51.24%)\n",
            "\n",
            "Training Progress: \tEpoch 57 [0/1692 (0.00%)]\t\tLoss: 0.60309\n",
            "Training Progress: \tEpoch 57 [320/1692 (18.87%)]\t\tLoss: 1.06648\n",
            "Training Progress: \tEpoch 57 [640/1692 (37.74%)]\t\tLoss: 0.78283\n",
            "Training Progress: \tEpoch 57 [960/1692 (56.60%)]\t\tLoss: 0.71345\n",
            "Training Progress: \tEpoch 57 [1280/1692 (75.47%)]\t\tLoss: 0.62514\n",
            "Training Progress: \tEpoch 57 [1600/1692 (94.34%)]\t\tLoss: 0.71842\n",
            "\tTrain loss: 0.01223, Accuracy: 1452/1692 (85.82%)\n",
            "\tValidation loss: 0.00287, Accuracy: 216/423 (51.06%)\n",
            "\tTest loss: 0.00293, Accuracy: 222/443 (50.11%)\n",
            "\n",
            "Training Progress: \tEpoch 58 [0/1692 (0.00%)]\t\tLoss: 0.53082\n",
            "Training Progress: \tEpoch 58 [320/1692 (18.87%)]\t\tLoss: 0.81784\n",
            "Training Progress: \tEpoch 58 [640/1692 (37.74%)]\t\tLoss: 0.79129\n",
            "Training Progress: \tEpoch 58 [960/1692 (56.60%)]\t\tLoss: 0.56997\n",
            "Training Progress: \tEpoch 58 [1280/1692 (75.47%)]\t\tLoss: 0.50433\n",
            "Training Progress: \tEpoch 58 [1600/1692 (94.34%)]\t\tLoss: 0.64002\n",
            "\tTrain loss: 0.01128, Accuracy: 1490/1692 (88.06%)\n",
            "\tValidation loss: 0.00303, Accuracy: 213/423 (50.35%)\n",
            "\tTest loss: 0.00309, Accuracy: 221/443 (49.89%)\n",
            "\n",
            "Training Progress: \tEpoch 59 [0/1692 (0.00%)]\t\tLoss: 0.69641\n",
            "Training Progress: \tEpoch 59 [320/1692 (18.87%)]\t\tLoss: 0.88198\n",
            "Training Progress: \tEpoch 59 [640/1692 (37.74%)]\t\tLoss: 1.00194\n",
            "Training Progress: \tEpoch 59 [960/1692 (56.60%)]\t\tLoss: 0.72461\n",
            "Training Progress: \tEpoch 59 [1280/1692 (75.47%)]\t\tLoss: 0.64617\n",
            "Training Progress: \tEpoch 59 [1600/1692 (94.34%)]\t\tLoss: 0.64112\n",
            "\tTrain loss: 0.01146, Accuracy: 1485/1692 (87.77%)\n",
            "\tValidation loss: 0.00285, Accuracy: 223/423 (52.72%)\n",
            "\tTest loss: 0.00280, Accuracy: 236/443 (53.27%)\n",
            "\n",
            "Training Progress: \tEpoch 60 [0/1692 (0.00%)]\t\tLoss: 0.63013\n",
            "Training Progress: \tEpoch 60 [320/1692 (18.87%)]\t\tLoss: 0.96530\n",
            "Training Progress: \tEpoch 60 [640/1692 (37.74%)]\t\tLoss: 0.56920\n",
            "Training Progress: \tEpoch 60 [960/1692 (56.60%)]\t\tLoss: 0.64524\n",
            "Training Progress: \tEpoch 60 [1280/1692 (75.47%)]\t\tLoss: 0.69267\n",
            "Training Progress: \tEpoch 60 [1600/1692 (94.34%)]\t\tLoss: 0.92788\n",
            "\tTrain loss: 0.01128, Accuracy: 1486/1692 (87.83%)\n",
            "\tValidation loss: 0.00295, Accuracy: 220/423 (52.01%)\n",
            "\tTest loss: 0.00295, Accuracy: 228/443 (51.47%)\n",
            "\n",
            "Training Progress: \tEpoch 61 [0/1692 (0.00%)]\t\tLoss: 0.46677\n",
            "Training Progress: \tEpoch 61 [320/1692 (18.87%)]\t\tLoss: 0.80205\n",
            "Training Progress: \tEpoch 61 [640/1692 (37.74%)]\t\tLoss: 0.60581\n",
            "Training Progress: \tEpoch 61 [960/1692 (56.60%)]\t\tLoss: 0.46502\n",
            "Training Progress: \tEpoch 61 [1280/1692 (75.47%)]\t\tLoss: 0.57264\n",
            "Training Progress: \tEpoch 61 [1600/1692 (94.34%)]\t\tLoss: 0.69540\n",
            "\tTrain loss: 0.01022, Accuracy: 1517/1692 (89.66%)\n",
            "\tValidation loss: 0.00290, Accuracy: 223/423 (52.72%)\n",
            "\tTest loss: 0.00293, Accuracy: 232/443 (52.37%)\n",
            "\n",
            "Training Progress: \tEpoch 62 [0/1692 (0.00%)]\t\tLoss: 0.63078\n",
            "Training Progress: \tEpoch 62 [320/1692 (18.87%)]\t\tLoss: 0.65718\n",
            "Training Progress: \tEpoch 62 [640/1692 (37.74%)]\t\tLoss: 0.87604\n",
            "Training Progress: \tEpoch 62 [960/1692 (56.60%)]\t\tLoss: 0.56375\n",
            "Training Progress: \tEpoch 62 [1280/1692 (75.47%)]\t\tLoss: 0.52917\n",
            "Training Progress: \tEpoch 62 [1600/1692 (94.34%)]\t\tLoss: 0.82698\n",
            "\tTrain loss: 0.01092, Accuracy: 1497/1692 (88.48%)\n",
            "\tValidation loss: 0.00291, Accuracy: 218/423 (51.54%)\n",
            "\tTest loss: 0.00292, Accuracy: 221/443 (49.89%)\n",
            "\n",
            "Training Progress: \tEpoch 63 [0/1692 (0.00%)]\t\tLoss: 0.46166\n",
            "Training Progress: \tEpoch 63 [320/1692 (18.87%)]\t\tLoss: 0.60079\n",
            "Training Progress: \tEpoch 63 [640/1692 (37.74%)]\t\tLoss: 0.82086\n",
            "Training Progress: \tEpoch 63 [960/1692 (56.60%)]\t\tLoss: 0.63700\n",
            "Training Progress: \tEpoch 63 [1280/1692 (75.47%)]\t\tLoss: 0.35394\n",
            "Training Progress: \tEpoch 63 [1600/1692 (94.34%)]\t\tLoss: 0.65871\n",
            "\tTrain loss: 0.01012, Accuracy: 1493/1692 (88.24%)\n",
            "\tValidation loss: 0.00320, Accuracy: 215/423 (50.83%)\n",
            "\tTest loss: 0.00306, Accuracy: 225/443 (50.79%)\n",
            "\n",
            "Training Progress: \tEpoch 64 [0/1692 (0.00%)]\t\tLoss: 0.52494\n",
            "Training Progress: \tEpoch 64 [320/1692 (18.87%)]\t\tLoss: 0.79965\n",
            "Training Progress: \tEpoch 64 [640/1692 (37.74%)]\t\tLoss: 0.70458\n",
            "Training Progress: \tEpoch 64 [960/1692 (56.60%)]\t\tLoss: 0.75949\n",
            "Training Progress: \tEpoch 64 [1280/1692 (75.47%)]\t\tLoss: 0.47830\n",
            "Training Progress: \tEpoch 64 [1600/1692 (94.34%)]\t\tLoss: 0.69112\n",
            "\tTrain loss: 0.00990, Accuracy: 1524/1692 (90.07%)\n",
            "\tValidation loss: 0.00314, Accuracy: 220/423 (52.01%)\n",
            "\tTest loss: 0.00320, Accuracy: 213/443 (48.08%)\n",
            "\n",
            "Training Progress: \tEpoch 65 [0/1692 (0.00%)]\t\tLoss: 0.59042\n",
            "Training Progress: \tEpoch 65 [320/1692 (18.87%)]\t\tLoss: 0.49827\n",
            "Training Progress: \tEpoch 65 [640/1692 (37.74%)]\t\tLoss: 0.71498\n",
            "Training Progress: \tEpoch 65 [960/1692 (56.60%)]\t\tLoss: 0.70621\n",
            "Training Progress: \tEpoch 65 [1280/1692 (75.47%)]\t\tLoss: 0.54842\n",
            "Training Progress: \tEpoch 65 [1600/1692 (94.34%)]\t\tLoss: 0.65970\n",
            "\tTrain loss: 0.01051, Accuracy: 1491/1692 (88.12%)\n",
            "\tValidation loss: 0.00303, Accuracy: 229/423 (54.14%)\n",
            "\tTest loss: 0.00311, Accuracy: 216/443 (48.76%)\n",
            "\n",
            "Training Progress: \tEpoch 66 [0/1692 (0.00%)]\t\tLoss: 0.40074\n",
            "Training Progress: \tEpoch 66 [320/1692 (18.87%)]\t\tLoss: 0.60696\n",
            "Training Progress: \tEpoch 66 [640/1692 (37.74%)]\t\tLoss: 0.73952\n",
            "Training Progress: \tEpoch 66 [960/1692 (56.60%)]\t\tLoss: 0.65014\n",
            "Training Progress: \tEpoch 66 [1280/1692 (75.47%)]\t\tLoss: 0.66417\n",
            "Training Progress: \tEpoch 66 [1600/1692 (94.34%)]\t\tLoss: 0.40914\n",
            "\tTrain loss: 0.01080, Accuracy: 1478/1692 (87.35%)\n",
            "\tValidation loss: 0.00336, Accuracy: 211/423 (49.88%)\n",
            "\tTest loss: 0.00337, Accuracy: 209/443 (47.18%)\n",
            "\n",
            "Training Progress: \tEpoch 67 [0/1692 (0.00%)]\t\tLoss: 0.42360\n",
            "Training Progress: \tEpoch 67 [320/1692 (18.87%)]\t\tLoss: 0.63600\n",
            "Training Progress: \tEpoch 67 [640/1692 (37.74%)]\t\tLoss: 0.68047\n",
            "Training Progress: \tEpoch 67 [960/1692 (56.60%)]\t\tLoss: 0.56610\n",
            "Training Progress: \tEpoch 67 [1280/1692 (75.47%)]\t\tLoss: 0.50064\n",
            "Training Progress: \tEpoch 67 [1600/1692 (94.34%)]\t\tLoss: 0.59155\n",
            "\tTrain loss: 0.00999, Accuracy: 1510/1692 (89.24%)\n",
            "\tValidation loss: 0.00325, Accuracy: 219/423 (51.77%)\n",
            "\tTest loss: 0.00319, Accuracy: 222/443 (50.11%)\n",
            "\n",
            "Training Progress: \tEpoch 68 [0/1692 (0.00%)]\t\tLoss: 0.59285\n",
            "Training Progress: \tEpoch 68 [320/1692 (18.87%)]\t\tLoss: 0.66225\n",
            "Training Progress: \tEpoch 68 [640/1692 (37.74%)]\t\tLoss: 0.51268\n",
            "Training Progress: \tEpoch 68 [960/1692 (56.60%)]\t\tLoss: 0.79049\n",
            "Training Progress: \tEpoch 68 [1280/1692 (75.47%)]\t\tLoss: 0.66874\n",
            "Training Progress: \tEpoch 68 [1600/1692 (94.34%)]\t\tLoss: 0.49908\n",
            "\tTrain loss: 0.01218, Accuracy: 1450/1692 (85.70%)\n",
            "\tValidation loss: 0.00332, Accuracy: 214/423 (50.59%)\n",
            "\tTest loss: 0.00326, Accuracy: 217/443 (48.98%)\n",
            "\n",
            "Training Progress: \tEpoch 69 [0/1692 (0.00%)]\t\tLoss: 0.61460\n",
            "Training Progress: \tEpoch 69 [320/1692 (18.87%)]\t\tLoss: 0.53765\n",
            "Training Progress: \tEpoch 69 [640/1692 (37.74%)]\t\tLoss: 0.57087\n",
            "Training Progress: \tEpoch 69 [960/1692 (56.60%)]\t\tLoss: 0.60278\n",
            "Training Progress: \tEpoch 69 [1280/1692 (75.47%)]\t\tLoss: 0.55060\n",
            "Training Progress: \tEpoch 69 [1600/1692 (94.34%)]\t\tLoss: 0.82447\n",
            "\tTrain loss: 0.00907, Accuracy: 1526/1692 (90.19%)\n",
            "\tValidation loss: 0.00304, Accuracy: 229/423 (54.14%)\n",
            "\tTest loss: 0.00304, Accuracy: 226/443 (51.02%)\n",
            "\n",
            "Training Progress: \tEpoch 70 [0/1692 (0.00%)]\t\tLoss: 0.38601\n",
            "Training Progress: \tEpoch 70 [320/1692 (18.87%)]\t\tLoss: 0.57573\n",
            "Training Progress: \tEpoch 70 [640/1692 (37.74%)]\t\tLoss: 0.64585\n",
            "Training Progress: \tEpoch 70 [960/1692 (56.60%)]\t\tLoss: 0.59731\n",
            "Training Progress: \tEpoch 70 [1280/1692 (75.47%)]\t\tLoss: 0.69154\n",
            "Training Progress: \tEpoch 70 [1600/1692 (94.34%)]\t\tLoss: 0.83776\n",
            "\tTrain loss: 0.00927, Accuracy: 1508/1692 (89.13%)\n",
            "\tValidation loss: 0.00337, Accuracy: 220/423 (52.01%)\n",
            "\tTest loss: 0.00332, Accuracy: 211/443 (47.63%)\n",
            "\n",
            "Training Progress: \tEpoch 71 [0/1692 (0.00%)]\t\tLoss: 0.64506\n",
            "Training Progress: \tEpoch 71 [320/1692 (18.87%)]\t\tLoss: 0.48842\n",
            "Training Progress: \tEpoch 71 [640/1692 (37.74%)]\t\tLoss: 0.70118\n",
            "Training Progress: \tEpoch 71 [960/1692 (56.60%)]\t\tLoss: 0.71013\n",
            "Training Progress: \tEpoch 71 [1280/1692 (75.47%)]\t\tLoss: 0.27349\n",
            "Training Progress: \tEpoch 71 [1600/1692 (94.34%)]\t\tLoss: 0.66241\n",
            "\tTrain loss: 0.00723, Accuracy: 1578/1692 (93.26%)\n",
            "\tValidation loss: 0.00305, Accuracy: 235/423 (55.56%)\n",
            "\tTest loss: 0.00303, Accuracy: 221/443 (49.89%)\n",
            "\n",
            "Training Progress: \tEpoch 72 [0/1692 (0.00%)]\t\tLoss: 0.50119\n",
            "Training Progress: \tEpoch 72 [320/1692 (18.87%)]\t\tLoss: 0.55699\n",
            "Training Progress: \tEpoch 72 [640/1692 (37.74%)]\t\tLoss: 0.55725\n",
            "Training Progress: \tEpoch 72 [960/1692 (56.60%)]\t\tLoss: 0.73861\n",
            "Training Progress: \tEpoch 72 [1280/1692 (75.47%)]\t\tLoss: 0.62121\n",
            "Training Progress: \tEpoch 72 [1600/1692 (94.34%)]\t\tLoss: 0.65894\n",
            "\tTrain loss: 0.00805, Accuracy: 1547/1692 (91.43%)\n",
            "\tValidation loss: 0.00320, Accuracy: 229/423 (54.14%)\n",
            "\tTest loss: 0.00306, Accuracy: 231/443 (52.14%)\n",
            "\n",
            "Training Progress: \tEpoch 73 [0/1692 (0.00%)]\t\tLoss: 0.43303\n",
            "Training Progress: \tEpoch 73 [320/1692 (18.87%)]\t\tLoss: 0.46599\n",
            "Training Progress: \tEpoch 73 [640/1692 (37.74%)]\t\tLoss: 0.80496\n",
            "Training Progress: \tEpoch 73 [960/1692 (56.60%)]\t\tLoss: 0.63891\n",
            "Training Progress: \tEpoch 73 [1280/1692 (75.47%)]\t\tLoss: 0.60748\n",
            "Training Progress: \tEpoch 73 [1600/1692 (94.34%)]\t\tLoss: 0.56828\n",
            "\tTrain loss: 0.00837, Accuracy: 1539/1692 (90.96%)\n",
            "\tValidation loss: 0.00339, Accuracy: 224/423 (52.96%)\n",
            "\tTest loss: 0.00322, Accuracy: 221/443 (49.89%)\n",
            "\n",
            "Training Progress: \tEpoch 74 [0/1692 (0.00%)]\t\tLoss: 0.52277\n",
            "Training Progress: \tEpoch 74 [320/1692 (18.87%)]\t\tLoss: 0.70369\n",
            "Training Progress: \tEpoch 74 [640/1692 (37.74%)]\t\tLoss: 0.67367\n",
            "Training Progress: \tEpoch 74 [960/1692 (56.60%)]\t\tLoss: 0.58880\n",
            "Training Progress: \tEpoch 74 [1280/1692 (75.47%)]\t\tLoss: 0.40113\n",
            "Training Progress: \tEpoch 74 [1600/1692 (94.34%)]\t\tLoss: 0.62904\n",
            "\tTrain loss: 0.00664, Accuracy: 1592/1692 (94.09%)\n",
            "\tValidation loss: 0.00321, Accuracy: 221/423 (52.25%)\n",
            "\tTest loss: 0.00323, Accuracy: 222/443 (50.11%)\n",
            "\n",
            "Training Progress: \tEpoch 75 [0/1692 (0.00%)]\t\tLoss: 0.45586\n",
            "Training Progress: \tEpoch 75 [320/1692 (18.87%)]\t\tLoss: 0.80291\n",
            "Training Progress: \tEpoch 75 [640/1692 (37.74%)]\t\tLoss: 0.60140\n",
            "Training Progress: \tEpoch 75 [960/1692 (56.60%)]\t\tLoss: 0.63992\n",
            "Training Progress: \tEpoch 75 [1280/1692 (75.47%)]\t\tLoss: 0.38897\n",
            "Training Progress: \tEpoch 75 [1600/1692 (94.34%)]\t\tLoss: 0.45814\n",
            "\tTrain loss: 0.00807, Accuracy: 1554/1692 (91.84%)\n",
            "\tValidation loss: 0.00350, Accuracy: 215/423 (50.83%)\n",
            "\tTest loss: 0.00339, Accuracy: 211/443 (47.63%)\n",
            "\n",
            "Training Progress: \tEpoch 76 [0/1692 (0.00%)]\t\tLoss: 0.46149\n",
            "Training Progress: \tEpoch 76 [320/1692 (18.87%)]\t\tLoss: 0.65701\n",
            "Training Progress: \tEpoch 76 [640/1692 (37.74%)]\t\tLoss: 0.66410\n",
            "Training Progress: \tEpoch 76 [960/1692 (56.60%)]\t\tLoss: 0.74864\n",
            "Training Progress: \tEpoch 76 [1280/1692 (75.47%)]\t\tLoss: 0.60762\n",
            "Training Progress: \tEpoch 76 [1600/1692 (94.34%)]\t\tLoss: 0.63300\n",
            "\tTrain loss: 0.00611, Accuracy: 1600/1692 (94.56%)\n",
            "\tValidation loss: 0.00334, Accuracy: 227/423 (53.66%)\n",
            "\tTest loss: 0.00342, Accuracy: 217/443 (48.98%)\n",
            "\n",
            "Training Progress: \tEpoch 77 [0/1692 (0.00%)]\t\tLoss: 0.36353\n",
            "Training Progress: \tEpoch 77 [320/1692 (18.87%)]\t\tLoss: 0.80787\n",
            "Training Progress: \tEpoch 77 [640/1692 (37.74%)]\t\tLoss: 0.91242\n",
            "Training Progress: \tEpoch 77 [960/1692 (56.60%)]\t\tLoss: 0.50285\n",
            "Training Progress: \tEpoch 77 [1280/1692 (75.47%)]\t\tLoss: 0.69326\n",
            "Training Progress: \tEpoch 77 [1600/1692 (94.34%)]\t\tLoss: 0.65018\n",
            "\tTrain loss: 0.00682, Accuracy: 1601/1692 (94.62%)\n",
            "\tValidation loss: 0.00313, Accuracy: 225/423 (53.19%)\n",
            "\tTest loss: 0.00313, Accuracy: 214/443 (48.31%)\n",
            "\n",
            "Training Progress: \tEpoch 78 [0/1692 (0.00%)]\t\tLoss: 0.51871\n",
            "Training Progress: \tEpoch 78 [320/1692 (18.87%)]\t\tLoss: 0.71644\n",
            "Training Progress: \tEpoch 78 [640/1692 (37.74%)]\t\tLoss: 0.48422\n",
            "Training Progress: \tEpoch 78 [960/1692 (56.60%)]\t\tLoss: 0.54300\n",
            "Training Progress: \tEpoch 78 [1280/1692 (75.47%)]\t\tLoss: 0.53471\n",
            "Training Progress: \tEpoch 78 [1600/1692 (94.34%)]\t\tLoss: 0.49993\n",
            "\tTrain loss: 0.00638, Accuracy: 1595/1692 (94.27%)\n",
            "\tValidation loss: 0.00297, Accuracy: 230/423 (54.37%)\n",
            "\tTest loss: 0.00317, Accuracy: 230/443 (51.92%)\n",
            "\n",
            "Training Progress: \tEpoch 79 [0/1692 (0.00%)]\t\tLoss: 0.25020\n",
            "Training Progress: \tEpoch 79 [320/1692 (18.87%)]\t\tLoss: 0.43812\n",
            "Training Progress: \tEpoch 79 [640/1692 (37.74%)]\t\tLoss: 0.69034\n",
            "Training Progress: \tEpoch 79 [960/1692 (56.60%)]\t\tLoss: 0.43759\n",
            "Training Progress: \tEpoch 79 [1280/1692 (75.47%)]\t\tLoss: 0.33622\n",
            "Training Progress: \tEpoch 79 [1600/1692 (94.34%)]\t\tLoss: 0.46175\n",
            "\tTrain loss: 0.00742, Accuracy: 1551/1692 (91.67%)\n",
            "\tValidation loss: 0.00328, Accuracy: 227/423 (53.66%)\n",
            "\tTest loss: 0.00338, Accuracy: 213/443 (48.08%)\n",
            "\n",
            "Training Progress: \tEpoch 80 [0/1692 (0.00%)]\t\tLoss: 0.63629\n",
            "Training Progress: \tEpoch 80 [320/1692 (18.87%)]\t\tLoss: 0.55788\n",
            "Training Progress: \tEpoch 80 [640/1692 (37.74%)]\t\tLoss: 0.56846\n",
            "Training Progress: \tEpoch 80 [960/1692 (56.60%)]\t\tLoss: 0.36056\n",
            "Training Progress: \tEpoch 80 [1280/1692 (75.47%)]\t\tLoss: 0.33970\n",
            "Training Progress: \tEpoch 80 [1600/1692 (94.34%)]\t\tLoss: 0.53176\n",
            "\tTrain loss: 0.00827, Accuracy: 1542/1692 (91.13%)\n",
            "\tValidation loss: 0.00338, Accuracy: 207/423 (48.94%)\n",
            "\tTest loss: 0.00342, Accuracy: 211/443 (47.63%)\n",
            "\n",
            "Training Progress: \tEpoch 81 [0/1692 (0.00%)]\t\tLoss: 0.68407\n",
            "Training Progress: \tEpoch 81 [320/1692 (18.87%)]\t\tLoss: 0.45223\n",
            "Training Progress: \tEpoch 81 [640/1692 (37.74%)]\t\tLoss: 0.47942\n",
            "Training Progress: \tEpoch 81 [960/1692 (56.60%)]\t\tLoss: 0.67028\n",
            "Training Progress: \tEpoch 81 [1280/1692 (75.47%)]\t\tLoss: 0.38572\n",
            "Training Progress: \tEpoch 81 [1600/1692 (94.34%)]\t\tLoss: 0.53011\n",
            "\tTrain loss: 0.00780, Accuracy: 1548/1692 (91.49%)\n",
            "\tValidation loss: 0.00369, Accuracy: 215/423 (50.83%)\n",
            "\tTest loss: 0.00363, Accuracy: 215/443 (48.53%)\n",
            "\n",
            "Training Progress: \tEpoch 82 [0/1692 (0.00%)]\t\tLoss: 0.59189\n",
            "Training Progress: \tEpoch 82 [320/1692 (18.87%)]\t\tLoss: 0.82228\n",
            "Training Progress: \tEpoch 82 [640/1692 (37.74%)]\t\tLoss: 0.50935\n",
            "Training Progress: \tEpoch 82 [960/1692 (56.60%)]\t\tLoss: 0.67337\n",
            "Training Progress: \tEpoch 82 [1280/1692 (75.47%)]\t\tLoss: 0.70689\n",
            "Training Progress: \tEpoch 82 [1600/1692 (94.34%)]\t\tLoss: 0.40646\n",
            "\tTrain loss: 0.00610, Accuracy: 1595/1692 (94.27%)\n",
            "\tValidation loss: 0.00348, Accuracy: 228/423 (53.90%)\n",
            "\tTest loss: 0.00355, Accuracy: 216/443 (48.76%)\n",
            "\n",
            "Training Progress: \tEpoch 83 [0/1692 (0.00%)]\t\tLoss: 0.69512\n",
            "Training Progress: \tEpoch 83 [320/1692 (18.87%)]\t\tLoss: 0.55112\n",
            "Training Progress: \tEpoch 83 [640/1692 (37.74%)]\t\tLoss: 0.53057\n",
            "Training Progress: \tEpoch 83 [960/1692 (56.60%)]\t\tLoss: 0.35455\n",
            "Training Progress: \tEpoch 83 [1280/1692 (75.47%)]\t\tLoss: 0.34458\n",
            "Training Progress: \tEpoch 83 [1600/1692 (94.34%)]\t\tLoss: 0.62541\n",
            "\tTrain loss: 0.00559, Accuracy: 1605/1692 (94.86%)\n",
            "\tValidation loss: 0.00345, Accuracy: 221/423 (52.25%)\n",
            "\tTest loss: 0.00360, Accuracy: 217/443 (48.98%)\n",
            "\n",
            "Training Progress: \tEpoch 84 [0/1692 (0.00%)]\t\tLoss: 0.29761\n",
            "Training Progress: \tEpoch 84 [320/1692 (18.87%)]\t\tLoss: 0.83147\n",
            "Training Progress: \tEpoch 84 [640/1692 (37.74%)]\t\tLoss: 0.53512\n",
            "Training Progress: \tEpoch 84 [960/1692 (56.60%)]\t\tLoss: 0.56407\n",
            "Training Progress: \tEpoch 84 [1280/1692 (75.47%)]\t\tLoss: 0.42380\n",
            "Training Progress: \tEpoch 84 [1600/1692 (94.34%)]\t\tLoss: 0.66642\n",
            "\tTrain loss: 0.00564, Accuracy: 1610/1692 (95.15%)\n",
            "\tValidation loss: 0.00317, Accuracy: 227/423 (53.66%)\n",
            "\tTest loss: 0.00332, Accuracy: 216/443 (48.76%)\n",
            "\n",
            "Training Progress: \tEpoch 85 [0/1692 (0.00%)]\t\tLoss: 0.34427\n",
            "Training Progress: \tEpoch 85 [320/1692 (18.87%)]\t\tLoss: 0.65088\n",
            "Training Progress: \tEpoch 85 [640/1692 (37.74%)]\t\tLoss: 0.49474\n",
            "Training Progress: \tEpoch 85 [960/1692 (56.60%)]\t\tLoss: 0.34766\n",
            "Training Progress: \tEpoch 85 [1280/1692 (75.47%)]\t\tLoss: 0.53738\n",
            "Training Progress: \tEpoch 85 [1600/1692 (94.34%)]\t\tLoss: 0.49284\n",
            "\tTrain loss: 0.00662, Accuracy: 1578/1692 (93.26%)\n",
            "\tValidation loss: 0.00335, Accuracy: 227/423 (53.66%)\n",
            "\tTest loss: 0.00360, Accuracy: 207/443 (46.73%)\n",
            "\n",
            "Training Progress: \tEpoch 86 [0/1692 (0.00%)]\t\tLoss: 0.64439\n",
            "Training Progress: \tEpoch 86 [320/1692 (18.87%)]\t\tLoss: 0.59331\n",
            "Training Progress: \tEpoch 86 [640/1692 (37.74%)]\t\tLoss: 0.65384\n",
            "Training Progress: \tEpoch 86 [960/1692 (56.60%)]\t\tLoss: 0.47838\n",
            "Training Progress: \tEpoch 86 [1280/1692 (75.47%)]\t\tLoss: 0.34873\n",
            "Training Progress: \tEpoch 86 [1600/1692 (94.34%)]\t\tLoss: 0.33046\n",
            "\tTrain loss: 0.00621, Accuracy: 1585/1692 (93.68%)\n",
            "\tValidation loss: 0.00371, Accuracy: 217/423 (51.30%)\n",
            "\tTest loss: 0.00378, Accuracy: 207/443 (46.73%)\n",
            "\n",
            "Training Progress: \tEpoch 87 [0/1692 (0.00%)]\t\tLoss: 0.36215\n",
            "Training Progress: \tEpoch 87 [320/1692 (18.87%)]\t\tLoss: 0.36654\n",
            "Training Progress: \tEpoch 87 [640/1692 (37.74%)]\t\tLoss: 0.52632\n",
            "Training Progress: \tEpoch 87 [960/1692 (56.60%)]\t\tLoss: 0.39173\n",
            "Training Progress: \tEpoch 87 [1280/1692 (75.47%)]\t\tLoss: 0.53192\n",
            "Training Progress: \tEpoch 87 [1600/1692 (94.34%)]\t\tLoss: 0.45020\n",
            "\tTrain loss: 0.00551, Accuracy: 1598/1692 (94.44%)\n",
            "\tValidation loss: 0.00349, Accuracy: 212/423 (50.12%)\n",
            "\tTest loss: 0.00365, Accuracy: 208/443 (46.95%)\n",
            "\n",
            "Training Progress: \tEpoch 88 [0/1692 (0.00%)]\t\tLoss: 0.60037\n",
            "Training Progress: \tEpoch 88 [320/1692 (18.87%)]\t\tLoss: 0.41986\n",
            "Training Progress: \tEpoch 88 [640/1692 (37.74%)]\t\tLoss: 0.62091\n",
            "Training Progress: \tEpoch 88 [960/1692 (56.60%)]\t\tLoss: 0.39421\n",
            "Training Progress: \tEpoch 88 [1280/1692 (75.47%)]\t\tLoss: 0.27232\n",
            "Training Progress: \tEpoch 88 [1600/1692 (94.34%)]\t\tLoss: 0.55219\n",
            "\tTrain loss: 0.00507, Accuracy: 1602/1692 (94.68%)\n",
            "\tValidation loss: 0.00363, Accuracy: 219/423 (51.77%)\n",
            "\tTest loss: 0.00383, Accuracy: 206/443 (46.50%)\n",
            "\n",
            "Training Progress: \tEpoch 89 [0/1692 (0.00%)]\t\tLoss: 0.54734\n",
            "Training Progress: \tEpoch 89 [320/1692 (18.87%)]\t\tLoss: 0.55467\n",
            "Training Progress: \tEpoch 89 [640/1692 (37.74%)]\t\tLoss: 0.55584\n",
            "Training Progress: \tEpoch 89 [960/1692 (56.60%)]\t\tLoss: 0.31607\n",
            "Training Progress: \tEpoch 89 [1280/1692 (75.47%)]\t\tLoss: 0.35385\n",
            "Training Progress: \tEpoch 89 [1600/1692 (94.34%)]\t\tLoss: 0.51080\n",
            "\tTrain loss: 0.00461, Accuracy: 1610/1692 (95.15%)\n",
            "\tValidation loss: 0.00387, Accuracy: 223/423 (52.72%)\n",
            "\tTest loss: 0.00391, Accuracy: 219/443 (49.44%)\n",
            "\n",
            "Training Progress: \tEpoch 90 [0/1692 (0.00%)]\t\tLoss: 0.36951\n",
            "Training Progress: \tEpoch 90 [320/1692 (18.87%)]\t\tLoss: 0.52524\n",
            "Training Progress: \tEpoch 90 [640/1692 (37.74%)]\t\tLoss: 0.47355\n",
            "Training Progress: \tEpoch 90 [960/1692 (56.60%)]\t\tLoss: 0.50630\n",
            "Training Progress: \tEpoch 90 [1280/1692 (75.47%)]\t\tLoss: 0.29717\n",
            "Training Progress: \tEpoch 90 [1600/1692 (94.34%)]\t\tLoss: 0.69001\n",
            "\tTrain loss: 0.00404, Accuracy: 1628/1692 (96.22%)\n",
            "\tValidation loss: 0.00337, Accuracy: 212/423 (50.12%)\n",
            "\tTest loss: 0.00355, Accuracy: 222/443 (50.11%)\n",
            "\n",
            "Training Progress: \tEpoch 91 [0/1692 (0.00%)]\t\tLoss: 0.31316\n",
            "Training Progress: \tEpoch 91 [320/1692 (18.87%)]\t\tLoss: 0.51145\n",
            "Training Progress: \tEpoch 91 [640/1692 (37.74%)]\t\tLoss: 0.39006\n",
            "Training Progress: \tEpoch 91 [960/1692 (56.60%)]\t\tLoss: 0.52195\n",
            "Training Progress: \tEpoch 91 [1280/1692 (75.47%)]\t\tLoss: 0.30049\n",
            "Training Progress: \tEpoch 91 [1600/1692 (94.34%)]\t\tLoss: 0.47096\n",
            "\tTrain loss: 0.00438, Accuracy: 1626/1692 (96.10%)\n",
            "\tValidation loss: 0.00338, Accuracy: 219/423 (51.77%)\n",
            "\tTest loss: 0.00359, Accuracy: 213/443 (48.08%)\n",
            "\n",
            "Training Progress: \tEpoch 92 [0/1692 (0.00%)]\t\tLoss: 0.49571\n",
            "Training Progress: \tEpoch 92 [320/1692 (18.87%)]\t\tLoss: 0.78978\n",
            "Training Progress: \tEpoch 92 [640/1692 (37.74%)]\t\tLoss: 0.39002\n",
            "Training Progress: \tEpoch 92 [960/1692 (56.60%)]\t\tLoss: 0.42819\n",
            "Training Progress: \tEpoch 92 [1280/1692 (75.47%)]\t\tLoss: 0.53160\n",
            "Training Progress: \tEpoch 92 [1600/1692 (94.34%)]\t\tLoss: 0.44901\n",
            "\tTrain loss: 0.00406, Accuracy: 1627/1692 (96.16%)\n",
            "\tValidation loss: 0.00348, Accuracy: 224/423 (52.96%)\n",
            "\tTest loss: 0.00362, Accuracy: 219/443 (49.44%)\n",
            "\n",
            "Training Progress: \tEpoch 93 [0/1692 (0.00%)]\t\tLoss: 0.43277\n",
            "Training Progress: \tEpoch 93 [320/1692 (18.87%)]\t\tLoss: 0.53801\n",
            "Training Progress: \tEpoch 93 [640/1692 (37.74%)]\t\tLoss: 0.58540\n",
            "Training Progress: \tEpoch 93 [960/1692 (56.60%)]\t\tLoss: 0.49715\n",
            "Training Progress: \tEpoch 93 [1280/1692 (75.47%)]\t\tLoss: 0.27490\n",
            "Training Progress: \tEpoch 93 [1600/1692 (94.34%)]\t\tLoss: 0.67519\n",
            "\tTrain loss: 0.00471, Accuracy: 1603/1692 (94.74%)\n",
            "\tValidation loss: 0.00382, Accuracy: 220/423 (52.01%)\n",
            "\tTest loss: 0.00386, Accuracy: 219/443 (49.44%)\n",
            "\n",
            "Training Progress: \tEpoch 94 [0/1692 (0.00%)]\t\tLoss: 0.28185\n",
            "Training Progress: \tEpoch 94 [320/1692 (18.87%)]\t\tLoss: 0.48591\n",
            "Training Progress: \tEpoch 94 [640/1692 (37.74%)]\t\tLoss: 0.40032\n",
            "Training Progress: \tEpoch 94 [960/1692 (56.60%)]\t\tLoss: 0.39659\n",
            "Training Progress: \tEpoch 94 [1280/1692 (75.47%)]\t\tLoss: 0.25846\n",
            "Training Progress: \tEpoch 94 [1600/1692 (94.34%)]\t\tLoss: 0.28135\n",
            "\tTrain loss: 0.00458, Accuracy: 1610/1692 (95.15%)\n",
            "\tValidation loss: 0.00371, Accuracy: 224/423 (52.96%)\n",
            "\tTest loss: 0.00391, Accuracy: 214/443 (48.31%)\n",
            "\n",
            "Training Progress: \tEpoch 95 [0/1692 (0.00%)]\t\tLoss: 0.23138\n",
            "Training Progress: \tEpoch 95 [320/1692 (18.87%)]\t\tLoss: 0.63780\n",
            "Training Progress: \tEpoch 95 [640/1692 (37.74%)]\t\tLoss: 0.55459\n",
            "Training Progress: \tEpoch 95 [960/1692 (56.60%)]\t\tLoss: 0.35604\n",
            "Training Progress: \tEpoch 95 [1280/1692 (75.47%)]\t\tLoss: 0.31888\n",
            "Training Progress: \tEpoch 95 [1600/1692 (94.34%)]\t\tLoss: 0.46487\n",
            "\tTrain loss: 0.00373, Accuracy: 1623/1692 (95.92%)\n",
            "\tValidation loss: 0.00368, Accuracy: 215/423 (50.83%)\n",
            "\tTest loss: 0.00394, Accuracy: 212/443 (47.86%)\n",
            "\n",
            "Training Progress: \tEpoch 96 [0/1692 (0.00%)]\t\tLoss: 0.30699\n",
            "Training Progress: \tEpoch 96 [320/1692 (18.87%)]\t\tLoss: 0.43637\n",
            "Training Progress: \tEpoch 96 [640/1692 (37.74%)]\t\tLoss: 0.39741\n",
            "Training Progress: \tEpoch 96 [960/1692 (56.60%)]\t\tLoss: 0.42888\n",
            "Training Progress: \tEpoch 96 [1280/1692 (75.47%)]\t\tLoss: 0.41004\n",
            "Training Progress: \tEpoch 96 [1600/1692 (94.34%)]\t\tLoss: 0.24625\n",
            "\tTrain loss: 0.00422, Accuracy: 1618/1692 (95.63%)\n",
            "\tValidation loss: 0.00386, Accuracy: 210/423 (49.65%)\n",
            "\tTest loss: 0.00397, Accuracy: 219/443 (49.44%)\n",
            "\n",
            "Training Progress: \tEpoch 97 [0/1692 (0.00%)]\t\tLoss: 0.33519\n",
            "Training Progress: \tEpoch 97 [320/1692 (18.87%)]\t\tLoss: 0.77716\n",
            "Training Progress: \tEpoch 97 [640/1692 (37.74%)]\t\tLoss: 0.49278\n",
            "Training Progress: \tEpoch 97 [960/1692 (56.60%)]\t\tLoss: 0.36409\n",
            "Training Progress: \tEpoch 97 [1280/1692 (75.47%)]\t\tLoss: 0.42753\n",
            "Training Progress: \tEpoch 97 [1600/1692 (94.34%)]\t\tLoss: 0.41286\n",
            "\tTrain loss: 0.00355, Accuracy: 1639/1692 (96.87%)\n",
            "\tValidation loss: 0.00396, Accuracy: 211/423 (49.88%)\n",
            "\tTest loss: 0.00417, Accuracy: 197/443 (44.47%)\n",
            "\n",
            "Training Progress: \tEpoch 98 [0/1692 (0.00%)]\t\tLoss: 0.65592\n",
            "Training Progress: \tEpoch 98 [320/1692 (18.87%)]\t\tLoss: 0.29900\n",
            "Training Progress: \tEpoch 98 [640/1692 (37.74%)]\t\tLoss: 0.36773\n",
            "Training Progress: \tEpoch 98 [960/1692 (56.60%)]\t\tLoss: 0.59382\n",
            "Training Progress: \tEpoch 98 [1280/1692 (75.47%)]\t\tLoss: 0.39004\n",
            "Training Progress: \tEpoch 98 [1600/1692 (94.34%)]\t\tLoss: 0.65126\n",
            "\tTrain loss: 0.00381, Accuracy: 1639/1692 (96.87%)\n",
            "\tValidation loss: 0.00369, Accuracy: 213/423 (50.35%)\n",
            "\tTest loss: 0.00370, Accuracy: 211/443 (47.63%)\n",
            "\n",
            "Training Progress: \tEpoch 99 [0/1692 (0.00%)]\t\tLoss: 0.41229\n",
            "Training Progress: \tEpoch 99 [320/1692 (18.87%)]\t\tLoss: 0.30352\n",
            "Training Progress: \tEpoch 99 [640/1692 (37.74%)]\t\tLoss: 0.34067\n",
            "Training Progress: \tEpoch 99 [960/1692 (56.60%)]\t\tLoss: 0.48222\n",
            "Training Progress: \tEpoch 99 [1280/1692 (75.47%)]\t\tLoss: 0.28312\n",
            "Training Progress: \tEpoch 99 [1600/1692 (94.34%)]\t\tLoss: 0.30602\n",
            "\tTrain loss: 0.00431, Accuracy: 1617/1692 (95.57%)\n",
            "\tValidation loss: 0.00414, Accuracy: 213/423 (50.35%)\n",
            "\tTest loss: 0.00417, Accuracy: 210/443 (47.40%)\n",
            "\n",
            "Training Progress: \tEpoch 100 [0/1692 (0.00%)]\t\tLoss: 0.32784\n",
            "Training Progress: \tEpoch 100 [320/1692 (18.87%)]\t\tLoss: 0.29717\n",
            "Training Progress: \tEpoch 100 [640/1692 (37.74%)]\t\tLoss: 0.53947\n",
            "Training Progress: \tEpoch 100 [960/1692 (56.60%)]\t\tLoss: 0.59795\n",
            "Training Progress: \tEpoch 100 [1280/1692 (75.47%)]\t\tLoss: 0.26364\n",
            "Training Progress: \tEpoch 100 [1600/1692 (94.34%)]\t\tLoss: 0.34326\n",
            "\tTrain loss: 0.00290, Accuracy: 1654/1692 (97.75%)\n",
            "\tValidation loss: 0.00390, Accuracy: 217/423 (51.30%)\n",
            "\tTest loss: 0.00397, Accuracy: 220/443 (49.66%)\n",
            "\n",
            "Best validation accuracy:\n",
            "0.5555555555555556\n",
            "Best test accuracy:\n",
            "0.5395033860045146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAEICAYAAACkmHavAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niqL0YlSRK4qiKEov5v8Di5PUZvMrMEIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}